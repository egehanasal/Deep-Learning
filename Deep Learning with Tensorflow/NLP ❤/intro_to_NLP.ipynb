{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro_to_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvUgFUGHRPxd"
      },
      "source": [
        "# Introduction to NLP Fundamentals in TensorFlow\n",
        "\n",
        "NLP has the goal of deriving information out of natural language (could be sequences text or speech)\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq)\n",
        "\n",
        "To get hands-on with NLP in TensorFlow, we're going to practice the steps we've used previously but this time with text data:\n",
        "\n",
        "```\n",
        "Text -> turn into numbers -> build a model -> train the model to find patterns -> use patterns (make predictions)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZQEXSoIYuyM"
      },
      "source": [
        "## Get helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcvVVeFHYu2A",
        "outputId": "de723ac1-d910-43ac-8f86-2161d83a93b3"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions \n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-07 21:23:34--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‚Äòhelper_functions.py‚Äô\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-07 21:23:34 (63.5 MB/s) - ‚Äòhelper_functions.py‚Äô saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzcVAAEwYu5P"
      },
      "source": [
        "## Get a text dataset\n",
        "\n",
        "The dataset we're going to be using is [`Kaggle's intorduction to NLP dataset`](https://www.kaggle.com/c/nlp-getting-started/data) (text samples of Tweets labelled as disaster or not disaster)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkgIpge1Yu8k",
        "outputId": "fbb5cce0-a6b1-40fe-8bc3-b9cdaa225d5d"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-07 21:23:42--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.141.128, 142.251.2.128, 74.125.137.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‚Äònlp_getting_started.zip‚Äô\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2021-10-07 21:23:42 (125 MB/s) - ‚Äònlp_getting_started.zip‚Äô saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fr7bStRrVkC"
      },
      "source": [
        "Unzipping `nlp_getting_started.zip` gives the following 3 `.csv` files:\n",
        "* `sample_submission.csv` - an example of the file you'd submit to the Kaggle competition of your model's predictions.\n",
        "* `train.csv` - training samples of real and not real diaster Tweets.\n",
        "* `test.csv` - testing samples of real and not real diaster Tweets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sxBIZXYYvAE"
      },
      "source": [
        "## Visualizing a text dataset\n",
        "\n",
        "To visualize our text samples, we first have to read them in, one way to do so would be to use Python.\n",
        "\n",
        "But another way to do this is to use Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "iL-1D6n5YvDZ",
        "outputId": "6a28d1c0-3ee5-4307-ee42-a09144a69432"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "7x7j9ZnMYvGx",
        "outputId": "9ad828e3-dc18-47ee-d131-4e00d287be7e"
      },
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ¬â√õ√èThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TNoLY40sIya"
      },
      "source": [
        "Notice how the training data has a `\"target\"` column.\n",
        "\n",
        "We're going to be writing code to find patterns (e.g. different combinations of words) in the `\"text\"` column of the training dataset to predict the value of the `\"target\"` column.\n",
        "\n",
        "The test dataset doesn't have a `\"target\"` column.\n",
        "\n",
        "```\n",
        "Inputs (text column) -> Machine Learning Algorithm -> Outputs (target column)\n",
        "```\n",
        "\n",
        "*Example text classification inputs and outputs for the problem of classifying whether a Tweet is about a diaster or not.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "l_-HxVvmYvKr",
        "outputId": "85c56aa6-0f04-4246-94da-98661fad7842"
      },
      "source": [
        "# What does the test dataframe look like?\n",
        "test_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi1sNsWGYvN9",
        "outputId": "082ee064-3173-4fb5-8d9d-e8ca35e71318"
      },
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI0TExWMtAax"
      },
      "source": [
        "Since we have two target values, we're dealing with a **binary classification** problem.\n",
        "\n",
        "It's fairly balanced too, about 60% negative class (`target = 0`) and 40% positive class (`target = 1`).\n",
        "\n",
        "Where, \n",
        "\n",
        "* `1` = a real disaster Tweet\n",
        "* `0` = not a real disaster Tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pbec6Q9YvRN",
        "outputId": "3c919721-545e-46a1-d502-64ed4fb83e59"
      },
      "source": [
        "# How many total samples?\n",
        "len(train_df), len(test_df)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLSl-8DjYvUl",
        "outputId": "95f9fbf0-3e51-4d68-8a9f-28e605e3ec90"
      },
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"-----\\n\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "@AisuMage @AkumaReisu --just between Gray and Ophelia red flames blazing around her person setting nearly everything in the area--\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Talk on GOZ is fantastic. Most interesting fact so far is that they manually bought all the .ru domains to sinkhole rather than seek co-op.\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "WOOOOOOO RT @GameRant: Call of Duty: Black Ops 3 eSports Mode Lets Players Ban Weapons http://t.co/76EHHmQQ6R http://t.co/umtffA9JjB\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Strong Thunderstorm 4 Miles North of Japton Moving SE At 25 MPH. Large Hail and Wind Gusts Up to 50 MPH Poss... #arwx http://t.co/TIM8x9bI0f\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "I liked a @YouTube video http://t.co/TNXQuOr1wb Kalle Mattson - 'Avalanche' (Official Video)\n",
            "\n",
            "-----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fzbfk8oYvX5"
      },
      "source": [
        "### Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g030UqDgYvbB"
      },
      "source": [
        "# Use train_test_split to split training data into training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=42) # use 10% of the data for validation split"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbvMESYgb8ql",
        "outputId": "e9033557-9d9f-4d0d-e7a2-8bbcd4321a0c"
      },
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl90dnqgb8oN",
        "outputId": "e9404573-7f23-4879-a101-a3397db91eac"
      },
      "source": [
        "# Check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY6fbQYtb8lR"
      },
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "When dealing with a text problem, one of the first things you'll have to do before you build a model is to convert your text to numbers\n",
        "\n",
        "In NLP, there are two main concepts for turning text into numbers:\n",
        "* **Tokenization** - A straight mapping from word or character or sub-word to a numerical value. There are three main levels of tokenization:\n",
        "  1. Using **word-level tokenization** with the sentence \"I love TensorFlow\" might result in \"I\" being `0`, \"love\" being `1` and \"TensorFlow\" being `2`. In this case, every word in a sequence considered a single **token**.\n",
        "  2. **Character-level tokenization**, such as converting the letters A-Z to values `1-26`. In this case, every character in a sequence considered a single **token**.\n",
        "  3. **Sub-word tokenization** is in between word-level and character-level tokenization. It involves breaking invidual words into smaller parts and then converting those smaller parts into numbers. For example, \"my favourite food is pineapple pizza\" might become \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After doing this, these sub-words would then be mapped to a numerical value. In this case, every word could be considered multiple **tokens**.\n",
        "* **Embeddings** - An embedding is a representation of natural language which can be learned. Representation comes in the form of a **feature vector**. For example, the word \"dance\" could be represented by the 5-dimensional vector `[-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]`. It's important to note here, the size of the feature vector is tuneable. There are two ways to use embeddings: \n",
        "  1. **Create your own embedding** - Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as [`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding)) and an embedding representation will be learned during model training.\n",
        "  2. **Reuse a pre-learned embedding** - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSvnkYtrLicc"
      },
      "source": [
        "> ü§î **Question:** What level of tokenzation should I use? What embedding should should I choose?\n",
        "\n",
        "It depends on your problem. You could try character-level tokenization/embeddings and word-level tokenization/embeddings and see which perform best. You might even want to try stacking them (e.g. combining the outputs of your embedding layers using [`tf.keras.layers.concatenate`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/concatenate)). \n",
        "\n",
        "If you're looking for pre-trained word embeddings, [Word2vec embeddings](http://jalammar.github.io/illustrated-word2vec/), [GloVe embeddings](https://nlp.stanford.edu/projects/glove/) and many of the options available on [TensorFlow Hub](https://tfhub.dev/s?module-type=text-embedding) are great places to start.\n",
        "\n",
        "> üîë **Note:** Much like searching for a pre-trained computer vision model, you can search for pre-trained word embeddings to use for your problem. Try searching for something like \"use pre-trained word embeddings in TensorFlow\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vnv4IJLJb8iM"
      },
      "source": [
        "### Text Vectorization (tokenization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdU0IItzLsou"
      },
      "source": [
        "The `TextVectorization` layer takes the following parameters:\n",
        "* `max_tokens` - The maximum number of words in your vocabulary (e.g. 20000 or the number of unique words in your text), includes a value for OOV (out of vocabulary) tokens. \n",
        "* `standardize` - Method for standardizing text. Default is `\"lower_and_strip_punctuation\"` which lowers text and removes all punctuation marks.\n",
        "* `split` - How to split text, default is `\"whitespace\"` which splits on spaces.\n",
        "* `ngrams` - How many words to contain per token split, for example, `ngrams=2` splits tokens into continuous sequences of 2.\n",
        "* `output_mode` -  How to output tokens, can be `\"int\"` (integer mapping), `\"binary\"` (one-hot encoding), `\"count\"` or `\"tf-idf\"`. See documentation for more.\n",
        "* `output_sequence_length` - Length of tokenized sequence to output. For example, if `output_sequence_length=150`, all tokenized sequences will be 150 tokens long.\n",
        "* `pad_to_max_tokens` - Defaults to `False`, if `True`, the output feature axis will be padded to `max_tokens` even if the number of unique tokens in the vocabulary is less than `max_tokens`. Only valid in certain modes, see docs for more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgiUWuOOb8fk",
        "outputId": "67e46ae6-08e2-404c-c5de-5b24bda9f2a1"
      },
      "source": [
        "train_sentences[:5]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D4itQ_6gJFI"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# DEMONSTRATING the DEFAULT TextVectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # defines how many words in the vocabulary (automatically add <OOV>)\n",
        "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                    split=\"whitespace\", # how to split tokens\n",
        "                                    ngrams=None, # create groups of n-words\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=None) # how long do you want your output sequences to be\n",
        "                                    # pad_to_max_tokens=True) # Not valid if using max_tokens=None"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZM6vLubNKaJ"
      },
      "source": [
        "We've initialized a `TextVectorization` object with the default settings but let's customize it a little bit for our own use case.\n",
        "\n",
        "In particular, let's set values for `max_tokens` and `output_sequence_length`.\n",
        "\n",
        "For `max_tokens` (the number of words in the vocabulary), multiples of 10,000 (`10,000`, `20,000`, `30,000`) or the exact number of unique words in your text (e.g. `32,179`) are common values.\n",
        "\n",
        "For our use case, we'll use `10,000`.\n",
        "\n",
        "And for the `output_sequence_length` we'll use the average number of tokens per Tweet in the training set. But first, we'll need to find it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKplxYePgJDL",
        "outputId": "66bec564-ca24-43fc-ea54-2a97c7b1e652"
      },
      "source": [
        "# Find the average number of tokens (words) in the training tweets\n",
        "round(sum(len(i.split()) for i in train_sentences)/len(train_sentences))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpPDn_szgJAs"
      },
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a tweet does our model see)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtpCOGbqNO0a"
      },
      "source": [
        "To map our `TextVectorization` instance `text_vectorizer` to our data, we can call the `adapt()` method on it whilst passing it our training text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvQmYZjTgI-T"
      },
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht8JPh9bgI76",
        "outputId": "3a4af274-04a4-4d44-d468-64b894be11c0"
      },
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a mug on the table!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 6), dtype=int64, numpy=array([[ 264,    3,    1,   11,    2, 2663]])>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDfXxT2IgczY",
        "outputId": "8212bf91-388c-4cfd-8e8e-e2d34af66a5e"
      },
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "        \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " 'The Reagan Administration had arranged for Israeli weapons to be sent to the Guatemalan Army  http://t.co/4fYNQ1hWWb        \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[   2, 9317, 6263,   94,    1,   10,  602,  258,    5,   21, 1596,\n",
              "           5,    2,    1,  164]])>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0grp0SspmPED"
      },
      "source": [
        "We can check the unique tokens in our vocabulary using the `get_vocabulary()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXRbgthsgcxN",
        "outputId": "51601fae-cfb9-40a5-e33d-6e42a3064f7d"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in our training data\n",
        "top_5_words = words_in_vocab[:5] # get the most common words\n",
        "bottom_5_words = words_in_vocab[-5:] # get the least common words\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"5 most common words in vocab: {top_5_words}\")\n",
        "print(f\"5 least common words in vocab: {bottom_5_words}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "5 most common words in vocab: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 least common words in vocab: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPkhPO_fgcux"
      },
      "source": [
        "### Creating an Embedding using an Embedding Layer\n",
        "\n",
        "The powerful thing about an embedding is it can be learned during training. This means rather than just being static (e.g. `1` = I, `2` = love, `3` = TensorFlow), a word's numeric representation can be improved as a model goes through data samples.\n",
        "\n",
        "The main parameters we're concerned about here are:\n",
        "* `input_dim` - The size of the vocabulary (e.g. `len(text_vectorizer.get_vocabulary()`).\n",
        "* `output_dim` - The size of the output embedding vector, for example, a value of `100` outputs a  feature vector of size 100 for each word. (each token gets represented bu a vector 100 long)\n",
        "* `embeddings_initializer` - How to initialize the embeddings matrix, default is `\"uniform\"` which randomly initalizes embedding matrix with uniform distribution. This can be changed for using pre-learned embeddings.\n",
        "* `input_length` - Length of sequences being passed to embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaxkG5sL76Fx",
        "outputId": "0c913258-dba0-45d9-ca7a-0b9de8d5cc6f"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # size of the embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, initialize randomly\n",
        "                             input_length=max_length) # how long is each input\n",
        "\n",
        "embedding"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f4105bd0cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45zMpAOXnkxk"
      },
      "source": [
        "Notice how `embedding` is a TensoFlow layer? This is important because we can use it as part of a model, meaning its parameters (word representations) can be updated and improved as the model learns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC98rRzY76C0",
        "outputId": "0561da7b-47a1-4dbd-e759-9b672f5e169a"
      },
      "source": [
        "# Get a random sentence from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " Man . somebody gotta stop Sbee dude too fuckin funny blood      \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.04461151,  0.03961584,  0.02465744, ..., -0.01866372,\n",
              "         -0.00841191,  0.04245517],\n",
              "        [ 0.01754216, -0.00119487, -0.01312176, ..., -0.04464993,\n",
              "          0.02956721, -0.02847507],\n",
              "        [ 0.04386619,  0.02840788,  0.00240091, ...,  0.00849953,\n",
              "         -0.03618901,  0.01962293],\n",
              "        ...,\n",
              "        [-0.0012532 ,  0.03716965,  0.00968367, ...,  0.04133293,\n",
              "          0.03937745,  0.01071076],\n",
              "        [-0.0012532 ,  0.03716965,  0.00968367, ...,  0.04133293,\n",
              "          0.03937745,  0.01071076],\n",
              "        [-0.0012532 ,  0.03716965,  0.00968367, ...,  0.04133293,\n",
              "          0.03937745,  0.01071076]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZPQnfjantmq"
      },
      "source": [
        "Each token in the sentence gets turned into a length 128 feature vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6Dg_y0z75_x",
        "outputId": "4730f2ea-80b2-4eaf-f673-cb46666eb939"
      },
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-0.04461151,  0.03961584,  0.02465744, -0.0457072 , -0.04604244,\n",
              "         0.0280154 , -0.03256259,  0.0141517 , -0.0045867 ,  0.01385221,\n",
              "        -0.01586212, -0.02253008, -0.01424081, -0.03278085, -0.01775406,\n",
              "         0.03185748, -0.02805494, -0.04060543,  0.00571389,  0.049997  ,\n",
              "        -0.01382437, -0.01721781,  0.02588366,  0.00428043,  0.00461042,\n",
              "         0.008045  , -0.00329085, -0.03441088,  0.01807323, -0.02745605,\n",
              "         0.02515955, -0.01643424,  0.02236005, -0.03658252,  0.04625135,\n",
              "        -0.02974608, -0.03771418,  0.0090288 , -0.02496538,  0.01323644,\n",
              "         0.03128991, -0.01619508, -0.03048185,  0.0221761 ,  0.04117687,\n",
              "         0.04873708,  0.03659612,  0.0299519 , -0.04769072,  0.02699271,\n",
              "         0.02555659, -0.04864026,  0.03403797, -0.00864235,  0.04029295,\n",
              "         0.04197798, -0.02318193,  0.02296982,  0.00574613, -0.00595979,\n",
              "         0.00151181, -0.0156226 , -0.04322232, -0.01174948, -0.03198489,\n",
              "        -0.03785137, -0.01397178, -0.01984216,  0.03318168, -0.04457105,\n",
              "         0.03744748, -0.00437842, -0.01177246,  0.02348032,  0.01016283,\n",
              "        -0.00572158,  0.01635802,  0.04556383,  0.02587687,  0.03477008,\n",
              "        -0.04934772, -0.04850631, -0.01926076,  0.00813726, -0.01038188,\n",
              "        -0.0216974 ,  0.00088273,  0.04844368,  0.02907214, -0.01368017,\n",
              "         0.02154176, -0.01843736, -0.04326529, -0.03924555,  0.00387524,\n",
              "         0.01193341, -0.01430527, -0.00741487,  0.03261291,  0.00536121,\n",
              "        -0.00638209,  0.01822784, -0.03252043, -0.04892796, -0.01424853,\n",
              "         0.00955614, -0.0106905 ,  0.03514787, -0.0012357 , -0.00867968,\n",
              "         0.04583348,  0.01459572, -0.02806333, -0.04744865,  0.03573838,\n",
              "         0.00669787,  0.02584075,  0.03712514, -0.03621947,  0.02045277,\n",
              "        -0.02765074, -0.00640074,  0.02921164, -0.0043473 , -0.04516558,\n",
              "        -0.01866372, -0.00841191,  0.04245517], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 'Man . somebody gotta stop Sbee dude too fuckin funny blood')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cNNK_va758Y"
      },
      "source": [
        "## Modelling a text dataset (running series of experiments)\n",
        "\n",
        "Now we've got way to turn our text sequences into numbes, it's time to start building a series of modelling experiments.\n",
        "\n",
        "We'll start with a baseline and move on from there.\n",
        "\n",
        "* **Model 0**: Naive Bayes (baseline)\n",
        "* **Model 1**: Feed-forward neural network (dense model)\n",
        "* **Model 2**: LSTM model (RNN)\n",
        "* **Model 3**: GRU model (RNN)\n",
        "* **Model 4**: Bidirectional-LSTM model (RNN)\n",
        "* **Model 5**: 1D Convolutional Neural Network (CNN)\n",
        "* **Model 6**: TensorFlow Hub Pretrained Feature Extractor (using transfer learning for NLP)\n",
        "* **Model 7**: Same as model 6 with 10% of training data\n",
        "\n",
        "Model 0 is the simplest to acquire a baseline which we'll expect each other of the other deeper models to beat.\n",
        "\n",
        "Each experiment will go through the following steps:\n",
        "* Create a model\n",
        "* Build a model\n",
        "* Fit a model\n",
        "* Evaluate our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNKCe5hk755g"
      },
      "source": [
        "### Model 0: Getting a baseline\n",
        "\n",
        "As with all machine learning modelling experiments, it's important to create a baseline model wo you've got a benchmark for future experiments to build up on.\n",
        "\n",
        "To create our baseline, we'll create a Scikit-Learn Pipeline using the TF-IDF (term frequency-inverse document frequency) formula to convert our words to numbers and then model them with the [Multinomial Naive Bayes algorithm](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB). This was chosen via referring to the [Scikit-Learn machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n",
        "\n",
        ">üîë **Note:** It's common practice to use non-DL algorithms as a baseline because of their speed and then later using DL to see if you can improve upon them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62nPwf6wD9e9",
        "outputId": "bd2d71ad-95eb-4e4d-b36b-2f2c9cb93df8"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "  (\"tfidf\", TfidfVectorizer()), # Convert words to numbers using tfidf\n",
        "  (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEOqDseHoe8R"
      },
      "source": [
        "The benefit of using a shallow model like Multinomial Naive Bayes is that training is very fast."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB25JiKND9cF",
        "outputId": "b42f0814-0c38-4c75-87be-5fe5b6d0078b"
      },
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "\n",
        "baseline_score"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7926509186351706"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q3UuivBD9Z5",
        "outputId": "83f94cea-a87e-4bde-b0f4-9ad6e150ecdf"
      },
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:10]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgGjSAXDD9Xj"
      },
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "We could evaluate these as they are but since we're going to be evaluating several models in the same way going forward, let's create a helper function which takes an array of predictions and ground truth labels and computes the following:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score\n",
        "\n",
        "> üîë **Note:** Since we're dealing with a classification problem, the above metrics are the most appropriate. If we were working with a regression problem, other metrics such as MAE (mean absolute error) would be a better choice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ues8N5OvJaLo"
      },
      "source": [
        "üìñ For a deep overview of many different evaluation methods, see the Sklearn documentation: https://scikit-learn.org/stable/modules/model_evaluation.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHK95g-cD9Sx"
      },
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1-score using *weighted* average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                   \"precision\": model_precision,\n",
        "                   \"recall\": model_recall,\n",
        "                   \"f1\": model_f1}\n",
        "\n",
        "  return model_results"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN8kDqXgD9Py",
        "outputId": "7e77d50b-33d7-44e2-9564-c80f4364fd25"
      },
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT0li8CMMXLQ"
      },
      "source": [
        "### Model 1: A simple dense model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBy6hTqHqqC7"
      },
      "source": [
        "It'll take our text and labels as input, tokenize the text, create an embedding, find the average of the embedding (using Global Average Pooling) and then pass the average through a fully connected layer with one output unit and a sigmoid activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KumFAS5kD9NE"
      },
      "source": [
        "# Create a tensorboard callback (need to create a nwe one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5l28J6FMW6i"
      },
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-dimensional string\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numberized inputs\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the feature vector for each token to one vector (lower the dimensionality of the embedding)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # Create the output layer, want binary outputs so used sigmoid\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9O3GSpjrIhC"
      },
      "source": [
        "Our model takes a 1-dimensional string as input (in our case, a Tweet), it then tokenizes the string using `text_vectorizer` and creates an embedding using `embedding`.\n",
        "\n",
        "We then  pool the outputs of the embedding layer to reduce the dimensionality of the tensor we pass to the output layer.\n",
        "\n",
        "Finally, we pass the output of the pooling layer to a dense layer with sigmoid activation (we use sigmoid since our problem is binary classification)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQTw6WqQMW4H",
        "outputId": "f881f094-2591-4416-cd68-76d514f51e0c"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC5DG3T7re8Q"
      },
      "source": [
        "Most of the trainable parameters are contained within the embedding layer. Recall we created an embedding of size 128 (`output_dim=128`) for a vocabulary of size 10,000 (`input_dim=10000`), hence the 1,280,000 trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX0ZSrJQMW1z",
        "outputId": "2bbec985-59bd-4972-eb57-71dd578e8617"
      },
      "source": [
        "# Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_1_history = model_1.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"model_1_dense\")])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20211007-102629\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 9ms/step - loss: 0.6102 - accuracy: 0.6865 - val_loss: 0.5349 - val_accuracy: 0.7533\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.4399 - accuracy: 0.8212 - val_loss: 0.4704 - val_accuracy: 0.7861\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.3453 - accuracy: 0.8606 - val_loss: 0.4573 - val_accuracy: 0.7861\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.2829 - accuracy: 0.8913 - val_loss: 0.4588 - val_accuracy: 0.7900\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.2363 - accuracy: 0.9118 - val_loss: 0.4760 - val_accuracy: 0.7874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0onHuzsMWzQ",
        "outputId": "0acc5c69-3858-4196-9d23-fa8744f70ac3"
      },
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7874\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4759829044342041, 0.787401556968689]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmDeMm5NMWwn",
        "outputId": "ef253db5-191d-4e7d-a1fc-69251ccf67fb"
      },
      "source": [
        "# Make some predictions and evaluate those\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPD_Az8DD9KQ",
        "outputId": "66eafa25-04a0-44e2-89ec-82577efc6305"
      },
      "source": [
        "# Look at a single prediction\n",
        "model_1_pred_probs[0]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.40028867], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBSndmACO7FQ",
        "outputId": "dd4acd3a-dd3f-4b40-ca64-a244bb014e3f"
      },
      "source": [
        "# Look at the first 10 predictions\n",
        "model_1_pred_probs[:10]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.40028867],\n",
              "       [0.800866  ],\n",
              "       [0.9978104 ],\n",
              "       [0.10491349],\n",
              "       [0.10441678],\n",
              "       [0.93273485],\n",
              "       [0.9109768 ],\n",
              "       [0.9928678 ],\n",
              "       [0.9658808 ],\n",
              "       [0.24589317]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMbFX5SgO69e"
      },
      "source": [
        "# Convert model prediction probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VriB4bdcO62d",
        "outputId": "7545925b-4671-4d5d-f883-e341caa12b91"
      },
      "source": [
        "model_1_preds[:10]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeJd8FHRO6zt",
        "outputId": "69c09df2-9dc2-459a-8605-25d99ac145ac"
      },
      "source": [
        "# Calculate our model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.74015748031496,\n",
              " 'f1': 0.7845557264291478,\n",
              " 'precision': 0.791897156051696,\n",
              " 'recall': 0.7874015748031497}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUbuz49OO6xX",
        "outputId": "76fa0fe3-f373-4afe-fa7f-c2d83f73bb0b"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3s0hHPCT4lS",
        "outputId": "d06915ea-2528-49c3-9c52-1f41f514df54"
      },
      "source": [
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6pT1ZxFYXwZ"
      },
      "source": [
        "Looks like our baseline is out performing our first deep learning model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyAW7P6msYO7"
      },
      "source": [
        "Since we'll be doing this kind of comparison (baseline compared to new model) quite a few times, let's create a function to help us out. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il0WVVB1sYiT",
        "outputId": "f75f94fe-7c71-46d7-b544-6fefbc29fe7c"
      },
      "source": [
        "# Create a helper function to compare our baseline results to new model results\n",
        "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
        "  for key, value in baseline_results.items():\n",
        "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
        "\n",
        "compare_baseline_to_new_results(baseline_results=baseline_results, \n",
        "                                new_model_results=model_1_results)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 78.74, Difference: -0.52\n",
            "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
            "Baseline recall: 0.79, New recall: 0.79, Difference: -0.01\n",
            "Baseline f1: 0.79, New f1: 0.78, Difference: -0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KptOkyusT4iW"
      },
      "source": [
        "## Visualizing learned embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e-knZGasz-i"
      },
      "source": [
        "Our first model (`model_1`) contained an embedding layer (`embedding`) which learned a way of representing words as feature vectors by passing over the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I21XbrQdT4fN",
        "outputId": "b68d2132-ce65-4b6a-aacb-0f8b5860f363"
      },
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvahN795T4cx",
        "outputId": "bcff81cd-cdc8-41d5-aa15-ad71285446ef"
      },
      "source": [
        "max_vocab_length"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X38c6q4TT4ZH",
        "outputId": "feefb4dc-6bea-4138-e8b5-f9b8166e2f11"
      },
      "source": [
        "# Model_1 summary\n",
        "model_1.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovCWGCn9T4Wk",
        "outputId": "51a33a2d-32b6-467b-a60b-da59c7854554"
      },
      "source": [
        "# Get the weight matrix of embedding layer\n",
        "# (these are the numerical represenatation of each token in our training data, which have been learned for 5 epochs)\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "embed_weights.shape #should be same size as vocab size and embedding_dim (output_dim of our embedding layer)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OynldGBtcGbc"
      },
      "source": [
        "Now we've got the embedding matrix our model has learned to represent our tokens, let's see how we can visualize it\n",
        "\n",
        "To do so, TensorFlow has a handy tool called projector: https://projector.tensorflow.org/\n",
        "\n",
        "And TensorFlow also has an incredible guide on word embeddings themselves: https://www.tensorflow.org/text/guide/word_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUBmXUjoal4i"
      },
      "source": [
        "# Create embedding files (we got this from TensorFlow's word embeddings documentation)\n",
        "import io\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBjA_AVMalwa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b69bc760-100e-4445-af59-b944fa8c6352"
      },
      "source": [
        "# Download files from Colab to upload to Projector\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vectors.tsv')\n",
        "  files.download('metadata.tsv')\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_96ade38d-96ee-4caa-8724-04f717d8eb28\", \"vectors.tsv\", 15376146)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6c51e477-8444-4584-aa61-76213bdf7327\", \"metadata.tsv\", 80388)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11jASyJZq74d"
      },
      "source": [
        "https://projector.tensorflow.org/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te7-6P-0pZhx"
      },
      "source": [
        "üìñ **Resources:**\n",
        " - [TensorFlow's Word Embeddings guide](https://www.tensorflow.org/text/guide/word_embeddings#representing_text_as_numbers)\n",
        " - [Jay Alammar's visualized word2vec post](https://jalammar.github.io/illustrated-word2vec/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wAGtjORalt3"
      },
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "\n",
        "RNN's are useful for sequence data\n",
        "\n",
        "The premise of an RNN is simple: use information from the past to help you with the future (this is where the term recurrent comes from). In other words, take an input (`X`) and compute an output (`y`) based on all previous inputs.\n",
        "\n",
        "This concept is especially helpful when dealing with sequences such as passages of natural language text (such as our Tweets).\n",
        "\n",
        "For example, when you read this sentence, you take into context the previous words when deciphering the meaning of the current word dog. \n",
        "\n",
        "See what happened there? \n",
        "\n",
        "I put the word \"dog\" at the end which is a valid word but it doesn't make sense in the context of the rest of the sentence.\n",
        "\n",
        "When an RNN looks at a sequence of text (already in numerical form), the patterns it learns are continually updated based on the order of the sequence. \n",
        "\n",
        "For a simple example, take two sentences:\n",
        "1. Massive earthquake last week, no?\n",
        "2. No massive earthquake last week.\n",
        "\n",
        "Both contain exactly the same words but have different meaning. The order of the words determines the meaning (one could argue punctuation marks also dictate the meaning but for simplicity sake, let's stay focused on the words).\n",
        "\n",
        "Recurrent neural networks can be used for a number of sequence-based problems:\n",
        "* **One to one:** one input, one output, such as image classification.\n",
        "* **One to many:** one input, many outputs, such as image captioning (image input, a sequence of text as caption output).\n",
        "* **Many to one:** many inputs, one outputs, such as text classification (classifying a Tweet as real diaster or not real diaster).\n",
        "* **Many to many:** many inputs, many outputs, such as machine translation (translating English to Spanish) or speech to text (audio wave as input, text as output).\n",
        "\n",
        "When you come across RNN's in the wild, you'll most likely come across variants of the following:\n",
        "* Long short-term memory cells (LSTMs).\n",
        "* Gated recurrent units (GRUs).\n",
        "* Bidirectional RNN's (passes forward and backward along a sequence, left to right and right to left).\n",
        "\n",
        "> üìñ **Resources:**\n",
        "> * [MIT Deep Learning Lecture on Recurrent Neural Networks](https://youtu.be/SEnXr6v2ifU) - explains the background of recurrent neural networks and introduces LSTMs.\n",
        "> * [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) by Andrej Karpathy - demonstrates the power of RNN's with examples generating various sequences.\n",
        "> * [Understanding LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) by Chris Olah - an in-depth (and technical) look at the mechanics of the LSTM cell, possibly the most popular RNN building block."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etuMGjHIalq2"
      },
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "LSTM = Long short term memory (one of the most popular LSTM cells)\n",
        "\n",
        "Our structure of an RNN typically looks like this:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers (RNNs/dense) -> Output (label probability\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXUm2wRkShb6"
      },
      "source": [
        "> üîë **Note:** The reason we use a new embedding layer for each model is since the embedding layer is a *learned* representation of words (as numbers), if we were to use the same embedding layer (`embedding_1`) for each model, we'd be mixing what one model learned with the next. And because we want to compare our models later on, starting them with their own embedding layer each time is a better idea."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf3cu5zlaloY"
      },
      "source": [
        "# Create an embedding layer (new embedding layer for each model)\n",
        "from tensorflow.keras import layers\n",
        "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_2\")\n",
        "# Create LSTM model \n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_2_embedding(x)\n",
        "#print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x) # when you're stacking RNN cells together, you need to set return_sequences=True\n",
        "#print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "#print(x.shape)\n",
        "#x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ym9Lt6dalmF",
        "outputId": "ebdc0b88-0544-4529-97bc-80194c2cea7b"
      },
      "source": [
        "# Get a summary\n",
        "model_2.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpSE3Y0Calf-"
      },
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_pnhaKtzBml",
        "outputId": "640c1fa7-c280-4ca3-c591-ce7df68feb41"
      },
      "source": [
        "# Fit the model\n",
        "model_2_history = model_2.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"model_2_LSTM\")])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20211007-102653\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 15ms/step - loss: 0.5087 - accuracy: 0.7453 - val_loss: 0.4605 - val_accuracy: 0.7743\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3130 - accuracy: 0.8724 - val_loss: 0.5130 - val_accuracy: 0.7690\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.2163 - accuracy: 0.9187 - val_loss: 0.5743 - val_accuracy: 0.7743\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.1506 - accuracy: 0.9461 - val_loss: 0.6909 - val_accuracy: 0.7612\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.1087 - accuracy: 0.9590 - val_loss: 0.8054 - val_accuracy: 0.7572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-V1jD8azBjQ",
        "outputId": "c5464c3b-7a85-49f7-922d-518b56bd6e6e"
      },
      "source": [
        "# Make predictions with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01293849],\n",
              "       [0.83402115],\n",
              "       [0.9996407 ],\n",
              "       [0.02915895],\n",
              "       [0.00839933],\n",
              "       [0.9996313 ],\n",
              "       [0.87252724],\n",
              "       [0.99984205],\n",
              "       [0.99966574],\n",
              "       [0.17700982]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLjvytOSzBfh",
        "outputId": "063dc65e-1d98-469b-f421-7ad259debad7"
      },
      "source": [
        "# Convert model_2 pred_probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xW_Qzlp0ilc",
        "outputId": "480ada99-f0e6-46d6-cdfa-22f0e947efc9"
      },
      "source": [
        "# Calculate model 2 results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.7217847769029,\n",
              " 'f1': 0.7543632423639389,\n",
              " 'precision': 0.7596733982700739,\n",
              " 'recall': 0.7572178477690289}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEc4hrZ_wK4Z",
        "outputId": "6e914996-4954-4e9b-9f56-30ef7ce5b97c"
      },
      "source": [
        "# Compare model 2 to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_2_results)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 75.72, Difference: -3.54\n",
            "Baseline precision: 0.81, New precision: 0.76, Difference: -0.05\n",
            "Baseline recall: 0.79, New recall: 0.76, Difference: -0.04\n",
            "Baseline f1: 0.79, New f1: 0.75, Difference: -0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOTelAMJzBdc"
      },
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Another popular and effective RNN component is the GRU of gated recurrent unit.\n",
        "\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters\n",
        "\n",
        "> üìñ **Resource:** A full explanation of the GRU cell is beyond the scope of this noteook but I'd suggest the following resources to learn more:\n",
        "* [Gated Recurrent Unit](https://en.wikipedia.org/wiki/Gated_recurrent_unit) Wikipedia page\n",
        "* [Understanding GRU networks](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be) by Simeon Kostadinov\n",
        "\n",
        "To use the GRU cell in TensorFlow, we can call the [`tensorflow.keras.layers.GRU()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU) class.\n",
        "\n",
        "The architecture of the GRU-powered model will follow the same structure we've been using:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0RbtpDyzBaA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d5c4288-3a2e-41b9-aeab-12da35aea2c9"
      },
      "source": [
        "# Create embedding layer\n",
        "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_3\")\n",
        "# Build an RNN using the GRU cell\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "#x = layers.GRU(64, return_sequences=True)(x) # if you want to stack recurrent layers on top of each other, you need to set return_sequences=True\n",
        "#x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.GRU(64)(x)\n",
        "print(x.shape)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7HnVHm5zBXJ",
        "outputId": "6e1ff2fe-d258-4fba-9a13-78548d701c6e"
      },
      "source": [
        "model_3.summary()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 64)                37248     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nB47tlewnQs"
      },
      "source": [
        "Notice the difference in number of trainable parameters between `model_2` (LSTM) and `model_3` (GRU). The difference comes from the LSTM cell having more trainable parameters than the GRU cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mcj8hudL8cem"
      },
      "source": [
        "> üîë **Note:** The return_sequences=True must be set if the next layer is an LSTM or a GRU since they need sequences in their input lists. But, if the next layer after an LSTM or a GRU is a Dense layer, return_sequences=False (or don't write anything because it is False as default) **BUT**, if you don't want to set it False, you need to add a GlobalAveragePooling1D layer to lower the dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TjZv7lr3_yz",
        "outputId": "91d88c91-385e-4943-9cbd-6d847cf0aab6"
      },
      "source": [
        "# Compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_3_GRU\")])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20211007-102717\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 14ms/step - loss: 0.5362 - accuracy: 0.7259 - val_loss: 0.4547 - val_accuracy: 0.7913\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3173 - accuracy: 0.8689 - val_loss: 0.5016 - val_accuracy: 0.7927\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.2189 - accuracy: 0.9188 - val_loss: 0.5325 - val_accuracy: 0.7822\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1605 - accuracy: 0.9426 - val_loss: 0.5812 - val_accuracy: 0.7835\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1198 - accuracy: 0.9610 - val_loss: 0.6795 - val_accuracy: 0.7703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_LVpMaP3_xN",
        "outputId": "464fc3c9-ccb0-457d-c37f-444a7c5dc4e7"
      },
      "source": [
        "# Make some predictions with our GRU model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.25605994],\n",
              "       [0.90098816],\n",
              "       [0.9986003 ],\n",
              "       [0.07926299],\n",
              "       [0.00769992],\n",
              "       [0.99643755],\n",
              "       [0.620371  ],\n",
              "       [0.99827266],\n",
              "       [0.9986731 ],\n",
              "       [0.37126163]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsIW8bku3_tk",
        "outputId": "2def6466-e079-40db-be21-5e7d50974db5"
      },
      "source": [
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK_Huw6x3_q8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "976d81a1-f647-4eff-832b-35c2921b47be"
      },
      "source": [
        "# Calculate model_3 results\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.03412073490814,\n",
              " 'f1': 0.7676409049388613,\n",
              " 'precision': 0.7732589791209112,\n",
              " 'recall': 0.7703412073490814}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFGIOVnMwzaK",
        "outputId": "de6a28b9-baf5-4b08-f269-c36e37dd6089"
      },
      "source": [
        "# Compare model_3 to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_3_results)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 77.03, Difference: -2.23\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-ejJM6g3_n0"
      },
      "source": [
        "### Model 4: Bidirectional RNN\n",
        "\n",
        "A standard RNN will process a sequence from left to right, where as a bidirectional RNN will process the sequence from left to right and then again from right to left.\n",
        "\n",
        "Intuitively, this can be thought of as if you were reading a sentence for the first time in the normal fashion (left to right) but for some reason it didn't make sense so you traverse back through the words and go back over them again (right to left).\n",
        "\n",
        "In practice, many sequence models often see an improvement in performance when using bidirectional RNN's.\n",
        "\n",
        "However, this improvement in performance often comes at the cost of longer training times and increased model parameters (since the model goes left to right and right to left, the number of trainable parameters doubles).\n",
        "\n",
        "We can use the `Bidirectional` class to wrap our existing RNNs, instantly making them bidirectional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvuvSu6kqmZx",
        "outputId": "fd0cda60-c329-428a-dfbf-398a938b2732"
      },
      "source": [
        "# Create an embedding layer for model_4\n",
        "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_4\")\n",
        "\n",
        "# Build a bidirectional RNN\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_4_embedding(x)\n",
        "print(x.shape)\n",
        "#x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "#print(x.shape)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
        "print(x.shape)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXNmOxNGyzjU"
      },
      "source": [
        "> üîë **Note:** You can use the `Bidirectional` wrapper on any RNN cell in TensorFlow. For example, `layers.Bidirectional(layers.GRU(64))` creates a bidirectional GRU cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUwwv0weqmXL",
        "outputId": "69ddab87-524a-4360-cb61-09c0dcc3d0a8"
      },
      "source": [
        "# Get a summary\n",
        "model_4.summary()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSAL8nsczD47"
      },
      "source": [
        "Notice the increased number of trainable parameters in `model_4` (bidirectional LSTM) compared to `model_2` (regular LSTM). This is due to the bidirectionality we added to our RNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qvVRhsMqmUn",
        "outputId": "f806985c-edb9-411e-91e8-abf18d92c6bf"
      },
      "source": [
        "# Compile the model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_4_bidirectional\")])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20211007-102732\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 21ms/step - loss: 0.5127 - accuracy: 0.7497 - val_loss: 0.4563 - val_accuracy: 0.7887\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.3070 - accuracy: 0.8759 - val_loss: 0.4687 - val_accuracy: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2033 - accuracy: 0.9285 - val_loss: 0.5409 - val_accuracy: 0.7717\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1380 - accuracy: 0.9526 - val_loss: 0.7430 - val_accuracy: 0.7533\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0981 - accuracy: 0.9656 - val_loss: 0.7541 - val_accuracy: 0.7612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSTYvZrRzHoy"
      },
      "source": [
        "Due to the bidirectionality of our model we see a slight increase in training time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HteoDbOIqmSI",
        "outputId": "7ed18fbb-51c5-499f-f25f-2574ac4c8e7c"
      },
      "source": [
        "# Make predictions with the bidirectional model\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.10345738],\n",
              "       [0.87129   ],\n",
              "       [0.9994141 ],\n",
              "       [0.03844122],\n",
              "       [0.02280842],\n",
              "       [0.99631953],\n",
              "       [0.98248786],\n",
              "       [0.9998838 ],\n",
              "       [0.9997061 ],\n",
              "       [0.12803969]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdDZlfqkqmPr",
        "outputId": "3f3a85bc-bf51-42b9-fe2e-8518d3690b74"
      },
      "source": [
        "# Convert pred to probs to pred labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVAPAlZCHlzi",
        "outputId": "85c04b3d-109e-407e-f226-16dc91fb409c"
      },
      "source": [
        "# Calculate the results of our bidirectional model\n",
        "model_4_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.11548556430446,\n",
              " 'f1': 0.7589888106092002,\n",
              " 'precision': 0.7625228137873495,\n",
              " 'recall': 0.7611548556430446}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yle-f6NdzLKK",
        "outputId": "0f3cc46d-c358-41ee-d5a9-af80d74f1c83"
      },
      "source": [
        "# Compare model_4 to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_4_results)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 76.12, Difference: -3.15\n",
            "Baseline precision: 0.81, New precision: 0.76, Difference: -0.05\n",
            "Baseline recall: 0.79, New recall: 0.76, Difference: -0.03\n",
            "Baseline f1: 0.79, New f1: 0.76, Difference: -0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXPx2_s1HlxM"
      },
      "source": [
        "## Convolutional Neural Networks for Text (and other types of sequences)\n",
        "\n",
        "You might've used convolutional neural networks (CNNs) for images before but they can also be used for sequences.\n",
        "\n",
        "The main difference between using CNNs for images and sequences is the shape of the data. Images come in 2-dimensions (height x width) where as sequences are often 1-dimensional (a string of text).\n",
        "\n",
        "So to use CNNs with sequences, we use a 1-dimensional convolution instead of a 2-dimensional convolution.\n",
        "\n",
        "The typical structure of a Conv1D model for sequences (in our case, text):\n",
        "\n",
        "```\n",
        "Inputs(text) -> Tokenization -> Embedding -> Layer(s) (typicallt Conv1D + pooling) -> Outputs (class probabilities)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1uVvdYfzoyh"
      },
      "source": [
        "Instead of using an LSTM or GRU cell, we're going to use a [`tensorflow.keras.layers.Conv1D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D) layer followed by a [`tensorflow.keras.layers.GlobablMaxPool1D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool1D) layer.\n",
        "\n",
        "> üìñ **Resource:** The intuition here is explained succinctly in the paper [*Understanding Convolutional Neural Networks for Text Classification*](https://www.aclweb.org/anthology/W18-5408.pdf), where they state that CNNs classify text through the following steps:\n",
        "1. 1-dimensional convolving filters are used as ngram detectors, each filter specializing in a closely-related family of ngrams (an ngram is a collection of n-words, for example, an ngram of 5 might result in \"hello, my name is Daniel\").\n",
        "2. Max-pooling over time extracts the relevant ngrams for making a decision.\n",
        "3. The rest of the network classifies the text based on this information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXtBgzuoHlui"
      },
      "source": [
        "## Model 5: Conv1D\n",
        "\n",
        "Before we build a full 1-dimensional CNN model, let's see a 1-dimensional convolutional layer (also called a **temporal convolution**) in action.\n",
        "\n",
        "We'll first create an embedding of a sample of text and experiment passing it through a `Conv1D()` layer and `GlobalMaxPool1D()` layer.\n",
        "\n",
        "Difference between same and valid padding: https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEnCoSE3Hlrs",
        "outputId": "e617b98b-630b-4c59-e60f-33eacbe0317a"
      },
      "source": [
        "#Create a new embedding layer and test out our Conv1D layer and max pooling\n",
        "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_5\")\n",
        "embedding_test = model_5_embedding(text_vectorizer([\"this is a test sentence\"]))\n",
        "conv_1d = layers.Conv1D(filters=32,\n",
        "                        kernel_size=5, # this is also referred to as an ngram of 5 (meaning it looks at 5 words at a time)\n",
        "                        strides=1, # default\n",
        "                        activation=\"relu\",\n",
        "                        padding=\"same\") #default is \"valid\", the output is smaller than the input shape, \"same\" means output is same\n",
        "conv_1d_output = conv_1d(embedding_test)\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output)\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 15, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUrhqixx0heW"
      },
      "source": [
        "Notice the output shapes of each layer.\n",
        "\n",
        "The embedding has an output shape dimension of the parameters we set it to (`input_length=15` and `output_dim=128`).\n",
        "\n",
        "The 1-dimensional convolutional layer has an output which has been compressed inline with its parameters. And the same goes for the max pooling layer output.\n",
        "\n",
        "Our text starts out as a string but gets converted to a feature vector of length 64 through various transformation steps (from tokenization to embedding to 1-dimensional convolution to max pool)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiRkxC8I33yc",
        "outputId": "1194f046-f01d-4f44-c5ef-e5772d7e12f8"
      },
      "source": [
        "embedding_test"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.0248079 , -0.0240456 ,  0.04465637, ...,  0.03560349,\n",
              "          0.01478291,  0.00075731],\n",
              "        [ 0.03398827, -0.04663584,  0.03603191, ..., -0.02147592,\n",
              "          0.01610745, -0.04382626],\n",
              "        [ 0.0094725 , -0.03847247,  0.03114759, ..., -0.03846492,\n",
              "          0.03844212,  0.01524312],\n",
              "        ...,\n",
              "        [-0.04060654,  0.00975567,  0.02875781, ...,  0.00677701,\n",
              "         -0.03042984,  0.0036012 ],\n",
              "        [-0.04060654,  0.00975567,  0.02875781, ...,  0.00677701,\n",
              "         -0.03042984,  0.0036012 ],\n",
              "        [-0.04060654,  0.00975567,  0.02875781, ...,  0.00677701,\n",
              "         -0.03042984,  0.0036012 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMH8FOff33wT",
        "outputId": "d0d1bdfe-f950-48f6-b454-c91ac5ee147b"
      },
      "source": [
        "conv_1d_output"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 32), dtype=float32, numpy=\n",
              "array([[[0.03095288, 0.        , 0.02258864, 0.01767981, 0.        ,\n",
              "         0.0165756 , 0.02414563, 0.        , 0.00471737, 0.01889767,\n",
              "         0.00057479, 0.00272519, 0.01032129, 0.        , 0.00515742,\n",
              "         0.        , 0.05588775, 0.        , 0.05683159, 0.        ,\n",
              "         0.00127766, 0.00069335, 0.06880899, 0.00514026, 0.01633281,\n",
              "         0.02667199, 0.        , 0.01130369, 0.01890977, 0.        ,\n",
              "         0.        , 0.01044305],\n",
              "        [0.        , 0.07054903, 0.        , 0.        , 0.        ,\n",
              "         0.06805822, 0.00064386, 0.        , 0.01075475, 0.        ,\n",
              "         0.02679862, 0.        , 0.        , 0.        , 0.04665826,\n",
              "         0.        , 0.        , 0.01515817, 0.        , 0.01940743,\n",
              "         0.04202352, 0.        , 0.00918078, 0.03937028, 0.        ,\n",
              "         0.05340003, 0.        , 0.00791318, 0.02790812, 0.        ,\n",
              "         0.        , 0.05429716],\n",
              "        [0.00391258, 0.        , 0.        , 0.        , 0.01962786,\n",
              "         0.        , 0.02223334, 0.        , 0.        , 0.        ,\n",
              "         0.05217432, 0.01423147, 0.00778961, 0.        , 0.        ,\n",
              "         0.02885417, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.00175401, 0.00340752, 0.        , 0.        ,\n",
              "         0.01978167, 0.05556371, 0.        , 0.        , 0.        ,\n",
              "         0.00444666, 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.0439317 , 0.00250269, 0.        ,\n",
              "         0.04048492, 0.        , 0.        , 0.05565118, 0.00325084,\n",
              "         0.        , 0.05673225, 0.        , 0.        , 0.1180964 ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.00894712, 0.        , 0.        , 0.        ,\n",
              "         0.06704469, 0.05059876],\n",
              "        [0.02577727, 0.        , 0.03876526, 0.        , 0.        ,\n",
              "         0.01788668, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.04422598, 0.        , 0.02337346, 0.        , 0.        ,\n",
              "         0.01922081, 0.09537452, 0.04007161, 0.        , 0.04664637,\n",
              "         0.00473767, 0.05592106, 0.        , 0.        , 0.02133248,\n",
              "         0.02966998, 0.        , 0.        , 0.        , 0.00305123,\n",
              "         0.05109838, 0.04970846],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.02361119, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.0134781 , 0.        , 0.        , 0.05130644, 0.        ,\n",
              "         0.        , 0.04243805, 0.        , 0.        , 0.03838069,\n",
              "         0.        , 0.        , 0.        , 0.0020408 , 0.0413751 ,\n",
              "         0.        , 0.        , 0.        , 0.02467667, 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.01665963, 0.        , 0.03516523, 0.        , 0.02006902,\n",
              "         0.02030271, 0.        , 0.        , 0.        , 0.01731236,\n",
              "         0.01507293, 0.        , 0.        , 0.0463589 , 0.        ,\n",
              "         0.        , 0.08852364, 0.01424398, 0.        , 0.06377141,\n",
              "         0.        , 0.        , 0.        , 0.01465992, 0.03718399,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.00024579, 0.        ],\n",
              "        [0.00152815, 0.        , 0.03705523, 0.        , 0.01065779,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.0357855 ,\n",
              "         0.03362681, 0.        , 0.        , 0.04903224, 0.        ,\n",
              "         0.        , 0.08444728, 0.03361557, 0.        , 0.07964209,\n",
              "         0.        , 0.        , 0.        , 0.00203   , 0.02912009,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.01365745, 0.        ],\n",
              "        [0.00152815, 0.        , 0.03705524, 0.        , 0.0106578 ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.03578551,\n",
              "         0.03362681, 0.        , 0.        , 0.04903224, 0.        ,\n",
              "         0.        , 0.08444728, 0.03361558, 0.        , 0.07964209,\n",
              "         0.        , 0.        , 0.        , 0.00202999, 0.02912009,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.01365745, 0.        ],\n",
              "        [0.00152814, 0.        , 0.03705523, 0.        , 0.0106578 ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.0357855 ,\n",
              "         0.03362681, 0.        , 0.        , 0.04903223, 0.        ,\n",
              "         0.        , 0.08444728, 0.03361558, 0.        , 0.07964209,\n",
              "         0.        , 0.        , 0.        , 0.00203   , 0.02912009,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.01365745, 0.        ],\n",
              "        [0.00152814, 0.        , 0.03705524, 0.        , 0.0106578 ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.03578551,\n",
              "         0.03362681, 0.        , 0.        , 0.04903223, 0.        ,\n",
              "         0.        , 0.08444728, 0.03361557, 0.        , 0.07964209,\n",
              "         0.        , 0.        , 0.        , 0.00203   , 0.02912009,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.01365745, 0.        ],\n",
              "        [0.00152815, 0.        , 0.03705523, 0.        , 0.01065779,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.03578551,\n",
              "         0.03362682, 0.        , 0.        , 0.04903224, 0.        ,\n",
              "         0.        , 0.08444729, 0.03361557, 0.        , 0.0796421 ,\n",
              "         0.        , 0.        , 0.        , 0.00202999, 0.02912009,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.01365745, 0.        ],\n",
              "        [0.00152814, 0.        , 0.03705523, 0.        , 0.0106578 ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.0357855 ,\n",
              "         0.03362681, 0.        , 0.        , 0.04903223, 0.        ,\n",
              "         0.        , 0.08444728, 0.03361558, 0.        , 0.0796421 ,\n",
              "         0.        , 0.        , 0.        , 0.00202999, 0.02912009,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.01365746, 0.        ],\n",
              "        [0.00777636, 0.        , 0.03597424, 0.        , 0.00858139,\n",
              "         0.        , 0.        , 0.        , 0.01005189, 0.04505733,\n",
              "         0.01575566, 0.01488623, 0.        , 0.03768707, 0.        ,\n",
              "         0.        , 0.07347139, 0.03242899, 0.        , 0.05169069,\n",
              "         0.00181605, 0.        , 0.        , 0.        , 0.02257027,\n",
              "         0.        , 0.        , 0.03256953, 0.        , 0.        ,\n",
              "         0.00145198, 0.        ],\n",
              "        [0.        , 0.02777113, 0.01414602, 0.        , 0.00710513,\n",
              "         0.        , 0.        , 0.        , 0.02734164, 0.05873045,\n",
              "         0.01002512, 0.01321408, 0.        , 0.03724828, 0.        ,\n",
              "         0.        , 0.03939611, 0.01284614, 0.        , 0.05367471,\n",
              "         0.        , 0.        , 0.        , 0.02169569, 0.01700883,\n",
              "         0.        , 0.        , 0.03635087, 0.00369508, 0.        ,\n",
              "         0.00808784, 0.        ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sshhnKyf33tW",
        "outputId": "fa50aed9-4e08-42cc-8dc6-b8778f7c6d34"
      },
      "source": [
        "max_pool_output"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              "array([[0.03095288, 0.07054903, 0.03876526, 0.01767981, 0.02006902,\n",
              "        0.06805822, 0.02414563, 0.0439317 , 0.02734164, 0.05873045,\n",
              "        0.05217432, 0.01488623, 0.02337346, 0.05565118, 0.04665826,\n",
              "        0.02885417, 0.09537452, 0.04007161, 0.05683159, 0.1180964 ,\n",
              "        0.04202352, 0.05592106, 0.06880899, 0.03937028, 0.0413751 ,\n",
              "        0.05340003, 0.05556371, 0.03635087, 0.02790812, 0.00305123,\n",
              "        0.06704469, 0.05429716]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TtlDbAO33q6",
        "outputId": "715a9621-3b8d-49f4-9d59-f1ddfb7a2d66"
      },
      "source": [
        "# Create 1-dimensional convolutional layer to sequences\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_5_embedding(x)\n",
        "x = layers.Conv1D(filters=64,\n",
        "                  kernel_size=5,\n",
        "                  strides=1,\n",
        "                  activation=\"relu\",\n",
        "                  padding=\"valid\",\n",
        "                  )(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_conv1D\")\n",
        "\n",
        "# Compile the model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary of the model\n",
        "model_5.summary()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_conv1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 11, 64)            41024     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGwd0rkO33oG",
        "outputId": "07aaf2ab-c832-414f-bb76-96dffad81a34"
      },
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"Conv1D\")])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20211007-102818\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 11ms/step - loss: 0.5474 - accuracy: 0.7218 - val_loss: 0.4722 - val_accuracy: 0.7730\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.3310 - accuracy: 0.8608 - val_loss: 0.4846 - val_accuracy: 0.7874\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.2024 - accuracy: 0.9242 - val_loss: 0.5452 - val_accuracy: 0.8005\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.1268 - accuracy: 0.9574 - val_loss: 0.6204 - val_accuracy: 0.7835\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0909 - accuracy: 0.9714 - val_loss: 0.6954 - val_accuracy: 0.7795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGlS5Eba4cC2",
        "outputId": "d8200f6f-4d25-4527-cf36-2c78369a56d6"
      },
      "source": [
        "# Make some predictions with our model_5\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7560621 ],\n",
              "       [0.98287416],\n",
              "       [0.9998497 ],\n",
              "       [0.05732524],\n",
              "       [0.00674937],\n",
              "       [0.9987935 ],\n",
              "       [0.8624532 ],\n",
              "       [0.99908936],\n",
              "       [0.9992617 ],\n",
              "       [0.09233704]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWkQ9HlW4b_p",
        "outputId": "6ab99e18-8642-4529-8ea3-c487e0eb13ef"
      },
      "source": [
        "# Convert model 5 pred probs to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWUGhvnX4b9D",
        "outputId": "3865e202-799f-4800-982b-f9e5d6e20a78"
      },
      "source": [
        "# Evaluate model 5 predictions\n",
        "model_5_results = calculate_results(y_true=val_labels, y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.95275590551181,\n",
              " 'f1': 0.7778858484546237,\n",
              " 'precision': 0.780644760213944,\n",
              " 'recall': 0.7795275590551181}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAjl4Cvo4b6V"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6OX-6YKl34A"
      },
      "source": [
        "## Using Pretrained Embeddings (transfer learning for NLP)\n",
        "\n",
        "For all of the previous deep learning models we've built and trained, we've created and used our own embeddings from scratch each time.\n",
        "\n",
        "However, a common practice is to leverage pretrained embeddings through **transfer learning**. This is one of the main benefits of using deep models: being able to take what one (often larger) model has learned (often on a large amount of data) and adjust it for our own use case.\n",
        "\n",
        "For our next model, instead of using our own embedding layer, we're going to replace it with a pretrained embedding layer.\n",
        "\n",
        "More specifically, we're going to be using the [Universal Sentence Encoder](https://www.aclweb.org/anthology/D18-2029.pdf) from [TensorFlow Hub](https://tfhub.dev/google/universal-sentence-encoder/4) (a great resource containing a plethora of pretrained model resources for a variety of tasks).\n",
        "\n",
        "> üîë **Note:** There are many different pretrained text embedding options on TensorFlow Hub, however, some require different levels of text preprocessing than others. Best to experiment with a few and see which best suits your use case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE2mr9bE_q2N"
      },
      "source": [
        "### Model 6: TensorFlow Hub Pretrained\n",
        "\n",
        "The main difference between the embedding layer we created and the Universal Sentence Encoder is that rather than create a word-level embedding, the Universal Sentence Encoder, as you might've guessed, creates a whole sentence-level embedding.\n",
        "\n",
        "Our embedding layer also outputs an a 128 dimensional vector for each word, where as, the Universal Sentence Encoder outputs a 512 dimensional vector for each sentence.\n",
        "\n",
        "> üîë **Note:** An **encoder** is the name for a model which converts raw data such as text into a numerical representation (feature vector), a **decoder** converts the numerical representation to a desired output.\n",
        "\n",
        "As usual, this is best demonstrated with an example.\n",
        "\n",
        "We can load in a TensorFlow Hub module using the [`hub.load()`](https://www.tensorflow.org/hub/api_docs/python/hub/load) method and passing it the target URL of the module we'd like to use, in our case, it's \"https://tfhub.dev/google/universal-sentence-encoder/4\".\n",
        "\n",
        "See how the USE was created here: https://arxiv.org/abs/1803.11175"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B05ik_m5UBwd",
        "outputId": "e946936c-0631-4fe4-ffc9-f572f8759ed9"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embed_samples = embed([sample_sentence,\n",
        "                       \"It is a sunny day but it might rain because we're living in England.\"])\n",
        "print(embed_samples[0][:50])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.03135942  0.00142239 -0.04809404  0.03051625  0.04949753  0.04206576\n",
            " -0.03197383  0.05812307  0.0120583   0.00367716 -0.01755392 -0.0676587\n",
            " -0.01695304  0.0718725  -0.10142155 -0.07390498 -0.02666863 -0.08618097\n",
            "  0.0033888  -0.02867646 -0.04432268  0.07022828 -0.01315258  0.00421487\n",
            "  0.06941666 -0.05387218  0.00486859 -0.04040928  0.03439252 -0.03427697\n",
            " -0.00278216  0.007595    0.08395509  0.0532172   0.08576487 -0.02394373\n",
            "  0.03180566  0.0513415  -0.02769209 -0.07493935  0.03671759  0.06041233\n",
            "  0.00197253  0.00279636 -0.01979633  0.02043864 -0.0175446   0.01333233\n",
            "  0.03749461 -0.08482482], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Bb_UqzOAUCkf",
        "outputId": "771ac91e-e325-4c1f-f408-2b5eefabbd37"
      },
      "source": [
        "sample_sentence"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"There's a mug on the table!\""
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP2B2NklUChp",
        "outputId": "fcd5da85-9626-470b-9629-ca73eb0da922"
      },
      "source": [
        "embed_samples"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 512), dtype=float32, numpy=\n",
              "array([[-0.03135942,  0.00142239, -0.04809404, ..., -0.02170624,\n",
              "        -0.01013064, -0.04518037],\n",
              "       [ 0.01969091, -0.01172204,  0.01516426, ...,  0.00428086,\n",
              "         0.00570428,  0.0076076 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liNXOsNMUCfI"
      },
      "source": [
        "# Create a Keras Layer using the USE pretrained layer from tensorflow hub (We can use this encoding layer in place of our text_vectorizer and embedding layer)\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # shape of inputs coming to our model \n",
        "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
        "                                        name=\"USE\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6gS6p1DUCcJ"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer,\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "# Compile\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A22Ij6YqUCaS",
        "outputId": "c33a646d-04bf-4586-ae40-a2127e11dfd8"
      },
      "source": [
        "model_6.summary()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "model_6_USE (Dense)          (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkFAQspbvfqS"
      },
      "source": [
        "The trainable parameters are only in our output layers, in other words, we're keeping the USE weights frozen and using it as a feature-extractor. We could fine-tune these weights by setting `trainable=True` when creating the `hub.KerasLayer` instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXVfBfTeUCWo",
        "outputId": "2d9a360d-752b-43c2-805d-662ee70c5ed4"
      },
      "source": [
        "# Train a clasifier on top of USE pretrained embeddings\n",
        "model_6_histroy = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"tf_hub_sentence_encoder\")])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 25ms/step - loss: 0.5058 - accuracy: 0.7771 - val_loss: 0.4560 - val_accuracy: 0.7979\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 22ms/step - loss: 0.4148 - accuracy: 0.8145 - val_loss: 0.4426 - val_accuracy: 0.8084\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 22ms/step - loss: 0.4000 - accuracy: 0.8234 - val_loss: 0.4320 - val_accuracy: 0.8123\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 5s 22ms/step - loss: 0.3921 - accuracy: 0.8253 - val_loss: 0.4373 - val_accuracy: 0.8110\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 5s 22ms/step - loss: 0.3841 - accuracy: 0.8311 - val_loss: 0.4280 - val_accuracy: 0.8136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZMJ_LhSUCT2",
        "outputId": "1e730ce7-af63-44aa-91a4-b5564b905b6b"
      },
      "source": [
        "# Make predictions with USE TF Hub Model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.19048762],\n",
              "       [0.7817213 ],\n",
              "       [0.9937733 ],\n",
              "       [0.2364839 ],\n",
              "       [0.7112599 ],\n",
              "       [0.7290034 ],\n",
              "       [0.986503  ],\n",
              "       [0.9821393 ],\n",
              "       [0.95714974],\n",
              "       [0.08604567]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk4HtQhcUCSG",
        "outputId": "83cd7227-8fbf-44f8-c3f3-c2c3e78fd120"
      },
      "source": [
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWfRRx_vUCOB",
        "outputId": "b22ac9a8-a760-4efd-8239-2f8b0401cbd9"
      },
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_6_preds)\n",
        "model_6_results"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.62729658792651,\n",
              " 'f1': 0.8143941941176969,\n",
              " 'precision': 0.8197988627231594,\n",
              " 'recall': 0.8162729658792651}"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdgFVd0PUCLb",
        "outputId": "01a0d35b-dd5a-419a-bfb5-b10974db93da"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvZg5EwxZfUS",
        "outputId": "78393075-3323-4ffa-9718-d2311e699549"
      },
      "source": [
        "len(train_sentences)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6851"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYT1SAVicfUe"
      },
      "source": [
        "### Model 7: TF Hub Pretrained Sentence Encoder USE but with 10% of training data\n",
        "\n",
        "Transfer learning really helps when you don't have a large dataset.\n",
        "\n",
        "To see how our model performs on a smaller dataset, let's replicate model_6 except we'll train it on 10% of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbZAsh06cfQu"
      },
      "source": [
        "## NOTE: Making data splits like below leads to data leakage (model_7 trained on 10% data, outperformos model_6 trained 100% data)\n",
        "## DO NOT MAKE DATA SPLITS WHICH LEAK DATA FROM VALIDATION/TEST SETS INTO TRAINING SET\n",
        "# Create subsets of 10% of the training data\n",
        "#train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
        "#train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
        "#train_labels_10_percent = train_10_percent[\"target\"].to_list()"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTpcCq6OobPv"
      },
      "source": [
        "# Making a better dataset split (no data leakage)\n",
        "train_10_percent_split = int(0.1*len(train_sentences))\n",
        "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent = train_labels[:train_10_percent_split]"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTPGJdW0obUX",
        "outputId": "e4faffaa-54b2-400c-a4f3-1e0d079b61f1"
      },
      "source": [
        "pd.Series(np.array(train_labels_10_percent)).value_counts()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    406\n",
              "1    279\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miqfFzMQcfOI",
        "outputId": "c0ee40a1-9b42-4bc1-b21a-b3e44e66a76b"
      },
      "source": [
        "# Check the number of targets in our subset of data\n",
        "train_10_percent[\"target\"].value_counts()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    413\n",
              "1    348\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuA_jTCocfLP",
        "outputId": "8aa6c718-038f-4416-c57f-a4450a3f26dc"
      },
      "source": [
        "train_df_shuffled[\"target\"].value_counts()"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOmq_hYhhK5L",
        "outputId": "a57fa33b-491c-4e73-ded3-349b47eaf296"
      },
      "source": [
        "# Let's build a model the same as model_6\n",
        "# model_7 = tf.keras.models.clone_model(model_6)\n",
        "model_7 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer,\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_7_USE_10_percent\")\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary\n",
        "model_7.summary()"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7_USE_10_percent\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw_S2FYyhK2n",
        "outputId": "b4607d92-8524-4c5a-9be9-d8cc51e15a1e"
      },
      "source": [
        "# Fit the model to the 10% training data subset\n",
        "model_7_histroy = model_7.fit(train_sentences_10_percent,\n",
        "                              train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"tf_hub_sentence_encoder_10_percent\")])"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_10_percent/20211007-120308\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 4s 113ms/step - loss: 0.6781 - accuracy: 0.6467 - val_loss: 0.6548 - val_accuracy: 0.7362\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 48ms/step - loss: 0.6140 - accuracy: 0.7956 - val_loss: 0.6035 - val_accuracy: 0.7467\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.5391 - accuracy: 0.8102 - val_loss: 0.5449 - val_accuracy: 0.7664\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.4739 - accuracy: 0.8234 - val_loss: 0.5071 - val_accuracy: 0.7651\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 1s 48ms/step - loss: 0.4301 - accuracy: 0.8277 - val_loss: 0.4902 - val_accuracy: 0.7690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4umDVSjvhK0b",
        "outputId": "abfbcf58-ab8e-4b60-fefa-78815d4a2566"
      },
      "source": [
        "# Make predictions with the model trained on 10% of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.23276465],\n",
              "       [0.575922  ],\n",
              "       [0.9235357 ],\n",
              "       [0.37949878],\n",
              "       [0.50372684],\n",
              "       [0.69539726],\n",
              "       [0.8872192 ],\n",
              "       [0.8141561 ],\n",
              "       [0.85962194],\n",
              "       [0.17460442]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1llaETHhKxs",
        "outputId": "f211b0b9-403f-4bec-8610-0dc365e483c8"
      },
      "source": [
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JicV8wsxhKux",
        "outputId": "ad7320a1-c317-4b7b-8234-1466a70c9493"
      },
      "source": [
        "# Evaluate model_7 predictions\n",
        "model_7_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_7_preds)\n",
        "model_7_results"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.9028871391076,\n",
              " 'f1': 0.7671875324347506,\n",
              " 'precision': 0.7701356893081864,\n",
              " 'recall': 0.7690288713910761}"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "layWU2oNyhKA"
      },
      "source": [
        "# Compare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_7_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-f24p9NhKpd"
      },
      "source": [
        "## Comparing the performance of each of our models\n",
        "\n",
        "it's worthwhile mentioning, this type of practice is a standard deep learning workflow. Training various different models, then comparing them to see which one performed best and continuing to train it if necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N7gu7I2hKnA"
      },
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"0_baseline\": baseline_results,\n",
        "                                  \"1_simple_dense\": model_1_results,\n",
        "                                  \"2_lstm\": model_2_results,\n",
        "                                  \"3_gru\": model_3_results,\n",
        "                                  \"4_bidirectional\": model_4_results,\n",
        "                                  \"5_conv1d\": model_5_results,\n",
        "                                  \"6_tf_hub_use_encoder\": model_6_results,\n",
        "                                  \"7_tf_hub_use_encoder_10_percent\": model_7_results})\n",
        "all_model_results = all_model_results.transpose()"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "sZF6PBHMhKkG",
        "outputId": "022ec780-9682-42d2-e12e-94a48f6e0066"
      },
      "source": [
        "# Reduce the accuracy to the same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n",
        "all_model_results"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>0.787402</td>\n",
              "      <td>0.791897</td>\n",
              "      <td>0.787402</td>\n",
              "      <td>0.784556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_lstm</th>\n",
              "      <td>0.757218</td>\n",
              "      <td>0.759673</td>\n",
              "      <td>0.757218</td>\n",
              "      <td>0.754363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_gru</th>\n",
              "      <td>0.770341</td>\n",
              "      <td>0.773259</td>\n",
              "      <td>0.770341</td>\n",
              "      <td>0.767641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_bidirectional</th>\n",
              "      <td>0.761155</td>\n",
              "      <td>0.762523</td>\n",
              "      <td>0.761155</td>\n",
              "      <td>0.758989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_conv1d</th>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.780645</td>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.777886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_tf_hub_use_encoder</th>\n",
              "      <td>0.816273</td>\n",
              "      <td>0.819799</td>\n",
              "      <td>0.816273</td>\n",
              "      <td>0.814394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
              "      <td>0.769029</td>\n",
              "      <td>0.770136</td>\n",
              "      <td>0.769029</td>\n",
              "      <td>0.767188</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 accuracy  precision    recall        f1\n",
              "0_baseline                       0.792651   0.811139  0.792651  0.786219\n",
              "1_simple_dense                   0.787402   0.791897  0.787402  0.784556\n",
              "2_lstm                           0.757218   0.759673  0.757218  0.754363\n",
              "3_gru                            0.770341   0.773259  0.770341  0.767641\n",
              "4_bidirectional                  0.761155   0.762523  0.761155  0.758989\n",
              "5_conv1d                         0.779528   0.780645  0.779528  0.777886\n",
              "6_tf_hub_use_encoder             0.816273   0.819799  0.816273  0.814394\n",
              "7_tf_hub_use_encoder_10_percent  0.769029   0.770136  0.769029  0.767188"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "kQPj2ctwsDbT",
        "outputId": "2530f243-846a-4886-aef9-4644e34fb34d"
      },
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10,7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "AHywySCosDY-",
        "outputId": "6bebd313-a447-4fc0-8036-b1d296e64a13"
      },
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10,7));"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnG2tO5FsDWj"
      },
      "source": [
        "## Uploading our model training logs to TensorBoard.dev"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZBPHR_wsDT1"
      },
      "source": [
        "# View TensorBoard logs of transfer learning modellin experiments (plus all of our other models)\n",
        "# Upload TensorBoard.dev records\n",
        "!tensorboard dev upload --logdir ./model_logs/ \\\n",
        "  --name \"NLP Modelling Experiments\" \\\n",
        "  --description \"Comparing multiple different types of model architectures on the Kaggle Tweet text classification dataset\" \\\n",
        "  --one_shot # exit the uploader once uploading is done"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZE4Y3UX3GnA"
      },
      "source": [
        "Now I've ran the cell above, my modelling experiments are visable on TensorBoard.dev: https://tensorboard.dev/experiment/5ZYTKoZvTOKLcprYYBSn0w/\n",
        "\n",
        "> üìñ **Resource:** TensorBoard is great for quickly tracking experiments but for larger scale experiments and a whole bunvh more tracking options, check out Weights & Biases: https://wandb.ai/site"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIbEj5BZsDRY"
      },
      "source": [
        "# If you need to remove previous experiments, you can do so using the following command\n",
        "# !tensorboard dev delete --experiment_id EXPERIMENT_ID_TO_DELETE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZaZEBmTCJYL"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2OYK6LF5qKC"
      },
      "source": [
        "## Finding the most wrong examples\n",
        "\n",
        "- If our best model still isn't perfect, what examples is it getting wrong?\n",
        "- And of these wrong examples which ones is it getting *most* wrong (those will prediction probabilities closes to the opposite class)\n",
        "\n",
        "For example if a sample should have a label of 0 but our model predicts a prediction probability of 0.999 (really close to 1) and vica versa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjLgEAbD-Oid",
        "outputId": "c6bb88fb-d519-4715-a064-7e17d45f3c30"
      },
      "source": [
        "# Download a pretrained model from Google Storage\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
        "!unzip 08_model_6_USE_feature_extractor.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-07 21:24:13--  https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.137.128, 142.250.101.128, 142.250.141.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.137.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 960779165 (916M) [application/zip]\n",
            "Saving to: ‚Äò08_model_6_USE_feature_extractor.zip‚Äô\n",
            "\n",
            "08_model_6_USE_feat 100%[===================>] 916.27M   121MB/s    in 8.2s    \n",
            "\n",
            "2021-10-07 21:24:22 (111 MB/s) - ‚Äò08_model_6_USE_feature_extractor.zip‚Äô saved [960779165/960779165]\n",
            "\n",
            "Archive:  08_model_6_USE_feature_extractor.zip\n",
            "   creating: 08_model_6_USE_feature_extractor/\n",
            "   creating: 08_model_6_USE_feature_extractor/assets/\n",
            "   creating: 08_model_6_USE_feature_extractor/variables/\n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.data-00000-of-00001  \n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.index  \n",
            "  inflating: 08_model_6_USE_feature_extractor/saved_model.pb  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "862MaFPz5qHo",
        "outputId": "6e4b631d-437c-43c1-f684-eb9f1f438468"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "# Import previously trained model from Google Storage\n",
        "model_6_pretrained = tf.keras.models.load_model(\"08_model_6_USE_feature_extractor\")\n",
        "model_6_pretrained.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
            "24/24 [==============================] - 1s 9ms/step - loss: 0.4272 - accuracy: 0.8163\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42723122239112854, 0.8162729740142822]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o4T_Ko_9-XF",
        "outputId": "02590472-f1ed-42d0-c210-30b602c01a35"
      },
      "source": [
        "# Make predictions with the loaded model from GS\n",
        "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences)\n",
        "model_6_pretrained_preds = tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n",
        "model_6_pretrained_preds[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "lCpBd00e5qFF",
        "outputId": "e1f4c631-53cc-426c-af90-f0be60ea24b0"
      },
      "source": [
        "# Create DataFrame with validation sentences, validation labels and best performing model predictions + probabilities\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": val_labels,\n",
        "                       \"pred\": model_6_pretrained_preds,\n",
        "                       \"pred_prob\": tf.squeeze(model_6_pretrained_pred_probs)})\n",
        "val_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.159757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.747162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.196229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.707808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.159757\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.747162\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.988749\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0   0.196229\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.707808"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "--IOHhSM5qCl",
        "outputId": "9cca8c26-cc11-4ea5-9efc-a3c16b0961c0"
      },
      "source": [
        "# Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
        "most_wrong[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.876982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.852300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: Australia¬â√õ¬™s collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.835454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.827213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.814816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.810840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.803122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>@freefromwolves GodsLove &amp;amp; #thankU brother...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>Air Group is here to the rescue! We have 24/7 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   0.910196\n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   0.876982\n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   0.852300\n",
              "209  Ashes 2015: Australia¬â√õ¬™s collapse at Trent Br...       0   1.0   0.835454\n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   0.827213\n",
              "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   0.814816\n",
              "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   0.810840\n",
              "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   0.803122\n",
              "119  @freefromwolves GodsLove &amp; #thankU brother...       0   1.0   0.766901\n",
              "344  Air Group is here to the rescue! We have 24/7 ...       0   1.0   0.766625"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "Xjj0PGo2EnIU",
        "outputId": "73c62dd1-0f80-42f7-9567-a0925779ce18"
      },
      "source": [
        "most_wrong.tail()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>I get to smoke my shit in peace</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Why are you deluged with low self-image? Take ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>Reddit Will Now Quarantine¬â√õ_ http://t.co/pkUA...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   0.043918\n",
              "233                    I get to smoke my shit in peace       1   0.0   0.042087\n",
              "38   Why are you deluged with low self-image? Take ...       1   0.0   0.038998\n",
              "244  Reddit Will Now Quarantine¬â√õ_ http://t.co/pkUA...       1   0.0   0.038949\n",
              "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   0.037186"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB2eA_QJEdBn"
      },
      "source": [
        "Target labels:\n",
        "- `0` = not disaster\n",
        "- `1` = disaster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef4OZSHL5qAE",
        "outputId": "1c8679bf-9021-4173-fb09-2cf7d68b8c04"
      },
      "source": [
        " # Check the false positives (model predicted 1 when should've been 0)\n",
        " for row in most_wrong[:10].itertuples():\n",
        "   _, text, target, pred, pred_prob = row\n",
        "   print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "   print(f\"Text:\\n{text}\\n\")\n",
        "   print(\"-----\\n\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0, Pred: 1.0, Prob: 0.9101957082748413\n",
            "Text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8769820928573608\n",
            "Text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8523001670837402\n",
            "Text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8354544639587402\n",
            "Text:\n",
            "Ashes 2015: Australia¬â√õ¬™s collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8272132873535156\n",
            "Text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.814815878868103\n",
            "Text:\n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8108397126197815\n",
            "Text:\n",
            "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8031218647956848\n",
            "Text:\n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7669006586074829\n",
            "Text:\n",
            "@freefromwolves GodsLove &amp; #thankU brother Danny for RT of NEW VIDEO http://t.co/cybKsXHF7d The Coming Apocalyptic US Earthquake &amp; Tsunami\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.766624927520752\n",
            "Text:\n",
            "Air Group is here to the rescue! We have 24/7 Emergency Service! Learn more about it here - http://t.co/9lyx7zMtHE http://t.co/5PbC96rTMJ\n",
            "\n",
            "-----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xAzcmirE8Xx",
        "outputId": "09633846-bc82-4510-87a1-3975d24dd973"
      },
      "source": [
        " # Check the false negatives (model predicted 1 when should've been 0)\n",
        " for row in most_wrong[-10:].itertuples():\n",
        "   _, text, target, pred, pred_prob = row\n",
        "   print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "   print(f\"Text:\\n{text}\\n\")\n",
        "   print(\"-----\\n\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1, Pred: 0.0, Prob: 0.06730344146490097\n",
            "Text:\n",
            "@DavidVonderhaar At least you were sincere ??\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.05507584288716316\n",
            "Text:\n",
            "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.05460337549448013\n",
            "Text:\n",
            "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.05459698289632797\n",
            "Text:\n",
            "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.04963727295398712\n",
            "Text:\n",
            "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.043918490409851074\n",
            "Text:\n",
            "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.04208682104945183\n",
            "Text:\n",
            "I get to smoke my shit in peace\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.03899793699383736\n",
            "Text:\n",
            "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.03894945606589317\n",
            "Text:\n",
            "Reddit Will Now Quarantine¬â√õ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.03718579187989235\n",
            "Text:\n",
            "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
            "\n",
            "-----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "oXGkHemvE8Uy",
        "outputId": "356d89a8-a20a-4617-99f4-8e052a15c741"
      },
      "source": [
        "test_df"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>EARTHQUAKE SAFETY LOS ANGELES ¬â√õ√í SAFETY FASTE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows √ó 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id keyword location                                               text\n",
              "0         0     NaN      NaN                 Just happened a terrible car crash\n",
              "1         2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2         3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3         9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4        11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n",
              "...     ...     ...      ...                                                ...\n",
              "3258  10861     NaN      NaN  EARTHQUAKE SAFETY LOS ANGELES ¬â√õ√í SAFETY FASTE...\n",
              "3259  10865     NaN      NaN  Storm in RI worse than last hurricane. My city...\n",
              "3260  10868     NaN      NaN  Green Line derailment in Chicago http://t.co/U...\n",
              "3261  10874     NaN      NaN  MEG issues Hazardous Weather Outlook (HWO) htt...\n",
              "3262  10875     NaN      NaN  #CityofCalgary has activated its Municipal Eme...\n",
              "\n",
              "[3263 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVpB8gFME8Sy"
      },
      "source": [
        "## Making predictions on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vgiwdJrE8RE",
        "outputId": "e1ba5f3b-9ae1-40ad-b4e5-7a8156025d4d"
      },
      "source": [
        "import random\n",
        "# Making predictions on the test dataset and visualizing them\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6_pretrained.predict([test_sample])) # our model expects a list as input\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print(\"------\\n\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 0, Prob: 0.1830405592918396\n",
            "Text:\n",
            "@mishavelgos @MattBacal8 @ComplexMag this is so accurate I can't even speak haha... Comparing hazard to harden is so true\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 1, Prob: 0.5818614363670349\n",
            "Text:\n",
            "U.S National Park Services Tonto National Forest: Stop the Annihilation of the Salt River Wild Horse... https://t.co/lATVr8RZCK via @Change\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 0, Prob: 0.19843491911888123\n",
            "Text:\n",
            "'I must not fear/Fear is the mindkiller/Fear is the little-death that brings total obliteration/I will face my fear' #Dune #BlacklivesMatter\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 0, Prob: 0.1088269054889679\n",
            "Text:\n",
            "Actually if I don't see Hunter Hayes and Lady Antebellum perform Where it All Begins live I will be a very devastated person :-)\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 0, Prob: 0.3061552941799164\n",
            "Text:\n",
            "Need a conquest server on CTE they're all Russian Squad Obliteration servers at the moment. Lame. But only 105 ping on Russian server. ??\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 0, Prob: 0.08442676067352295\n",
            "Text:\n",
            "I had trouble breathing while listening to kian singing omg\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 0, Prob: 0.10286793112754822\n",
            "Text:\n",
            "I attacked Robot-lvl 1 and I've earned a total of 16000 free satoshis! http://t.co/2PZcXSkNCg #robotcoingame #Bitcoin #FreeBitcoin\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 0, Prob: 0.09756553173065186\n",
            "Text:\n",
            "Just watched Punisher: War Zone. IDK why everyone hates it. It is basically the best possible movie you could get out of Punisher\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 1, Prob: 0.5394994616508484\n",
            "Text:\n",
            "Stop using the money of tax layers of the country to feed bloody terrorist. Shot them and give a strong msg as other country does...\n",
            "\n",
            "------\n",
            "\n",
            "Pred: 0, Prob: 0.04110133647918701\n",
            "Text:\n",
            "I just watched Halt and Catch Fire 2x10 'Heaven is a Place' https://t.co/jcPxOrV3AU #trakt\n",
            "\n",
            "------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf0CT400E8OB",
        "outputId": "6d13326b-7960-4e89-cf51-a77a37e7e2ab"
      },
      "source": [
        "test_sample=\"The flood hit Kastamonu for the second time, transportation to some villages was cut off\"\n",
        "pred_prob = tf.squeeze(model_6_pretrained.predict([test_sample])) # our model expects a list as input\n",
        "pred = tf.round(pred_prob)\n",
        "print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "print(f\"Text:\\n{test_sample}\\n\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 1, Prob: 0.9150900840759277\n",
            "Text:\n",
            "The flood hit Kastamonu for the second time, transportation to some villages was cut off\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grHKaX8bueWP"
      },
      "source": [
        "## The speed/score tradeoff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0oPj9lwE8Kz"
      },
      "source": [
        "# Let's make a function to measure the time of prediction\n",
        "import time \n",
        "def pred_timer(model, samples):\n",
        "  \"\"\"\n",
        "  Times how long a model takes to make predictions on samples\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter() # get start time \n",
        "  model.predict(samples) # make predictions\n",
        "  end_time = time.perf_counter() # get finish time\n",
        "  total_time = end_time - start_time # calculate how long predictions took to make\n",
        "  time_per_pred = total_time/len(samples)\n",
        "  return total_time, time_per_pred"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXLOEF87P5pq",
        "outputId": "756fd97e-5b9e-494a-cc70-b04ec21bd31e"
      },
      "source": [
        "# Calculate TF Hub Sentence Encoder time per pred\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model=model_6_pretrained,\n",
        "                                                            samples=val_sentences)\n",
        "model_6_total_pred_time, model_6_time_per_pred"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2218951489999199, 0.00029120098293952744)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywGA9uqMP5nY",
        "outputId": "ce293951-0344-48a0-ec75-574b5dd7ff01"
      },
      "source": [
        "# Calculate our basleine model times per pred\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.01536283999985244, 2.0161207348887716e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJA2WxWaw0yL",
        "outputId": "6c0a7b7a-8a79-4121-8d4f-86d185bcf822"
      },
      "source": [
        "# Get results for pretrained GS model\n",
        "model_6_pretrained_results = calculate_results(y_true=val_labels,\n",
        "                                               y_pred=model_6_pretrained_preds)\n",
        "model_6_pretrained_results"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.62729658792651,\n",
              " 'f1': 0.8148082644367335,\n",
              " 'precision': 0.818446310697231,\n",
              " 'recall': 0.8162729658792651}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "6Lu7qVccwMwe",
        "outputId": "87924d62-62c7-4b98-bb42-de6ca9caf3c9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
        "plt.scatter(model_6_time_per_pred, model_6_pretrained_results[\"f1\"], label=\"tf_hub_sentence_encoder\")\n",
        "plt.legend()\n",
        "plt.title(\"F1-score vs. time per prediction\")\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"f1-score\");"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}