{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine Tuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQynf8U84zOw"
      },
      "source": [
        "## Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM0OndcRV6aj"
      },
      "source": [
        "## Model's we are going to build\n",
        "\n",
        "- Model 0: a transfer learning model using the Keras Functional API\n",
        "- Model 1: a feature extraction transfer learning model on 1% of the data with data augmentation\n",
        "- Model 2: a feature extraction transfer learning model on 10% of the data with data augmentation\n",
        "- Model 3: a fine-tuned transfer learning model on 10% of the data\n",
        "- Model 4: a fine-tuned transfer learning model on 100% of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkl80x5OWo8Z"
      },
      "source": [
        "## Creating helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WanM2QtEfidq"
      },
      "source": [
        "It's a good idea to put functions you'll want to use again in a script you can download and import into your ntwbooks (or elsewhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fXOjJ8hWo_r",
        "outputId": "27a661a9-03f3-4c64-e232-26ef2fb6d189"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-25 08:13:09--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: â€˜helper_functions.pyâ€™\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-25 08:13:09 (49.0 MB/s) - â€˜helper_functions.pyâ€™ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lADxKqDWpDS"
      },
      "source": [
        "# Import helper functions we're going to use in this notebook\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pERIfmafWpGg"
      },
      "source": [
        "## Let's get some data\n",
        "\n",
        "This time we're going to see how we can use the pretrained models within tf.keras.applications and apply them to our own problem (recognizing images of food)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6eivstqWpJq",
        "outputId": "95b18b8b-947e-450b-cbe0-b1734d914a03"
      },
      "source": [
        "# Get 10% of training data of 10 classes of Food101\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "unzip_data(\"10_food_classes_10_percent.zip\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-25 08:13:12--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.69.128, 173.194.195.128, 173.194.197.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.69.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: â€˜10_food_classes_10_percent.zipâ€™\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   119MB/s    in 1.3s    \n",
            "\n",
            "2021-09-25 08:13:14 (119 MB/s) - â€˜10_food_classes_10_percent.zipâ€™ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaOlatWQWpNL",
        "outputId": "6d31ccad-90e7-4736-f77b-50cf7e6ffad2"
      },
      "source": [
        "# Check out how many images and subdirectories are in our dataset\n",
        "walk_through_dir(\"10_food_classes_10_percent\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdBIUWVPWpQ-"
      },
      "source": [
        "# Create training and test directory paths\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-l9zwlUWpUX",
        "outputId": "0dcb965c-08c7-427b-a615-f3f7a7251dc9"
      },
      "source": [
        "import tensorflow as tf\n",
        "IMG_SIZE = (224,224)\n",
        "BATCH_SIZE = 32\n",
        "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n",
        "                                                                            image_size=IMG_SIZE,\n",
        "                                                                            label_mode=\"categorical\",\n",
        "                                                                            batch_size=BATCH_SIZE)\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
        "                                                                image_size=IMG_SIZE,\n",
        "                                                                label_mode=\"categorical\",\n",
        "                                                                batch_size=BATCH_SIZE)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNQ42ccFnQhA"
      },
      "source": [
        "One of the main benefits of using [`tf.keras.prepreprocessing.image_dataset_from_directory()`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory) rather than `ImageDataGenerator` is that it creates a [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) object rather than a generator. The main advantage of this is the `tf.data.Dataset` API is much more efficient (faster) than the `ImageDataGenerator` API which is paramount for larger datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVcxrHy-WpXj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41218d8b-94ea-4e7c-c6db-9a5b2432f760"
      },
      "source": [
        "train_data_10_percent"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 224, 224, 3), (None, 10)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B62r0YbkE8jV"
      },
      "source": [
        "In the above output:\n",
        "\n",
        "* `(None, 224, 224, 3)` refers to the tensor shape of our images where `None` is the batch size, `224` is the height (and width) and `3` is the color channels (red, green, blue).\n",
        "* `(None, 10)` refers to the tensor shape of the labels where `None` is the batch size and `10` is the number of possible labels (the 10 different food classes).\n",
        "* Both image tensors and labels are of the datatype `tf.float32`.\n",
        "\n",
        "The `batch_size` is `None` due to it only being used during model training. You can think of `None` as a placeholder waiting to be filled with the `batch_size` parameter from `image_dataset_from_directory()`.\n",
        "\n",
        "Another benefit of using the `tf.data.Dataset` API are the assosciated methods which come with it.\n",
        "\n",
        "For example, if we want to find the name of the classes we were working with, we could use the `class_names` attribute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSq1H8csWeYR"
      },
      "source": [
        "If we want to see an example batch of data, we could use the take() method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HYCdMyVWpbG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02e8def4-4dac-4f12-fd0d-893f799b0b13"
      },
      "source": [
        "# Check out class names of our dataset\n",
        "train_data_10_percent.class_names"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chicken_curry',\n",
              " 'chicken_wings',\n",
              " 'fried_rice',\n",
              " 'grilled_salmon',\n",
              " 'hamburger',\n",
              " 'ice_cream',\n",
              " 'pizza',\n",
              " 'ramen',\n",
              " 'steak',\n",
              " 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2A-FoCCixVJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c37e6d2-9339-4b8d-e424-c414a93d282d"
      },
      "source": [
        "# See an example of a batch data\n",
        "for images, labels in train_data_10_percent.take(1):\n",
        "  print(images, labels)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[3.99336739e+01 2.99336720e+01 2.79336720e+01]\n",
            "   [3.77448997e+01 2.89387760e+01 2.63418369e+01]\n",
            "   [3.76428566e+01 2.94285698e+01 2.80714283e+01]\n",
            "   ...\n",
            "   [1.63193848e+02 1.46755081e+02 1.28474457e+02]\n",
            "   [1.68102112e+02 1.55244995e+02 1.36173553e+02]\n",
            "   [1.86036148e+02 1.76796417e+02 1.58209656e+02]]\n",
            "\n",
            "  [[5.13418427e+01 4.33418427e+01 4.03418427e+01]\n",
            "   [4.11020393e+01 3.31020393e+01 3.01020412e+01]\n",
            "   [3.85000000e+01 3.32857132e+01 3.09285717e+01]\n",
            "   ...\n",
            "   [1.41642746e+02 1.22785599e+02 1.05714172e+02]\n",
            "   [1.39795959e+02 1.25071487e+02 1.06071487e+02]\n",
            "   [1.51668579e+02 1.36928879e+02 1.20500275e+02]]\n",
            "\n",
            "  [[4.73673477e+01 4.23673477e+01 3.83673477e+01]\n",
            "   [5.03010216e+01 4.57295914e+01 4.15153084e+01]\n",
            "   [3.68622437e+01 3.28622437e+01 3.02908154e+01]\n",
            "   ...\n",
            "   [1.37137650e+02 1.15709084e+02 9.92601089e+01]\n",
            "   [1.23102097e+02 1.03617432e+02 8.87602768e+01]\n",
            "   [1.40413559e+02 1.21561592e+02 1.06418701e+02]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[2.18000000e+02 2.13000000e+02 1.93000000e+02]\n",
            "   [2.18000000e+02 2.13000000e+02 1.91000000e+02]\n",
            "   [2.16908173e+02 2.11525543e+02 1.89525543e+02]\n",
            "   ...\n",
            "   [5.22601738e+01 3.41683540e+01 2.37857361e+01]\n",
            "   [4.72856445e+01 3.01019955e+01 1.96581593e+01]\n",
            "   [4.49437637e+01 2.89999695e+01 1.80765305e+01]]\n",
            "\n",
            "  [[2.17357147e+02 2.15357147e+02 1.94357147e+02]\n",
            "   [2.17005081e+02 2.12005081e+02 1.90005081e+02]\n",
            "   [2.14000000e+02 2.08785721e+02 1.86785721e+02]\n",
            "   ...\n",
            "   [5.07856750e+01 3.35867195e+01 2.51581898e+01]\n",
            "   [4.38571167e+01 2.72755585e+01 1.91377792e+01]\n",
            "   [4.55714722e+01 3.19745750e+01 2.29745750e+01]]\n",
            "\n",
            "  [[2.17357147e+02 2.15357147e+02 1.94357147e+02]\n",
            "   [2.14474518e+02 2.12474518e+02 1.89474518e+02]\n",
            "   [2.15433716e+02 2.10219437e+02 1.88219437e+02]\n",
            "   ...\n",
            "   [5.21427307e+01 3.59846725e+01 2.77040253e+01]\n",
            "   [4.65255470e+01 3.29286499e+01 2.39286499e+01]\n",
            "   [4.31836205e+01 3.19439564e+01 2.23571777e+01]]]\n",
            "\n",
            "\n",
            " [[[1.77018490e+01 1.27018499e+01 8.70184994e+00]\n",
            "   [1.65475121e+01 1.15475130e+01 7.54751253e+00]\n",
            "   [1.47273598e+01 9.72735977e+00 5.72735977e+00]\n",
            "   ...\n",
            "   [3.48838768e+01 2.93386135e+01 2.33386135e+01]\n",
            "   [3.33571434e+01 2.83571434e+01 2.23571434e+01]\n",
            "   [3.28992386e+01 2.98992405e+01 2.28992405e+01]]\n",
            "\n",
            "  [[2.03408813e+01 1.53408794e+01 1.13408794e+01]\n",
            "   [1.89110355e+01 1.39110336e+01 9.91103363e+00]\n",
            "   [2.19668369e+01 1.69668369e+01 1.29668379e+01]\n",
            "   ...\n",
            "   [3.52355728e+01 3.06750355e+01 2.64553051e+01]\n",
            "   [3.28654327e+01 2.98571434e+01 2.48612881e+01]\n",
            "   [3.45044823e+01 3.15044823e+01 2.45044823e+01]]\n",
            "\n",
            "  [[2.08571434e+01 1.58571434e+01 1.18571434e+01]\n",
            "   [2.25653706e+01 1.75653706e+01 1.35653706e+01]\n",
            "   [2.59853325e+01 2.09853325e+01 1.69853325e+01]\n",
            "   ...\n",
            "   [3.71128731e+01 3.25354309e+01 2.84002113e+01]\n",
            "   [3.75258446e+01 3.43115616e+01 2.97401314e+01]\n",
            "   [3.80628052e+01 3.48485184e+01 3.02770901e+01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[5.54507554e-01 6.18353510e+00 4.33495045e+00]\n",
            "   [1.19300900e+01 2.13068771e+01 2.07354050e+01]\n",
            "   [9.67823639e+01 1.09002640e+02 1.09358124e+02]\n",
            "   ...\n",
            "   [1.37273697e+02 1.63166794e+02 1.76685822e+02]\n",
            "   [1.27608803e+02 1.52465866e+02 1.64894394e+02]\n",
            "   [1.20124756e+02 1.41964539e+02 1.52375793e+02]]\n",
            "\n",
            "  [[6.86767292e+00 4.33350992e+00 1.20215142e+00]\n",
            "   [8.22385120e+00 9.00026608e+00 4.00026655e+00]\n",
            "   [3.45993423e+00 5.30014753e+00 3.29918098e+00]\n",
            "   ...\n",
            "   [1.29194580e+02 1.48362518e+02 1.56983002e+02]\n",
            "   [1.15525093e+02 1.30355347e+02 1.35319214e+02]\n",
            "   [9.47316589e+01 1.05424843e+02 1.07987282e+02]]\n",
            "\n",
            "  [[1.05300026e+01 1.75221360e+00 0.00000000e+00]\n",
            "   [1.34552174e+01 5.89839172e+00 1.36025798e+00]\n",
            "   [6.77324533e+00 4.00881624e+00 2.24438691e+00]\n",
            "   ...\n",
            "   [9.99744568e+01 1.15009346e+02 1.20585091e+02]\n",
            "   [7.15901794e+01 8.13117371e+01 8.17714233e+01]\n",
            "   [5.34428596e+01 5.79759140e+01 5.41980934e+01]]]\n",
            "\n",
            "\n",
            " [[[5.34183645e+00 5.34183645e+00 0.00000000e+00]\n",
            "   [5.99999952e+00 4.99999952e+00 6.88775301e-01]\n",
            "   [7.95918465e-01 7.95918465e-01 0.00000000e+00]\n",
            "   ...\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[4.26530600e+00 3.26530600e+00 1.93877459e-01]\n",
            "   [1.42856598e-01 1.14285660e+00 0.00000000e+00]\n",
            "   [2.64285731e+00 1.42857170e+00 2.29591981e-01]\n",
            "   ...\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[9.06122494e+00 8.84693909e+00 6.41836786e+00]\n",
            "   [9.84693229e-01 4.13264453e-01 5.61222434e-02]\n",
            "   [5.42857170e+00 1.26020420e+00 9.18367505e-02]\n",
            "   ...\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[9.39285736e+01 8.19285736e+01 8.59285736e+01]\n",
            "   [9.90000000e+01 8.70000000e+01 9.10000000e+01]\n",
            "   [9.76428680e+01 8.58571548e+01 8.99489975e+01]\n",
            "   ...\n",
            "   [1.69000000e+02 1.51045883e+02 1.31642853e+02]\n",
            "   [1.65928558e+02 1.47714264e+02 1.28357147e+02]\n",
            "   [1.63642822e+02 1.45428528e+02 1.26071411e+02]]\n",
            "\n",
            "  [[9.33316193e+01 8.13316193e+01 8.53316193e+01]\n",
            "   [9.80050888e+01 8.60050888e+01 9.00050888e+01]\n",
            "   [9.82295914e+01 8.64438782e+01 9.08724518e+01]\n",
            "   ...\n",
            "   [1.68801041e+02 1.50229568e+02 1.33015305e+02]\n",
            "   [1.65928558e+02 1.46928558e+02 1.29928558e+02]\n",
            "   [1.63974487e+02 1.44974487e+02 1.27974495e+02]]\n",
            "\n",
            "  [[9.38724518e+01 8.18724518e+01 8.58724518e+01]\n",
            "   [9.59285736e+01 8.39285736e+01 8.79285736e+01]\n",
            "   [9.85050964e+01 8.59336700e+01 9.27193832e+01]\n",
            "   ...\n",
            "   [1.68076523e+02 1.49076523e+02 1.33647995e+02]\n",
            "   [1.66596924e+02 1.47596924e+02 1.32596924e+02]\n",
            "   [1.65000000e+02 1.46000000e+02 1.31000000e+02]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[1.15285713e+02 6.82857132e+01 4.02857132e+01]\n",
            "   [1.18071426e+02 7.10714264e+01 4.50714264e+01]\n",
            "   [1.23285713e+02 7.46428528e+01 5.32857132e+01]\n",
            "   ...\n",
            "   [2.16913422e+02 1.54984741e+02 2.10841797e+02]\n",
            "   [2.02076172e+02 1.29652634e+02 1.66438248e+02]\n",
            "   [1.40142334e+02 5.57851562e+01 7.82543945e+01]]\n",
            "\n",
            "  [[1.22520409e+02 7.45255127e+01 4.68571434e+01]\n",
            "   [1.27433678e+02 7.76479568e+01 5.25765305e+01]\n",
            "   [1.30698990e+02 7.96989822e+01 5.91275520e+01]\n",
            "   ...\n",
            "   [1.87764893e+02 1.25836212e+02 1.80152405e+02]\n",
            "   [1.73397766e+02 9.81170883e+01 1.30683319e+02]\n",
            "   [1.46570770e+02 6.09023247e+01 8.02337799e+01]]\n",
            "\n",
            "  [[1.21209183e+02 6.87806168e+01 4.47806129e+01]\n",
            "   [1.25071434e+02 7.30714340e+01 4.95000000e+01]\n",
            "   [1.26831635e+02 7.50000000e+01 5.31683693e+01]\n",
            "   ...\n",
            "   [1.81995087e+02 1.12612335e+02 1.60255035e+02]\n",
            "   [1.98515228e+02 1.18959045e+02 1.49045700e+02]\n",
            "   [1.57973923e+02 7.06167526e+01 8.66982956e+01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[9.98520889e+01 9.84948807e+01 1.45280624e+02]\n",
            "   [9.96990051e+01 9.70714264e+01 1.42428528e+02]\n",
            "   [1.00663300e+02 9.51683502e+01 1.40663254e+02]\n",
            "   ...\n",
            "   [2.81631374e+01 5.49286804e+01 1.08827715e+01]\n",
            "   [2.50561962e+01 5.90715027e+01 2.27551823e+01]\n",
            "   [3.41991806e+01 6.56277084e+01 3.45511475e+01]]\n",
            "\n",
            "  [[1.04357140e+02 9.83571396e+01 1.46357147e+02]\n",
            "   [1.01275528e+02 9.51428528e+01 1.41209198e+02]\n",
            "   [1.02301041e+02 9.53010406e+01 1.39301025e+02]\n",
            "   ...\n",
            "   [3.14284668e+01 6.76173935e+01 2.68725452e+01]\n",
            "   [2.90561295e+01 6.29183502e+01 3.02806625e+01]\n",
            "   [3.50204697e+01 6.29030113e+01 3.35918808e+01]]\n",
            "\n",
            "  [[1.05357140e+02 9.73571396e+01 1.46357147e+02]\n",
            "   [1.04357178e+02 9.54030914e+01 1.42403091e+02]\n",
            "   [1.06571465e+02 9.80000381e+01 1.42785751e+02]\n",
            "   ...\n",
            "   [2.69437637e+01 6.87245026e+01 3.44388885e+01]\n",
            "   [2.66938572e+01 6.30969276e+01 3.76939468e+01]\n",
            "   [2.94847546e+01 5.61836205e+01 3.54847527e+01]]]\n",
            "\n",
            "\n",
            " [[[3.73571434e+01 3.63571434e+01 5.23571434e+01]\n",
            "   [3.73571434e+01 3.63571434e+01 5.23571434e+01]\n",
            "   [3.68622437e+01 3.58622437e+01 5.18622437e+01]\n",
            "   ...\n",
            "   [2.04933334e+02 2.18862015e+02 2.01443420e+02]\n",
            "   [1.62163055e+02 1.90479446e+02 1.41137421e+02]\n",
            "   [1.27586342e+02 1.65683350e+02 9.13973923e+01]]\n",
            "\n",
            "  [[3.68571434e+01 3.78571434e+01 5.58571434e+01]\n",
            "   [3.59285736e+01 3.69285736e+01 5.49285736e+01]\n",
            "   [3.78010216e+01 3.98010216e+01 5.48010216e+01]\n",
            "   ...\n",
            "   [2.22958923e+02 2.33688644e+02 2.24703812e+02]\n",
            "   [1.89714081e+02 2.11280457e+02 1.78984421e+02]\n",
            "   [1.53545502e+02 1.82193497e+02 1.30596390e+02]]\n",
            "\n",
            "  [[3.61377563e+01 3.91377563e+01 5.61377563e+01]\n",
            "   [3.74132652e+01 4.04132652e+01 5.74132652e+01]\n",
            "   [3.71224480e+01 4.01224480e+01 5.71224480e+01]\n",
            "   ...\n",
            "   [2.39556015e+02 2.43642838e+02 2.45387665e+02]\n",
            "   [2.25489700e+02 2.36362183e+02 2.28178452e+02]\n",
            "   [2.05867050e+02 2.21938507e+02 2.04300659e+02]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[9.80656357e+01 1.03065636e+02 1.45065643e+02]\n",
            "   [1.37637436e+02 1.42208908e+02 1.84423172e+02]\n",
            "   [9.08619919e+01 9.31732483e+01 1.35867172e+02]\n",
            "   ...\n",
            "   [1.21566559e+02 1.07071625e+02 1.11474739e+02]\n",
            "   [1.28199265e+02 1.13199265e+02 1.17770737e+02]\n",
            "   [1.39362595e+02 1.24362602e+02 1.28934067e+02]]\n",
            "\n",
            "  [[5.87757721e+01 6.38472137e+01 1.01653297e+02]\n",
            "   [6.94793167e+01 7.26170883e+01 1.13198677e+02]\n",
            "   [9.11937180e+01 9.41937180e+01 1.37622284e+02]\n",
            "   ...\n",
            "   [1.34188995e+02 1.21188988e+02 1.28188995e+02]\n",
            "   [1.50576630e+02 1.35505188e+02 1.42719513e+02]\n",
            "   [1.54331696e+02 1.38663345e+02 1.47668365e+02]]\n",
            "\n",
            "  [[1.41307678e+02 1.46307678e+02 1.77593323e+02]\n",
            "   [5.71127129e+01 6.11127129e+01 9.79698639e+01]\n",
            "   [4.59999657e+01 4.89999657e+01 9.18672562e+01]\n",
            "   ...\n",
            "   [1.47806183e+02 1.34806183e+02 1.43806183e+02]\n",
            "   [1.54454163e+02 1.41454163e+02 1.51454163e+02]\n",
            "   [1.65785889e+02 1.49785889e+02 1.60785889e+02]]]\n",
            "\n",
            "\n",
            " [[[4.63979607e+01 1.73979588e+01 8.26530755e-01]\n",
            "   [5.23061218e+01 2.33061218e+01 5.30612230e+00]\n",
            "   [5.26377563e+01 2.06377544e+01 6.06632662e+00]\n",
            "   ...\n",
            "   [4.96529579e+01 1.26529589e+01 4.65295839e+00]\n",
            "   [4.33827095e+01 1.03827095e+01 3.38270998e+00]\n",
            "   [4.26172066e+01 1.26172047e+01 4.61720467e+00]]\n",
            "\n",
            "  [[6.00663300e+01 2.84030628e+01 1.07346954e+01]\n",
            "   [6.10663300e+01 3.00663261e+01 1.20663261e+01]\n",
            "   [5.34591827e+01 2.14591846e+01 6.88775539e+00]\n",
            "   ...\n",
            "   [4.83009949e+01 1.13009968e+01 3.30099678e+00]\n",
            "   [4.20663528e+01 9.06635189e+00 1.32677391e-01]\n",
            "   [4.29030609e+01 1.29030590e+01 2.90305901e+00]]\n",
            "\n",
            "  [[6.99948959e+01 3.39948997e+01 2.04234695e+01]\n",
            "   [5.88877525e+01 2.52448959e+01 1.08877535e+01]\n",
            "   [5.54234657e+01 2.24693871e+01 8.40306091e+00]\n",
            "   ...\n",
            "   [4.68111839e+01 9.81118584e+00 1.76527214e+00]\n",
            "   [4.65255013e+01 1.35255013e+01 4.52550173e+00]\n",
            "   [4.32959328e+01 1.32959328e+01 3.29593277e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[8.27806625e+01 8.24234543e+01 6.37806625e+01]\n",
            "   [8.18571625e+01 8.28571625e+01 6.48571625e+01]\n",
            "   [8.19081726e+01 8.51224594e+01 6.85510330e+01]\n",
            "   ...\n",
            "   [2.11505066e+02 2.26168350e+02 2.32908188e+02]\n",
            "   [2.16698929e+02 2.29270401e+02 2.36841873e+02]\n",
            "   [2.15790726e+02 2.26004990e+02 2.34362198e+02]]\n",
            "\n",
            "  [[8.26479645e+01 8.06479645e+01 6.56479645e+01]\n",
            "   [8.19234543e+01 8.29234543e+01 6.69234543e+01]\n",
            "   [8.03418198e+01 8.27703934e+01 6.85561066e+01]\n",
            "   ...\n",
            "   [2.09142883e+02 2.24571411e+02 2.31571411e+02]\n",
            "   [2.13066345e+02 2.26066345e+02 2.34066345e+02]\n",
            "   [2.14311157e+02 2.24311157e+02 2.33311157e+02]]\n",
            "\n",
            "  [[8.45561676e+01 8.25561676e+01 6.95561676e+01]\n",
            "   [8.21888123e+01 8.31888123e+01 6.91888123e+01]\n",
            "   [7.97091751e+01 8.26990280e+01 6.82041016e+01]\n",
            "   ...\n",
            "   [2.13637863e+02 2.29066391e+02 2.36066391e+02]\n",
            "   [2.12571381e+02 2.25571381e+02 2.33571381e+02]\n",
            "   [2.14770401e+02 2.24770401e+02 2.33770401e+02]]]], shape=(32, 224, 224, 3), dtype=float32) tf.Tensor(\n",
            "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(32, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nJCrNUJixSf"
      },
      "source": [
        "## Model 0: Building a transfer learning feature extraction model using the Keras Functional API\n",
        "\n",
        "The sequential API is straight-forward, it runs our layers in sequential order.\n",
        "\n",
        "But the functioanl API gives us more flexibility with our models - http://www.tensorflow.org/guide/keras/functional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8BlLfq_WppQ"
      },
      "source": [
        "We're going to go through the following steps:\n",
        "\n",
        "1. Instantiate a pre-trained base model object by choosing a target model such as [`EfficientNetB0`](https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB0) from `tf.keras.applications`, setting the `include_top` parameter to `False` (we do this because we're going to create our own top, which are the output layers for the model).\n",
        "2. Set the base model's `trainable` attribute to `False` to freeze all of the weights in the pre-trained model.\n",
        "3. Define an input layer for our model, for example, what shape of data should our model expect?\n",
        "4. [Optional] Normalize the inputs to our model if it requires. Some computer vision models such as `ResNetV250` require their inputs to be between 0 & 1.\n",
        "\n",
        "> ðŸ”‘ **Note:** As of writing, the `EfficientNet` models in the `tf.keras.applications` module do not require images to be normalized (pixel values between 0 and 1) on input, where as many of the other models do.\n",
        "\n",
        "5. Pass the inputs to the base model.\n",
        "6. Pool the outputs of the base model into a shape compatible with the output activation layer (turn base model output tensors into same shape as label tensors). This can be done using [`tf.keras.layers.GlobalAveragePooling2D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D) or [`tf.keras.layers.GlobalMaxPooling2D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool2D?hl=en) though the former is more common in practice.\n",
        "7. Create an output activation layer using `tf.keras.layers.Dense()` with the appropriate activation function and number of neurons.\n",
        "8. Combine the inputs and outputs layer into a model using [`tf.keras.Model()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model).\n",
        "9. Compile the model using the appropriate loss function and choose of optimizer.\n",
        "10. Fit the model for desired number of epochs and with necessary callbacks (in our case, we'll start off with the TensorBoard callback)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO8WnqR4ixP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "022771ef-eed0-45ef-cf83-d811e82879b7"
      },
      "source": [
        "# 1. Create the base model with tf.keras.applications\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "\n",
        "# 2. Freeze the base model (so the underlying pre-trained patterns aren't updated during training)\n",
        "base_model.trainable = False\n",
        "\n",
        "# 3. Create inputs into our model\n",
        "inputs = tf.keras.layers.Input(shape=(224,224,3), name=\"input_layer\")\n",
        "\n",
        "# 4. If using ResNet50V2, you will need to normalize inputs (you don't have to for EfficientNet)\n",
        "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1/255.0)(inputs)\n",
        "\n",
        "# 5. Pass the inputs to the base_model\n",
        "x = base_model(inputs)\n",
        "print(f\"Shape after passing inputs through base model: {x.shape}\")\n",
        "\n",
        "# 6. Average pool the outputs of the base model (aggregate all the most important information, reduce number of computations)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
        "print(f\"Shape after GlobalAveragePooling2D: {x.shape}\")\n",
        "\n",
        "# 7. Create the output activation layer\n",
        "outputs = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n",
        "\n",
        "# 8. Compile the inputs with the outputs into a model\n",
        "model_0 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# 9. Compile the model\n",
        "model_0.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 10. Fit the model\n",
        "history_10_percent = model_0.fit(train_data_10_percent,\n",
        "                                 epochs=5,\n",
        "                                 steps_per_epoch=len(train_data_10_percent),\n",
        "                                 validation_data=test_data,\n",
        "                                 validation_steps=int(0.25*len(test_data)),\n",
        "                                 callbacks=[create_tensorboard_callback(dir_name=\"transfer_learning\",\n",
        "                                                                        experiment_name=\"10_percent_feature_extraction\")])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after passing inputs through base model: (None, 7, 7, 1280)\n",
            "Shape after GlobalAveragePooling2D: (None, 1280)\n",
            "Saving TensorBoard log files to: transfer_learning/10_percent_feature_extraction/20210925-090144\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 15s 366ms/step - loss: 1.9194 - accuracy: 0.3720 - val_loss: 1.3584 - val_accuracy: 0.7039\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 7s 262ms/step - loss: 1.1698 - accuracy: 0.7400 - val_loss: 0.9457 - val_accuracy: 0.8125\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 9s 354ms/step - loss: 0.8508 - accuracy: 0.8160 - val_loss: 0.7520 - val_accuracy: 0.8289\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 7s 266ms/step - loss: 0.7039 - accuracy: 0.8267 - val_loss: 0.6699 - val_accuracy: 0.8438\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 9s 353ms/step - loss: 0.6085 - accuracy: 0.8560 - val_loss: 0.6072 - val_accuracy: 0.8503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2hvdB5aZFAn"
      },
      "source": [
        "It's important to note the kind of transfer learning we used here is called feature extraction transfer learning, similar to what we did with the TensorFlow Hub models.\n",
        "\n",
        "In other words, we passed our custom data to an already pre-trained model (EfficientNetB0), asked it \"what patterns do you see?\" and then put our own output layer on top to make sure the outputs were tailored to our desired number of classes.\n",
        "\n",
        "We also used the Keras Functional API to build our model rather than the Sequential API. For now, the benefits of this main not seem clear but when you start to build more sophisticated models, you'll probably want to use the Functional API. So it's important to have exposure to this way of building models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAURTTb5DB8m",
        "outputId": "e50e7275-da7f-48ce-bfa6-2c9b77927cc4"
      },
      "source": [
        "# Evaluate on the full test dataset\n",
        "model_0.evaluate(test_data)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 11s 133ms/step - loss: 0.6131 - accuracy: 0.8428\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.613102912902832, 0.8428000211715698]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjAXe3cgDB_y",
        "outputId": "5448d99f-831c-4e0f-8a29-335d9f40f755"
      },
      "source": [
        "# Check the layers in our base model\n",
        "for layer_number, layer in enumerate(base_model.layers):\n",
        "  print(layer_number, layer.name)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_5\n",
            "1 rescaling_4\n",
            "2 normalization_4\n",
            "3 stem_conv_pad\n",
            "4 stem_conv\n",
            "5 stem_bn\n",
            "6 stem_activation\n",
            "7 block1a_dwconv\n",
            "8 block1a_bn\n",
            "9 block1a_activation\n",
            "10 block1a_se_squeeze\n",
            "11 block1a_se_reshape\n",
            "12 block1a_se_reduce\n",
            "13 block1a_se_expand\n",
            "14 block1a_se_excite\n",
            "15 block1a_project_conv\n",
            "16 block1a_project_bn\n",
            "17 block2a_expand_conv\n",
            "18 block2a_expand_bn\n",
            "19 block2a_expand_activation\n",
            "20 block2a_dwconv_pad\n",
            "21 block2a_dwconv\n",
            "22 block2a_bn\n",
            "23 block2a_activation\n",
            "24 block2a_se_squeeze\n",
            "25 block2a_se_reshape\n",
            "26 block2a_se_reduce\n",
            "27 block2a_se_expand\n",
            "28 block2a_se_excite\n",
            "29 block2a_project_conv\n",
            "30 block2a_project_bn\n",
            "31 block2b_expand_conv\n",
            "32 block2b_expand_bn\n",
            "33 block2b_expand_activation\n",
            "34 block2b_dwconv\n",
            "35 block2b_bn\n",
            "36 block2b_activation\n",
            "37 block2b_se_squeeze\n",
            "38 block2b_se_reshape\n",
            "39 block2b_se_reduce\n",
            "40 block2b_se_expand\n",
            "41 block2b_se_excite\n",
            "42 block2b_project_conv\n",
            "43 block2b_project_bn\n",
            "44 block2b_drop\n",
            "45 block2b_add\n",
            "46 block3a_expand_conv\n",
            "47 block3a_expand_bn\n",
            "48 block3a_expand_activation\n",
            "49 block3a_dwconv_pad\n",
            "50 block3a_dwconv\n",
            "51 block3a_bn\n",
            "52 block3a_activation\n",
            "53 block3a_se_squeeze\n",
            "54 block3a_se_reshape\n",
            "55 block3a_se_reduce\n",
            "56 block3a_se_expand\n",
            "57 block3a_se_excite\n",
            "58 block3a_project_conv\n",
            "59 block3a_project_bn\n",
            "60 block3b_expand_conv\n",
            "61 block3b_expand_bn\n",
            "62 block3b_expand_activation\n",
            "63 block3b_dwconv\n",
            "64 block3b_bn\n",
            "65 block3b_activation\n",
            "66 block3b_se_squeeze\n",
            "67 block3b_se_reshape\n",
            "68 block3b_se_reduce\n",
            "69 block3b_se_expand\n",
            "70 block3b_se_excite\n",
            "71 block3b_project_conv\n",
            "72 block3b_project_bn\n",
            "73 block3b_drop\n",
            "74 block3b_add\n",
            "75 block4a_expand_conv\n",
            "76 block4a_expand_bn\n",
            "77 block4a_expand_activation\n",
            "78 block4a_dwconv_pad\n",
            "79 block4a_dwconv\n",
            "80 block4a_bn\n",
            "81 block4a_activation\n",
            "82 block4a_se_squeeze\n",
            "83 block4a_se_reshape\n",
            "84 block4a_se_reduce\n",
            "85 block4a_se_expand\n",
            "86 block4a_se_excite\n",
            "87 block4a_project_conv\n",
            "88 block4a_project_bn\n",
            "89 block4b_expand_conv\n",
            "90 block4b_expand_bn\n",
            "91 block4b_expand_activation\n",
            "92 block4b_dwconv\n",
            "93 block4b_bn\n",
            "94 block4b_activation\n",
            "95 block4b_se_squeeze\n",
            "96 block4b_se_reshape\n",
            "97 block4b_se_reduce\n",
            "98 block4b_se_expand\n",
            "99 block4b_se_excite\n",
            "100 block4b_project_conv\n",
            "101 block4b_project_bn\n",
            "102 block4b_drop\n",
            "103 block4b_add\n",
            "104 block4c_expand_conv\n",
            "105 block4c_expand_bn\n",
            "106 block4c_expand_activation\n",
            "107 block4c_dwconv\n",
            "108 block4c_bn\n",
            "109 block4c_activation\n",
            "110 block4c_se_squeeze\n",
            "111 block4c_se_reshape\n",
            "112 block4c_se_reduce\n",
            "113 block4c_se_expand\n",
            "114 block4c_se_excite\n",
            "115 block4c_project_conv\n",
            "116 block4c_project_bn\n",
            "117 block4c_drop\n",
            "118 block4c_add\n",
            "119 block5a_expand_conv\n",
            "120 block5a_expand_bn\n",
            "121 block5a_expand_activation\n",
            "122 block5a_dwconv\n",
            "123 block5a_bn\n",
            "124 block5a_activation\n",
            "125 block5a_se_squeeze\n",
            "126 block5a_se_reshape\n",
            "127 block5a_se_reduce\n",
            "128 block5a_se_expand\n",
            "129 block5a_se_excite\n",
            "130 block5a_project_conv\n",
            "131 block5a_project_bn\n",
            "132 block5b_expand_conv\n",
            "133 block5b_expand_bn\n",
            "134 block5b_expand_activation\n",
            "135 block5b_dwconv\n",
            "136 block5b_bn\n",
            "137 block5b_activation\n",
            "138 block5b_se_squeeze\n",
            "139 block5b_se_reshape\n",
            "140 block5b_se_reduce\n",
            "141 block5b_se_expand\n",
            "142 block5b_se_excite\n",
            "143 block5b_project_conv\n",
            "144 block5b_project_bn\n",
            "145 block5b_drop\n",
            "146 block5b_add\n",
            "147 block5c_expand_conv\n",
            "148 block5c_expand_bn\n",
            "149 block5c_expand_activation\n",
            "150 block5c_dwconv\n",
            "151 block5c_bn\n",
            "152 block5c_activation\n",
            "153 block5c_se_squeeze\n",
            "154 block5c_se_reshape\n",
            "155 block5c_se_reduce\n",
            "156 block5c_se_expand\n",
            "157 block5c_se_excite\n",
            "158 block5c_project_conv\n",
            "159 block5c_project_bn\n",
            "160 block5c_drop\n",
            "161 block5c_add\n",
            "162 block6a_expand_conv\n",
            "163 block6a_expand_bn\n",
            "164 block6a_expand_activation\n",
            "165 block6a_dwconv_pad\n",
            "166 block6a_dwconv\n",
            "167 block6a_bn\n",
            "168 block6a_activation\n",
            "169 block6a_se_squeeze\n",
            "170 block6a_se_reshape\n",
            "171 block6a_se_reduce\n",
            "172 block6a_se_expand\n",
            "173 block6a_se_excite\n",
            "174 block6a_project_conv\n",
            "175 block6a_project_bn\n",
            "176 block6b_expand_conv\n",
            "177 block6b_expand_bn\n",
            "178 block6b_expand_activation\n",
            "179 block6b_dwconv\n",
            "180 block6b_bn\n",
            "181 block6b_activation\n",
            "182 block6b_se_squeeze\n",
            "183 block6b_se_reshape\n",
            "184 block6b_se_reduce\n",
            "185 block6b_se_expand\n",
            "186 block6b_se_excite\n",
            "187 block6b_project_conv\n",
            "188 block6b_project_bn\n",
            "189 block6b_drop\n",
            "190 block6b_add\n",
            "191 block6c_expand_conv\n",
            "192 block6c_expand_bn\n",
            "193 block6c_expand_activation\n",
            "194 block6c_dwconv\n",
            "195 block6c_bn\n",
            "196 block6c_activation\n",
            "197 block6c_se_squeeze\n",
            "198 block6c_se_reshape\n",
            "199 block6c_se_reduce\n",
            "200 block6c_se_expand\n",
            "201 block6c_se_excite\n",
            "202 block6c_project_conv\n",
            "203 block6c_project_bn\n",
            "204 block6c_drop\n",
            "205 block6c_add\n",
            "206 block6d_expand_conv\n",
            "207 block6d_expand_bn\n",
            "208 block6d_expand_activation\n",
            "209 block6d_dwconv\n",
            "210 block6d_bn\n",
            "211 block6d_activation\n",
            "212 block6d_se_squeeze\n",
            "213 block6d_se_reshape\n",
            "214 block6d_se_reduce\n",
            "215 block6d_se_expand\n",
            "216 block6d_se_excite\n",
            "217 block6d_project_conv\n",
            "218 block6d_project_bn\n",
            "219 block6d_drop\n",
            "220 block6d_add\n",
            "221 block7a_expand_conv\n",
            "222 block7a_expand_bn\n",
            "223 block7a_expand_activation\n",
            "224 block7a_dwconv\n",
            "225 block7a_bn\n",
            "226 block7a_activation\n",
            "227 block7a_se_squeeze\n",
            "228 block7a_se_reshape\n",
            "229 block7a_se_reduce\n",
            "230 block7a_se_expand\n",
            "231 block7a_se_excite\n",
            "232 block7a_project_conv\n",
            "233 block7a_project_bn\n",
            "234 top_conv\n",
            "235 top_bn\n",
            "236 top_activation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IEwQwzVDCCz",
        "outputId": "a1f4453f-404c-4e45-c840-a0f9b56fe265"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnetb0\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "rescaling_4 (Rescaling)         (None, None, None, 3 0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "normalization_4 (Normalization) (None, None, None, 3 7           rescaling_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "stem_conv_pad (ZeroPadding2D)   (None, None, None, 3 0           normalization_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stem_conv (Conv2D)              (None, None, None, 3 864         stem_conv_pad[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "stem_bn (BatchNormalization)    (None, None, None, 3 128         stem_conv[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "stem_activation (Activation)    (None, None, None, 3 0           stem_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1a_dwconv (DepthwiseConv2D (None, None, None, 3 288         stem_activation[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1a_bn (BatchNormalization) (None, None, None, 3 128         block1a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block1a_activation (Activation) (None, None, None, 3 0           block1a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_excite (Multiply)    (None, None, None, 3 0           block1a_activation[0][0]         \n",
            "                                                                 block1a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_project_conv (Conv2D)   (None, None, None, 1 512         block1a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_project_bn (BatchNormal (None, None, None, 1 64          block1a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_conv (Conv2D)    (None, None, None, 9 1536        block1a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_bn (BatchNormali (None, None, None, 9 384         block2a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_activation (Acti (None, None, None, 9 0           block2a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_dwconv_pad (ZeroPadding (None, None, None, 9 0           block2a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2a_dwconv (DepthwiseConv2D (None, None, None, 9 864         block2a_dwconv_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_bn (BatchNormalization) (None, None, None, 9 384         block2a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2a_activation (Activation) (None, None, None, 9 0           block2a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_excite (Multiply)    (None, None, None, 9 0           block2a_activation[0][0]         \n",
            "                                                                 block2a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_project_conv (Conv2D)   (None, None, None, 2 2304        block2a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_project_bn (BatchNormal (None, None, None, 2 96          block2a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2b_expand_conv (Conv2D)    (None, None, None, 1 3456        block2a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_expand_bn (BatchNormali (None, None, None, 1 576         block2b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2b_expand_activation (Acti (None, None, None, 1 0           block2b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_dwconv (DepthwiseConv2D (None, None, None, 1 1296        block2b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2b_bn (BatchNormalization) (None, None, None, 1 576         block2b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2b_activation (Activation) (None, None, None, 1 0           block2b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_excite (Multiply)    (None, None, None, 1 0           block2b_activation[0][0]         \n",
            "                                                                 block2b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_project_conv (Conv2D)   (None, None, None, 2 3456        block2b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_project_bn (BatchNormal (None, None, None, 2 96          block2b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2b_drop (Dropout)          (None, None, None, 2 0           block2b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_add (Add)               (None, None, None, 2 0           block2b_drop[0][0]               \n",
            "                                                                 block2a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_conv (Conv2D)    (None, None, None, 1 3456        block2b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_bn (BatchNormali (None, None, None, 1 576         block3a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_activation (Acti (None, None, None, 1 0           block3a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_dwconv_pad (ZeroPadding (None, None, None, 1 0           block3a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3a_dwconv (DepthwiseConv2D (None, None, None, 1 3600        block3a_dwconv_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_bn (BatchNormalization) (None, None, None, 1 576         block3a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3a_activation (Activation) (None, None, None, 1 0           block3a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_excite (Multiply)    (None, None, None, 1 0           block3a_activation[0][0]         \n",
            "                                                                 block3a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_project_conv (Conv2D)   (None, None, None, 4 5760        block3a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_project_bn (BatchNormal (None, None, None, 4 160         block3a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3b_expand_conv (Conv2D)    (None, None, None, 2 9600        block3a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_expand_bn (BatchNormali (None, None, None, 2 960         block3b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3b_expand_activation (Acti (None, None, None, 2 0           block3b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_dwconv (DepthwiseConv2D (None, None, None, 2 6000        block3b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3b_bn (BatchNormalization) (None, None, None, 2 960         block3b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3b_activation (Activation) (None, None, None, 2 0           block3b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_squeeze (GlobalAvera (None, 240)          0           block3b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_excite (Multiply)    (None, None, None, 2 0           block3b_activation[0][0]         \n",
            "                                                                 block3b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_project_conv (Conv2D)   (None, None, None, 4 9600        block3b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_project_bn (BatchNormal (None, None, None, 4 160         block3b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3b_drop (Dropout)          (None, None, None, 4 0           block3b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_add (Add)               (None, None, None, 4 0           block3b_drop[0][0]               \n",
            "                                                                 block3a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_conv (Conv2D)    (None, None, None, 2 9600        block3b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_bn (BatchNormali (None, None, None, 2 960         block4a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_activation (Acti (None, None, None, 2 0           block4a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_dwconv_pad (ZeroPadding (None, None, None, 2 0           block4a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4a_dwconv (DepthwiseConv2D (None, None, None, 2 2160        block4a_dwconv_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_bn (BatchNormalization) (None, None, None, 2 960         block4a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4a_activation (Activation) (None, None, None, 2 0           block4a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_squeeze (GlobalAvera (None, 240)          0           block4a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_excite (Multiply)    (None, None, None, 2 0           block4a_activation[0][0]         \n",
            "                                                                 block4a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_project_conv (Conv2D)   (None, None, None, 8 19200       block4a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_project_bn (BatchNormal (None, None, None, 8 320         block4a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4b_expand_conv (Conv2D)    (None, None, None, 4 38400       block4a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_expand_bn (BatchNormali (None, None, None, 4 1920        block4b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4b_expand_activation (Acti (None, None, None, 4 0           block4b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_dwconv (DepthwiseConv2D (None, None, None, 4 4320        block4b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4b_bn (BatchNormalization) (None, None, None, 4 1920        block4b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4b_activation (Activation) (None, None, None, 4 0           block4b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_squeeze (GlobalAvera (None, 480)          0           block4b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_excite (Multiply)    (None, None, None, 4 0           block4b_activation[0][0]         \n",
            "                                                                 block4b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_project_conv (Conv2D)   (None, None, None, 8 38400       block4b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_project_bn (BatchNormal (None, None, None, 8 320         block4b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4b_drop (Dropout)          (None, None, None, 8 0           block4b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_add (Add)               (None, None, None, 8 0           block4b_drop[0][0]               \n",
            "                                                                 block4a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_expand_conv (Conv2D)    (None, None, None, 4 38400       block4b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4c_expand_bn (BatchNormali (None, None, None, 4 1920        block4c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4c_expand_activation (Acti (None, None, None, 4 0           block4c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_dwconv (DepthwiseConv2D (None, None, None, 4 4320        block4c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4c_bn (BatchNormalization) (None, None, None, 4 1920        block4c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4c_activation (Activation) (None, None, None, 4 0           block4c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_excite (Multiply)    (None, None, None, 4 0           block4c_activation[0][0]         \n",
            "                                                                 block4c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_project_conv (Conv2D)   (None, None, None, 8 38400       block4c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_project_bn (BatchNormal (None, None, None, 8 320         block4c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4c_drop (Dropout)          (None, None, None, 8 0           block4c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_add (Add)               (None, None, None, 8 0           block4c_drop[0][0]               \n",
            "                                                                 block4b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_conv (Conv2D)    (None, None, None, 4 38400       block4c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_bn (BatchNormali (None, None, None, 4 1920        block5a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_activation (Acti (None, None, None, 4 0           block5a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_dwconv (DepthwiseConv2D (None, None, None, 4 12000       block5a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5a_bn (BatchNormalization) (None, None, None, 4 1920        block5a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5a_activation (Activation) (None, None, None, 4 0           block5a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_squeeze (GlobalAvera (None, 480)          0           block5a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_excite (Multiply)    (None, None, None, 4 0           block5a_activation[0][0]         \n",
            "                                                                 block5a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_project_conv (Conv2D)   (None, None, None, 1 53760       block5a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_project_bn (BatchNormal (None, None, None, 1 448         block5a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5b_expand_conv (Conv2D)    (None, None, None, 6 75264       block5a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_expand_bn (BatchNormali (None, None, None, 6 2688        block5b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5b_expand_activation (Acti (None, None, None, 6 0           block5b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_dwconv (DepthwiseConv2D (None, None, None, 6 16800       block5b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5b_bn (BatchNormalization) (None, None, None, 6 2688        block5b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5b_activation (Activation) (None, None, None, 6 0           block5b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_squeeze (GlobalAvera (None, 672)          0           block5b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_excite (Multiply)    (None, None, None, 6 0           block5b_activation[0][0]         \n",
            "                                                                 block5b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_project_conv (Conv2D)   (None, None, None, 1 75264       block5b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_project_bn (BatchNormal (None, None, None, 1 448         block5b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5b_drop (Dropout)          (None, None, None, 1 0           block5b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_add (Add)               (None, None, None, 1 0           block5b_drop[0][0]               \n",
            "                                                                 block5a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_expand_conv (Conv2D)    (None, None, None, 6 75264       block5b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5c_expand_bn (BatchNormali (None, None, None, 6 2688        block5c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5c_expand_activation (Acti (None, None, None, 6 0           block5c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_dwconv (DepthwiseConv2D (None, None, None, 6 16800       block5c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5c_bn (BatchNormalization) (None, None, None, 6 2688        block5c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5c_activation (Activation) (None, None, None, 6 0           block5c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_excite (Multiply)    (None, None, None, 6 0           block5c_activation[0][0]         \n",
            "                                                                 block5c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_project_conv (Conv2D)   (None, None, None, 1 75264       block5c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_project_bn (BatchNormal (None, None, None, 1 448         block5c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5c_drop (Dropout)          (None, None, None, 1 0           block5c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_add (Add)               (None, None, None, 1 0           block5c_drop[0][0]               \n",
            "                                                                 block5b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_conv (Conv2D)    (None, None, None, 6 75264       block5c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_bn (BatchNormali (None, None, None, 6 2688        block6a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_activation (Acti (None, None, None, 6 0           block6a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_dwconv_pad (ZeroPadding (None, None, None, 6 0           block6a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6a_dwconv (DepthwiseConv2D (None, None, None, 6 16800       block6a_dwconv_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_bn (BatchNormalization) (None, None, None, 6 2688        block6a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6a_activation (Activation) (None, None, None, 6 0           block6a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_squeeze (GlobalAvera (None, 672)          0           block6a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_excite (Multiply)    (None, None, None, 6 0           block6a_activation[0][0]         \n",
            "                                                                 block6a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_project_conv (Conv2D)   (None, None, None, 1 129024      block6a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_project_bn (BatchNormal (None, None, None, 1 768         block6a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6b_expand_conv (Conv2D)    (None, None, None, 1 221184      block6a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_expand_bn (BatchNormali (None, None, None, 1 4608        block6b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6b_expand_activation (Acti (None, None, None, 1 0           block6b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_dwconv (DepthwiseConv2D (None, None, None, 1 28800       block6b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6b_bn (BatchNormalization) (None, None, None, 1 4608        block6b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6b_activation (Activation) (None, None, None, 1 0           block6b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_squeeze (GlobalAvera (None, 1152)         0           block6b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_excite (Multiply)    (None, None, None, 1 0           block6b_activation[0][0]         \n",
            "                                                                 block6b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_project_conv (Conv2D)   (None, None, None, 1 221184      block6b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_project_bn (BatchNormal (None, None, None, 1 768         block6b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6b_drop (Dropout)          (None, None, None, 1 0           block6b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_add (Add)               (None, None, None, 1 0           block6b_drop[0][0]               \n",
            "                                                                 block6a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_expand_conv (Conv2D)    (None, None, None, 1 221184      block6b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6c_expand_bn (BatchNormali (None, None, None, 1 4608        block6c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6c_expand_activation (Acti (None, None, None, 1 0           block6c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_dwconv (DepthwiseConv2D (None, None, None, 1 28800       block6c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6c_bn (BatchNormalization) (None, None, None, 1 4608        block6c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6c_activation (Activation) (None, None, None, 1 0           block6c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_excite (Multiply)    (None, None, None, 1 0           block6c_activation[0][0]         \n",
            "                                                                 block6c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_project_conv (Conv2D)   (None, None, None, 1 221184      block6c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_project_bn (BatchNormal (None, None, None, 1 768         block6c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6c_drop (Dropout)          (None, None, None, 1 0           block6c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_add (Add)               (None, None, None, 1 0           block6c_drop[0][0]               \n",
            "                                                                 block6b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6d_expand_conv (Conv2D)    (None, None, None, 1 221184      block6c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6d_expand_bn (BatchNormali (None, None, None, 1 4608        block6d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6d_expand_activation (Acti (None, None, None, 1 0           block6d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_dwconv (DepthwiseConv2D (None, None, None, 1 28800       block6d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6d_bn (BatchNormalization) (None, None, None, 1 4608        block6d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6d_activation (Activation) (None, None, None, 1 0           block6d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_excite (Multiply)    (None, None, None, 1 0           block6d_activation[0][0]         \n",
            "                                                                 block6d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_project_conv (Conv2D)   (None, None, None, 1 221184      block6d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_project_bn (BatchNormal (None, None, None, 1 768         block6d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6d_drop (Dropout)          (None, None, None, 1 0           block6d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_add (Add)               (None, None, None, 1 0           block6d_drop[0][0]               \n",
            "                                                                 block6c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block7a_expand_conv (Conv2D)    (None, None, None, 1 221184      block6d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block7a_expand_bn (BatchNormali (None, None, None, 1 4608        block7a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7a_expand_activation (Acti (None, None, None, 1 0           block7a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_dwconv (DepthwiseConv2D (None, None, None, 1 10368       block7a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block7a_bn (BatchNormalization) (None, None, None, 1 4608        block7a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block7a_activation (Activation) (None, None, None, 1 0           block7a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_squeeze (GlobalAvera (None, 1152)         0           block7a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_excite (Multiply)    (None, None, None, 1 0           block7a_activation[0][0]         \n",
            "                                                                 block7a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_project_conv (Conv2D)   (None, None, None, 3 368640      block7a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_project_bn (BatchNormal (None, None, None, 3 1280        block7a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "top_conv (Conv2D)               (None, None, None, 1 409600      block7a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "top_bn (BatchNormalization)     (None, None, None, 1 5120        top_conv[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "top_activation (Activation)     (None, None, None, 1 0           top_bn[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 4,049,571\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,571\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I88dvtgJZdwJ"
      },
      "source": [
        "You can see how each of the different layers have a certain number of parameters each. Since we are using a pre-trained model, you can think of all of these parameters are patterns the base model has learned on another dataset. And because we set base_model.trainable = False, these patterns remain as they are during training (they're frozen and don't get updated)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV28Cr9eDCGN",
        "outputId": "16d04fea-e52a-487b-d219-b4436482b9f0"
      },
      "source": [
        "model_0.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (InputLayer)     [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "efficientnetb0 (Functional)  (None, None, None, 1280)  4049571   \n",
            "_________________________________________________________________\n",
            "global_average_pooling_layer (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 10)                12810     \n",
            "=================================================================\n",
            "Total params: 4,062,381\n",
            "Trainable params: 12,810\n",
            "Non-trainable params: 4,049,571\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFt_jesiZuHF"
      },
      "source": [
        "Our overall model has five layers but really, one of those layers (efficientnetb0) has 236 layers.\n",
        "\n",
        "You can see how the output shape started out as (None, 224, 224, 3) for the input layer (the shape of our images) but was transformed to be (None, 10) by the output layer (the shape of our labels), where None is the placeholder for the batch size.\n",
        "\n",
        "Notice too, the only trainable parameters in the model are those in the output layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "_rLfQB-5DCJd",
        "outputId": "d1ec3dd8-b289-4066-f5af-3eb87936d89d"
      },
      "source": [
        "plot_loss_curves(history_10_percent)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEWCAYAAAB2X2wCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deVxVdf7H8deHXREBWURFxAXBHdMsNUvN0lZbLLN9daqZahpzdKZlWmcqa6apmepnjVO2Ta7tWZmaLbaggogKrigusSgIKrJ9f3+cq6KyyuWeey+f5+NxHwLn3HM/XOXtl+/5ns8RYwxKKaU8n4/dBSillHIODXSllPISGuhKKeUlNNCVUspLaKArpZSX0EBXSikvoYGulFJeQgNdtQgisk1Exthdh1LNSQNdKaW8hAa6arFEJFBEXhCRXY7HCyIS6NgWKSKfiEihiOwVkW9FxMexbZqI7BSRYhHJFJFz7f1OlLL42V2AUjZ6EDgTSAYM8CHwEPAwMAXIAaIc+54JGBFJBH4HnG6M2SUi8YCva8tWqmY6Qlct2XXA48aYXGNMHvAYcINjWznQAehijCk3xnxrrMZHlUAg0FtE/I0x24wxm22pXqkTaKCrlqwjkF3t82zH1wBmAJuAL0Vki4hMBzDGbAJ+DzwK5IrI/0SkI0q5AQ101ZLtArpU+zzO8TWMMcXGmCnGmG7ApcAfjsyVG2PeNcac5XiuAZ5xbdlK1UwDXbUk/iISdOQBvAc8JCJRIhIJPAK8DSAiF4tIDxERoAhrqqVKRBJFZLTj5GkpcAiosufbUep4GuiqJfkMK4CPPIKAFGANkA6sAp507JsALAZKgBXAy8aYpVjz508D+cAeIBr4k+u+BaVqJ3qDC6WU8g46QldKKS+hga6UUl5CA10ppbyEBrpSSnkJ2y79j4yMNPHx8Xa9vFJKeaSVK1fmG2OiatpmW6DHx8eTkpJi18srpZRHEpHs2rbplItSSnkJDXSllPISGuhKKeUltB+6Uuo45eXl5OTkUFpaancpLVpQUBCxsbH4+/s3+Dka6Eqp4+Tk5BASEkJ8fDxWbzLlasYYCgoKyMnJoWvXrg1+nk65KKWOU1paSkREhIa5jUSEiIiIRv+WpIGulDqJhrn9TuXvwOMCfXfRIR77OIPySm1BrZRS1XlcoK/JKeK/32/j5aV6G0ellKrO4wJ9bJ8YLkvuyEtLNrJ2Z5Hd5SilnKywsJCXX3650c+78MILKSwsrHOfRx55hMWLF59qaTVq06aNU4/XFB4X6ACPXtqHdsEBPDA3jbIKnXpRypvUFugVFRV1Pu+zzz4jLCyszn0ef/xxxowZ06T63JlHLlsMax3A01f249Y3Unjx6408MDbR7pKU8kqPfZzBul37nXrM3h3b8pdL+tS6ffr06WzevJnk5GT8/f0JCgoiPDycDRs2kJWVxWWXXcaOHTsoLS3lvvvuY/LkycCx/lAlJSVccMEFnHXWWfzwww906tSJDz/8kFatWnHzzTdz8cUXM2HCBOLj47npppv4+OOPKS8vZ+7cuSQlJZGXl8e1117Lrl27GDp0KF999RUrV64kMjKyzu/LGMMf//hHPv/8c0SEhx56iIkTJ7J7924mTpzI/v37qaio4JVXXmHYsGHcdtttpKSkICLceuut3H///U1+bz1yhA4wOqk9Vw2K5ZVvNpO2o+5fs5RSnuPpp5+me/fupKamMmPGDFatWsU///lPsrKyAJg1axYrV64kJSWFF198kYKCgpOOsXHjRn7729+SkZFBWFgY8+fPr/G1IiMjWbVqFXfddRfPPfccAI899hijR48mIyODCRMmsH379gbVvWDBAlJTU0lLS2Px4sVMnTqV3bt38+677zJ27Nij25KTk0lNTWXnzp2sXbuW9PR0brnlllN8t47nkSP0Ix6+pDffbcpnytw0PrnnLIL8fe0uSSmvUtdI2lWGDBly3MU1L774IgsXLgRgx44dbNy4kYiIiOOe07VrV5KTkwEYNGgQ27Ztq/HYV1xxxdF9FixYAMB333139Pjjxo0jPDy8QXV+9913TJo0CV9fX9q3b88555zDL7/8wumnn86tt95KeXk5l112GcnJyXTr1o0tW7Zwzz33cNFFF3H++ec3/A2pg8eO0AHaBvnzzJX92ZRbwj++yrK7HKVUMwgODj768bJly1i8eDErVqwgLS2NgQMH1njxTWBg4NGPfX19a51/P7JfXfs01dlnn83y5cvp1KkTN998M7NnzyY8PJy0tDRGjhzJq6++yu233+6U1/LoQAc4u2cUk4bEMfPbLazM3mt3OUqpJgoJCaG4uLjGbUVFRYSHh9O6dWs2bNjAjz/+6PTXHz58OHPmzAHgyy+/ZN++fQ163ogRI3j//feprKwkLy+P5cuXM2TIELKzs2nfvj133HEHt99+O6tWrSI/P5+qqiquvPJKnnzySVatWuWU2j16yuWIBy/qxfKsPB6Yu4bP7h1BqwCdelHKU0VERDB8+HD69u1Lq1ataN++/dFt48aN49VXX6VXr14kJiZy5plnOv31//KXvzBp0iTeeusthg4dSkxMDCEhIfU+7/LLL2fFihUMGDAAEeHZZ58lJiaGN998kxkzZuDv70+bNm2YPXs2O3fu5JZbbqGqylql97e//c0ptYsxxikHaqzBgwcbZ96x6IfN+Vz72k/cOrwrj1zS22nHVaqlWb9+Pb169bK7DNscPnwYX19f/Pz8WLFiBXfddRepqam21FLT34WIrDTGDK5pf68YoQMM6x7JTUO78N8ftjK2T3vO6BZR/5OUUuoE27dv5+qrr6aqqoqAgABee+01u0tqMK8JdIBpFySxLCuPqfPW8Pl9IwgO9KpvTynlAgkJCaxevfq4rxUUFHDuueeetO/XX3990gobO3lV4rUO8GPGhAFMnLmCpz/fwBOX9bW7JKWUF4iIiLBt2qUxPH6Vy4mGdG3HrcO78taP2Xy/Kd/ucpRSymW8LtABpo5NpFtkMH+ct4bi0nK7y1FKKZeoN9BFZJaI5IrI2lq2h4rIxyKSJiIZIuKca1ibIMjfl+euHsDuokP89bP1dpejlFIu0ZAR+hvAuDq2/xZYZ4wZAIwEnheRgKaX1jSnxYUz+ezuvPfzDpZl5tpdjlJKNbt6A90Ysxyo6xJMA4SIdb+kNo59m+ca2kb6/ZgEEqLbMH1+OkWHdOpFKW9UVz/ybdu20bdvy1kc4Yw59H8BvYBdQDpwnzGmxiblIjJZRFJEJCUvL88JL123IH9fnr96AHklh3n843XN/npKKWUnZyxbHAukAqOB7sBXIvKtMeakJsrGmJnATLCuFHXCa9erf2wYd4/szktLNnFB3xjG9G5f/5OUUpbPp8OedOceM6YfXPB0rZunT59O586d+e1vfwvAo48+ip+fH0uXLmXfvn2Ul5fz5JNPMn78+Ea9bGlpKXfddRcpKSn4+fnx97//nVGjRpGRkcEtt9xCWVkZVVVVzJ8/n44dO3L11VeTk5NDZWUlDz/8MBMnTmzSt+0Kzhih3wIsMJZNwFYgyQnHdZp7RieQFBPCnxams+9Amd3lKKXqMHHixKPNsQDmzJnDTTfdxMKFC1m1ahVLly5lypQpNLZtyb///W9EhPT0dN577z1uuukmSktLefXVV7nvvvtITU0lJSWF2NhYFi1aRMeOHUlLS2Pt2rWMG1fXaUT34YwR+nbgXOBbEWkPJAJbnHBcpwnw8+H5qwcw/l/f8+jHGfzzmoF2l6SUZ6hjJN1cBg4cSG5uLrt27SIvL4/w8HBiYmK4//77Wb58OT4+PuzcuZNff/2VmJiYBh/3u+++45577gEgKSmJLl26kJWVxdChQ3nqqafIycnhiiuuICEhgX79+jFlyhSmTZvGxRdfzIgRI5rr23WqhixbfA9YASSKSI6I3CYid4rInY5dngCGiUg68DUwzRjjdlf09OkYyr3nJvBh6i4Wrd1tdzlKqTpcddVVzJs3j/fff5+JEyfyzjvvkJeXx8qVK0lNTaV9+/Y19kE/Fddeey0fffQRrVq14sILL2TJkiX07NmTVatW0a9fPx566CEef/xxp7xWc6t3hG6MmVTP9l2Ac2630czuGtmdr9b9yoML13J6fDsi2gTW/ySllMtNnDiRO+64g/z8fL755hvmzJlDdHQ0/v7+LF26lOzs7EYfc8SIEbzzzjuMHj2arKwstm/fTmJiIlu2bKFbt27ce++9bN++nTVr1pCUlES7du24/vrrCQsL4/XXX2+G79L5vPJK0dr4+/rw3FUDKC6t4OEP1zZ6Dk4p5Rp9+vShuLiYTp060aFDB6677jpSUlLo168fs2fPJimp8afp7r77bqqqqujXrx8TJ07kjTfeIDAwkDlz5tC3b1+Sk5NZu3YtN954I+np6QwZMoTk5GQee+wxHnrooWb4Lp3Pa/qhN8bLyzbx7KJMXpo0kEsGdLSlBqXcVUvvh+5OGtsPvUWN0I+YPKIbyZ3DePjDteQWO2ceTiml7NYiA93PMfVyqKySBxfq1ItSni49PZ3k5OTjHmeccYbdZbmcV/VDb4we0W2YOjaRJz9dz8LVO7nitFi7S1LKbRhjsLp5eIZ+/fp5RL/yxjiVgWaLHKEfccvwrgzuEs6jH2Wwp0inXpQCCAoKoqCgQH9ztZExhoKCAoKCghr1vBY7Qgfw9RGeu2oA4/65nOkL1vDfm0/3qFGJUs0hNjaWnJwcXNFvSdUuKCiI2NjGzRy06EAHiI8MZvq4JB79eB1zU3K4+vTOdpeklK38/f3p2rWr3WWoU9Cip1yOuHFoPGd2a8fjn6xjZ+Ehu8tRSqlTooEO+PgIMyYMwBjDtHlrdO5QKeWRNNAdOrdrzZ8v6sV3m/J556ftdpejlFKNpoFezbVD4hiREMlfP1vPjr0H7S5HKaUaRQO9GhHhmSv74yvCA3PTqKrSqRellOfQQD9Bx7BWPHxxb37aupfZK7bZXY5SSjWYBnoNrhocy6jEKJ5etIGt+QfsLkcppRpEA70GIsLTV/YnwNeHqXPTqNSpF6WUB9BAr0X7tkE8Nr4PKdn7mPXdVrvLUUqpemmg1+Gy5E6c17s9M77MZFNuid3lKKVUnTTQ6yAi/PXyfgQH+DJlbhoVlVV2l6SUUrXSQK9HVEggj4/vS9qOQmZ+u8XucpRSqlYa6A1wyYCOXNSvAy98tZHMPcV2l6OUUjWqN9BFZJaI5IrI2jr2GSkiqSKSISLfOLdE9/D4+D6EBPkxZW4q5Tr1opRyQw0Zob8BjKtto4iEAS8Dlxpj+gBXOac09xLRJpCnLu/H2p37eXnpZrvLUUqpk9Qb6MaY5cDeOna5FlhgjNnu2D/XSbW5nXF9Yxif3JGXlmwkY1eR3eUopdRxnDGH3hMIF5FlIrJSRG6sbUcRmSwiKSKS4ql3Q3ns0j6EBwcwZU4aZRU69aKUch/OCHQ/YBBwETAWeFhEeta0ozFmpjFmsDFmcFRUlBNe2vXCWgfw9BX92LCnmJeWbLS7HKWUOsoZgZ4DfGGMOWCMyQeWAwOccFy3dW6v9kwYFMvLyzaTtqPQ7nKUUgpwTqB/CJwlIn4i0ho4A1jvhOO6tYcv7k1Um0AemJtGaXml3eUopVSDli2+B6wAEkUkR0RuE5E7ReROAGPMemARsAb4GXjdGFPrEkdvEdrKn2cm9Gdjbgn/WJxldzlKKYVffTsYYyY1YJ8ZwAynVORBzukZxaQhnXlt+RbO7x3DoC7hdpeklGrB9ErRJnrwot50CG3F1LlpHCrTqRellH000JuoTaAfMyb0Z0v+AZ77MtPucpRSLZgGuhMM6xHJjUO7MOv7rfy8ta5rsJRSqvlooDvJtHFJdA5vzQNz0zhYVmF3OUqpFkgD3UmCA/147qoB7Nh3kKc/32B3OUqpFkgD3YmGdG3HLcO6MntFNj9syre7HKVUC6OB7mRTxybSLTKYqfPWUFxabnc5SqkWRAPdyVoF+DLjqgHsLjrEXz/TqRellOtooDeDQV3CuePsbrz383a+yfLMrpJKKc+jgd5M7h/Tk4ToNkybt4aiQzr1opRqfhrozSTI35fnrhpAXslhnvhknd3lKKVaAA30ZjSgcxh3ndOdeStz+Hr9r3aXo5TychrozezecxNIiglh+oJ0Cg+W2V2OUsqLaaA3swA/H56/egD7DpTx6EcZdpejlPJiGugu0KdjKPeMTuCD1F0sWrvH7nKUUl5KA91F7h7Vnb6d2vLgwnQKSg7bXY5SygtpoLuIv68Pz1+VzP7Sch75UKdelFLOp4HuQokxIfx+TE8+Td/NJ2t22V2OUsrLaKC72G/O7saAzmE8/MFa8op16kUp5Twa6C7m5+vD81f150BZJX9emI4xxu6SlFJeQgPdBj2iQ5h6fiJfrfuVD1J32l2OUspL1BvoIjJLRHJFZG09+50uIhUiMsF55XmvW8/qyuAu4fzlwwx+3V9qdzlKKS/QkBH6G8C4unYQEV/gGeBLJ9TUIvj6CDOuGkBZZRXT56/RqRelVJPVG+jGmOVAfXc+vgeYD+Q6o6iWomtkMNPGJbE0M4+5K3PsLkcp5eGaPIcuIp2Ay4FXGrDvZBFJEZGUvDztEw5w09B4zujajic+XseuwkN2l6OU8mDOOCn6AjDNGFNV347GmJnGmMHGmMFRUVFOeGnP5+MjzJgwgEpjmKZTL0qpJnBGoA8G/ici24AJwMsicpkTjttixEW05s8X9uLbjfm8+/N2u8tRSnmoJge6MaarMSbeGBMPzAPuNsZ80OTKWpjrzojjrB6RPPXpenbsPWh3OUopD9SQZYvvASuARBHJEZHbROROEbmz+ctrOUSEZyb0x0eEqfPSqKrSqRelVOP41beDMWZSQw9mjLm5SdU0VPGvENLeJS/lSp3CWvHwxb2YNj+d2Su2cfPwrnaXpJTyIJ53pWjGB/BiMqxdYHclzeLqwZ0ZmRjF04s2sC3/gN3lKKU8iOcFetxQiOkH826Br5+AqnoX13gUEeHpK/oT4OvDA3PTqNSpF6VUA3leoIe0h5s+hoE3wLfPwfvXQel+u6tyqpjQIB69tA8p2fv47/db7S5HKeUhPC/QAfwC4dKX4IJnIesL+M95sHeL3VU51eUDOzGmV3ue/SKTTbkldpejlPIAnhnoACJwxm/ghgVQvAdmjoIty+yuymlEhL9e0ZfWAb5MmZtGRaV3TS0ppZzPcwP9iG4jYfJSCOkAb10BP74KXnK1ZXRIEI+P70vajkJmfutdv4EopZzP8wMdoF03uP0r6DkWFk2Dj34HFd5xN6BL+nfgwn4xvPDVRjL3FNtdjlLKjXlHoAMEhsDEd+DsqbD6bXjzEmu9uocTEZ4Y35eQID+mzE2lXKdelFK18J5AB/DxgdEPwVVvwO418Noo2LXa7qqaLKJNIE9e1pe1O/fzyrLNdpejlHJT3hXoR/S5HG77AhCYNQ7S59ldUZNd0K8Dlw7oyItfbyRjV5Hd5Sil3JB3BjpAhwEweRl0HAjzb4PFj0JVpc1FNc1jl/YhPDiAKXPSKKvQqRel1PG8N9AB2kTBjR/BoJvhu3/Ae5Og1HNHt+HBAfzt8n5s2FPMS0s22l2OUsrNeHegA/gFwMUvwIXPwabF8PoYKPDceegxvdtz5WmxvLxsM2tyCu0uRynlRrw/0MG6CGnIHXDjh3Ag3zpZuulru6s6ZY9c0puoNoFMmZNGablnTyMppZynZQT6EV1HWBchtY2FdybAin975EVIoa38efrKfmzMLeGFxTr1opSytKxABwiPh9u+hMQL4Ys/wwd3Q3mp3VU12sjEaK45vTMzl29m1fZ9dpejlHIDLS/QAQLbwNVvwTnTIe1deOMiqx+Mh3nwol50CG3FAzr1opSipQY6WBchjfoTXD0bctfBzJGwc6XdVTVKSJA/z07oz5b8A8z4ItPucpRSNmu5gX5E7/Fw21fg6w+zLoC09+2uqFGG94jkhjO7MOv7rfy8da/d5SilbKSBDhDTF+5YBrGnw8LJ8OXDHnUR0vQLkugc3pqp89I4WFZhdzlKKZtooB8RHAE3fgCn3w4/vAjvToRDnrHOOzjQjxkT+pNdcJBnPt9gdzlKKZvUG+giMktEckVkbS3brxORNSKSLiI/iMgA55fpIr7+cNHzcPE/YMtSeP1cyPeMZYFndIvgluHxvLkimx825dtdjlLKBg0Zob8BjKtj+1bgHGNMP+AJYKYT6rLX4FutlgGH9sFr58LGr+yuqEH+ODaJrpHBTJ23hpLDOvWiVEtTb6AbY5YDtZ5tM8b8YIw5shD6RyDWSbXZK3641dwrLA7evRq+/6fbX4TUKsCX567qz+6iQzz16Xq7y1FKuZiz59BvAz538jHtExZnteHtdSl89Qgs/A2UH7K7qjoN6tKOO0Z0472ft7M8K8/ucpRSLuS0QBeRUViBPq2OfSaLSIqIpOTleUjYBARbN8wY9RCseR/+eyHs32V3VXW6/7ye9Ihuw7T5ayg6VG53OUopF3FKoItIf+B1YLwxpqC2/YwxM40xg40xg6Oiopzx0q4hAudMtW5xl58FM0fBjl/srqpWQf6+PH/VAHKLD/PkJ+vsLkcp5SJNDnQRiQMWADcYY7KaXpIb63WxdRGSXyC8cSGkvmt3RbUa0DmMO8/pxtyVOXy93vPvraqUql9Dli2+B6wAEkUkR0RuE5E7ReROxy6PABHAyyKSKiIpzViv/dr3tk6Wxp0JH9wFXzwIle65ouTecxNIiglh+oJ0sgsO2F2OUqqZibFp5cbgwYNNSooHZ39luRXmP/8fdB8NE2ZBq3C7qzpJxq4irvm/HymrrOK+MQncMaIb/r56PZlSnkpEVhpjBte0TX+yT5WvP1z4LFzyImz9Fl4bDXnu1yCrT8dQvvrDOYxKjObZRZlc8tJ3rNZ2u0p5JQ30php0E9z8CRwuti5CyvrC7opOEhMaxKs3DGLmDYMoPFjOFa/8wF8+XEtxqa6AUcqbaKA7Q9yZcMdSaNfV6gHz7d/d8iKk8/vE8NUfzuamofHM/jGb8/6+nC8yPK8PvFKqZhrozhLWGW79AvpcDl8/BvNvh7KDdld1kpAgfx69tA8L7hpGWGt/fvPWSn7zVgp7ijzvrk1KqeNpoDtTQGvr5Oi5j8Da+fDfC6Bop91V1WhgXDgf33MW08YlsSwzjzF//4a3Vmyjqsr9frNQSjWMBrqzicCIKTDpPSjYbN0JaftPdldVI39fH+4a2Z0v7z+bgXFhPPxhBhNe/YHMPcV2l6aUOgUa6M0l8QK4fbHVOuCNi2DVW3ZXVKsuEcHMvnUI/5g4gG0FB7noxW+Z8cUGvU+pUh5GA705RSfBHUuszo0f/Q4+n+a2FyGJCJcPjGXxH85hfHIn/r10M+NeWM732ltdKY+hgd7cWreD6+bDmXfDT6/C21fAQfe992e74ACev3oA79x+BgDXvf4TU+aksfdAmc2VKaXqo4HuCr5+MO5vMP7fsH0FvDYKct27X/nwHpEs+v3Z/G5UDz5M3cmYv3/DglU52HVlsVKqfhrorjTwerj5U6un+utjYMNndldUpyB/Xx4Ym8in946gS0Rr/jAnjRv+87P2hVHKTWmgu1rnIdZFSBE94H/XwvIZbnkRUnWJMSHMv3MYT4zvQ9qOQs7/x3JeWbaZ8soqu0tTSlWjgW6H0E5w6yLoNwGWPAnzboEy9x71+vgINwyNP9oX5plFG7QvjFJuRgPdLv6t4IrXYMxjkPEBzBoLhTvsrqpe2hdGKfelgW4nETjr93DtHNiXbV2ElP2D3VU1SE19Yb7UvjBK2UoD3R30PB9u/xpahcGbl8LKN+yuqEFO7AszWfvCKGUrDXR3EdXTCvWuZ8PH98GnD1g30fAA2hdGKfegge5OWoXBdXNh6O/gl9fgrcvhQK333HYr2hdGKftpoLsbH18Y+xRc9irs+BleGwm/ZthdVYNpXxil7KOB7q6SJ8Etn0NFGbx+Hqz/2O6KGkz7wihlDw10dxY7CCYvs5p8vX89LHsGqjznYh7tC6OUa2mgu7u2HeDmz6D/NbDsrzD3JjhcYndVjaJ9YZRyjXoDXURmiUiuiKytZbuIyIsisklE1ojIac4vs4XzD4LLX4Xzn4INn1gXIe3LtruqRtG+MEo1v4aM0N8AxtWx/QIgwfGYDLzS9LLUSURg2O+sVTCFO6yOjdu+s7uqRqveFyZV+8Io5VT1BroxZjlQVwPv8cBsY/kRCBORDs4qUJ2gxxjrphmt2sHs8fDL63ZX1GhH+sIs1r4wSjmVM+bQOwHVm5DkOL52EhGZLCIpIpKSl5fnhJduoSJ7wB1fQ/fR8OkU+OR+azWMh9G+MEo5l0tPihpjZhpjBhtjBkdFRbnypb1PUChM+h8M/z2kzIK3LoMDnrksUPvCKOUczgj0nUDnap/HOr6mmpuPL5z3GFzxOuxcCTNHwZ50u6s6JTX1hbnzrZXaF0apRnBGoH8E3OhY7XImUGSM2e2E46qG6n+VdRFSVQX853yrHa+Hqt4XZmlmrvaFUaoRGrJs8T1gBZAoIjkicpuI3Ckidzp2+QzYAmwCXgPubrZqVe06nQaTl0L7vtZa9SVPedRFSNVV7wuT3Fn7wijVUGLXxR2DBw82KSkptry2V6s4DJ/8AVLfhqSLrfXrgSF2V3XKjDF8kLqTJz5Zz/5D5fzmnG7cMzqBIH9fu0tTyhYistIYM7imbXqlqLfxC4Tx/4JxT0PmZ9YUzN6tdld1ymrrC/OD9oVR6iQa6N5IBM68C65fAPt3WRchLf0r7Ntmd2Wn7MS+MNdqXxilTqJTLt6uYDN8NhU2LwEMdD0HBt4AvS627mvqgUrLK3lpyUb+75sttG3lz8MX9+Ky5E6IiN2lKdXs6ppy0UBvKQp3QOq71tx64XYIDIV+E2Dg9dBxoDWq9zCZe4qZvmANq7cXMiIhkicv60uXiGC7y1KqWWmgq2OqqmDbt7D6bVj/EVSUWitjBl4P/a6G4Ai7K2yUqirDOz9l88yiTMorq/j9mJ7cPqIr/r46m6i8kwa6qtmhQlg7H1a/BbtWg48/JF1oTcl0H21duOQh9hSV8uhHGSzK2NXaW44AABSLSURBVENSTAh/u6IfA+PC7S5LKafTQFf127MWUt+BtP/Bob0Q0hGSr4WB10G7bnZX12BfZuzhkQ8z+LW4lJuGxjPl/J6EBPnbXZZSTqOBrhquogyyPremZDYtBlMFXc6ypmR6j4eA1nZXWK/i0nKe/zKLN1dso31IEI+P78P5fWLsLkspp9BAV6dm/y7rROrqt2HfVggIgX5XWlMynQa5/YnU1dv38acF6WzYU8y4PjE8emkfYkKD7C5LqSbRQFdNYwxk/2AF+7oPoPwgRCVZo/b+10Ab9+2cWV5ZxevfbuWFxVn4+/owbVwi153RBR8f9/7PSKnaaKAr5yndDxkLrHDP+QV8/KDnOGvU3mMM+PrZXWGNsgsO8ODCtXy3KZ/T4sL42xX9SYzx3JYIquXSQFfNI3eDta497X9wIA/atIcBk6xwj+xhd3UnMcawcPVOnvxU+8Ioz6WBrppXZTls/BJWvWX9aSohbqjjROplENjG7gqPs/dAGU99up75q3KIj2jNXy/vx7AekXaXpVSDaKAr1yneY43YV78NBRvBPxj6Xm6N2juf4VYnUr/flM+DC9PZVnCQK0+L5cGLetEuOMDuspSqkwa6cj1jYMfPsHo2rF0I5QcgIsEatQ+4BkLcYxmh9oVRnkYDXdnrcIm1Omb127B9BYgvJJxvhXvPseBr/4U/G/bs508L0lm9vZCzekRy87B4hvWIoHWAe57kVS2XBrpyH/mbrBOpqe9ByR4IjrJG7MnXQ3SSraUd6Qsz44tM9pdWEODnw5ndIhidGMWopGht/KXcgga6cj+VFdaVqKvfgqxF1v1QY0+3Ru19roCgtraVdriikl+27mNpZi5LM3PZkncAgG6RwYxKimZUYjRDurYjwE8bgCnX00BX7q0kD9a8b4V73gbwb22tjhl4PXQZZvuJ1G35B1iWmcuSzDx+3FJAWUUVwQG+DO8RyeikaEYmRusVqMplNNCVZzAGdq60gj19PpQVW43Bkq+zGoW17Wh3hRwsq+CHTQXW6H1DLruKSgHo3aEto5KiGJUYzcC4cHz1SlTVTDTQlecpO2j1a1/9ttW/XXysK1EHXg89LwA/+5cXGmPI+rWEpZm5LNmQy8rsfVRWGcJa+3N2QhSjk6I5u2eULoVUTtXkQBeRccA/AV/gdWPM0ydsjwPeBMIc+0w3xnxW1zE10FWD7d0Cq9+xGoUV74LWEdB/ohXu7fvYXd1RRYfK+XZjHks35PFNVi75JWWIwMDOYYxKjGZUUjR9OrbVJZGqSZoU6CLiC2QB5wE5wC/AJGPMumr7zARWG2NeEZHewGfGmPi6jquBrhqtqhI2L7WmZDZ8ClXl1u3zBt4Afa+EVmF2V3hUVZUhfWfR0amZtJwiAKJDAhmZaI3eh/eI1F7tqtGaGuhDgUeNMWMdn/8JwBjzt2r7/B+wxRjzjGP/540xw+o6rga6apIDBZA+x2o3kJsBfkHQ61Jr1B4/AnzcawVKXvFhvsnKY2lmLsuz8igurcDfVzg9vp1j9B5F96g2OnpX9WpqoE8Axhljbnd8fgNwhjHmd9X26QB8CYQDwcAYY8zKGo41GZgMEBcXNyg7O/vUviOljjAGdqdac+1r5sLhIgjr4rgidRKEdba7wpOUV1axKnsfSzPzWLohl8xfiwHo3K7V0amZod0itGmYqpErAv0PjmM97xih/wfoa4ypqu24OkJXTld+yJqKWf0WbFkGCHQfZYV74kXg755LC3cWHmLphlyWZeby/aYCDpVXEuTvw7DukYxyXNQUG+7+d4pSruGKKZcMrNDf4fh8C3CmMSa3tuNqoKtmtS/bOoma+g4U7YCgsGMnUjv0t7u6WpWWV/LT1r0s3WBd1JRdcBCAhOg2R9e8D44Px9/XvaaUlOs0NdD9sE6KngvsxDopeq0xJqPaPp8D7xtj3hCRXsDXQCdTx8E10JVLVFXB1m+sKZn1H0PlYYjpb51I7TcBWrezu8JaGWPYmn+AJRtyWZaZx09bCyivNIQE+jGiZyQjE6MZmRhFdIh7/uahmoczli1eCLyAtSRxljHmKRF5HEgxxnzkWNnyGtAGMMAfjTFf1nVMDXTlcof2Qfo8a0pmdxr4BkDSxXDaDdB1pNudSD1RyeEKvt+Uf3T0/uv+wwD06xTqaEkQRf/YML2oycvphUVKnWj3Gms6Zs37VtCHdrauRk2+FsLj7a6uXsYY1u8uProsctX2fVQZaBccwMieUYxMiuachChCW+uySG+jga5UbSoOO06kvg2blwDGWvYYNxSiEq1HRA/wb2V3pXXad6CM5RutVTPfZOWx72A5PgKDuoQfbSiWFBOiyyK9gAa6Ug1RlGO19V07H/KzrFvpASDWqD0qCaJ6Ov5MhMieEOh+N5qurDKk5RQenZpZu3M/AB1CgxiZaE3NDO8RSXCg9nr3RBroSjVWxWEo2Gx1f8zPsv7My7Juq1dZdmy/trEnhLxjVO9GJ1t/3V/KN5l5LNmQy3eb8ik5XEGArw9ndGt3dN1710jt9e4pNNCVcpbKCti3DfIzj4X8kdAvP3hsv+DoY1M2R0I+KgnaRNvaDrisooqU7CPLIvPYlFsCQNfIYEYmWt0iz+jWjkA/vajJXWmgK9Xcqqpgfw7kHQn6zGOPw0XH9gsKtYI98sio3jGN0zbWllU22wsOsizL6ha5YnMBhyuqaB3gy7DuR3q9R9ExzL3PH7Q0GuhK2cUYKPn1+NF8XqY1wj+Qd2w//2Ar2I+O5h0j+vB48HHNaPlQWSUrtuSzdIM1PbOz8BAASTEhR0+snhYXhp9e1GQrDXSl3NGBAsfUTeaxkM/LhP07j+3jG2itsok6IejbdW/WnvDGGDblHuv1nrJtHxVVhrZBfpzd0+oWeU7PKCLaBDZbDapmGuhKeZLS/ZC/0TGar3ZSdl821nV7gPhad3OqHvJRiRCRAAHO7/uyv7Sc7zbmH517zy85jAgMiLV6vQ/qEk7vjm31Zh4uoIGulDcoP+QI+sxqJ2UzrRuAVFU4dhIIizs+6CMTremcoFCnlFFVZcjYtf/o6D0tp5AjMdIhNIjeHdrSp2NbendsS+8OoXRu10rXvzuRBrpS3qyizAr1o9M3jvn6/Cyrd80RIR2qhXy1pZbBkU16+cKDZWTs2s+6XftZt3s/GbuK2Jx3gMoqK1tCAv3o1bHtcUGfEB1CgJ/OxZ8KDXSlWqKqSijMPj7kj0zhlJUc2691xMkhH5Vo/QdwiiPr0vJKMvcUs263FfQZu4pYv7uYQ+XWxVr+vkJCdAi9OzpCvkNbenVsS1u9g1O9NNCVUscYY514PXF5Zd4GKC08tl9g2xPW0TseoXGntMSyssqQXXDAGs3v3u8Y1ReRX3LsQq24dq3p3aHtsaDv2JaYtkE6ZVONBrpSqn7GWEspjwt6x4i+5Ndj+/m1gsiE41shhHe17g51CvP0ucWlx6ZsHGG/Nf/A0e3tggOOD/kObekaGdxil09qoCulmubQvpPX0edlWjcPqS4o1DopG9bF+jO0s+Nzx6OBN/IuOVzBht37q03Z7CdzTzFlldZN0AL9fEjq0Pa4oE+KCaF1gPf3p9FAV0o1j8Ml1gi+MBsKd0Dh9uMf5QeO3z+w7fEBf1Lgh9c6b19eWcXmvJKjI/kjUzdFh8oB62ndIoPp3TH0uBOwkV62Vl4DXSnlesZYI/vC7Gohf0LolxUf/5yAEGvqpsbQ72I1PasW+MYYdhWVkrGzqNq8/P6jV7kCRIcEHreMsk/HtsS1a42Ph94IpK5A9/7fT5RS9hCxArh1O+g48OTtxlgnYY8b1VcL/OwVx/fBAatFQrXAl7A4OoV2plNYF87vEgfBCSBC0cFyMnYXHTcvv3xj/tGllG0C/ejVIaTalE0oCe3beHxTMh2hK6Xc16FCa57+xKmcI4/qq3LAOmF74gg/LA5C4yht04mNJa1Zt+fYlM363fs5UGYtpfTzEXpEt3GM5B1B3yHU7e76pFMuSinvVLq/7sA/tPf4/f2CHFM4VuhXhcaR79eeTYfDSS1pyy95/mTsLiG3+NgFWZ3CWlWbsmlLn06hdAy1bymlTrkopbxTUFsI6gPt+9S8/XCxNY1zNPSzj03t7F6Dz8F8ooFoYBhYNw4P7UxZh04U+MewvSqS9YfCWLU7hPfXt+FXE04VPoS28j++xUHHtnSPaoO/zUspdYSulGq5yg5UC/waTt4eyD1u9yoff0qCYsj1iWZreTvWHQxjW2UkOSaKXN9owqLj6NUp/OhovleHtk6/1V+TR+giMg74J+ALvG6MebqGfa4GHsVqB5dmjLn2lCtWSilXCAiG6CTrUZOyg9a9ZousoPcp3E5bx6NHYTrn+e6xUtGhYq8ve/ZGsD01kq0mkm+J4nBwLIGR8UTE9iAuvge9Y9sRHRLULN9OvSN0EfEFsoDzgBzgF2CSMWZdtX0SgDnAaGPMPhGJNsbk1nhABx2hK6U8XnmpFfiF2UendUzhdsrzt1FVuJ3AQ7kIxzK2wviwh3ZsiLuWMbc9cUov2dQR+hBgkzFmi+Ng/wPGA+uq7XMH8G9jzD6A+sJcKaW8gn8QRPawHg4CHO0KX3HYEfjbOZi3jb07N1Gat5UuXbo2SzkNCfROQPXre3OAM07YpyeAiHyP9QvIo8aYRSceSEQmA5MB4uLiTqVepZTyHH6BENEdIrrTujs4/9Yjx3PWKVk/IAEYCUwCXhORk5o2GGNmGmMGG2MGR0VFOemllVJKQcMCfSfQudrnsY6vVZcDfGSMKTfGbMWac09wTolKKaUaoiGB/guQICJdRSQAuAb46IR9PsAanSMikVhTMFucWKdSSql61BvoxpgK4HfAF8B6YI4xJkNEHheRSx27fQEUiMg6YCkw1RhT0FxFK6WUOpleWKSUUh6krmWLLfOWH0op5YU00JVSyktooCullJewbQ5dRPKA7FN8eiSQ78RynMVd6wL3rU3rahytq3G8sa4uxpgaL+SxLdCbQkRSajspYCd3rQvctzatq3G0rsZpaXXplItSSnkJDXSllPISnhroM+0uoBbuWhe4b21aV+NoXY3TouryyDl0pZRSJ/PUEbpSSqkTaKArpZSXcOtAF5FxIpIpIptEZHoN2wNF5H3H9p9EJN5N6rpZRPJEJNXxuN1Fdc0SkVwRWVvLdhGRFx11rxGR09ykrpEiUlTt/XrEBTV1FpGlIrJORDJE5L4a9nH5+9XAulz+fjleN0hEfhaRNEdtj9Wwj8t/JhtYl10/k74islpEPqlhm/PfK2OMWz6w7ny0GeiGdUenNKD3CfvcDbzq+Pga4H03qetm4F82vGdnA6cBa2vZfiHwOdZdss4EfnKTukYCn7j4veoAnOb4OASrh/+Jf48uf78aWJfL3y/H6wrQxvGxP/ATcOYJ+9jxM9mQuuz6mfwD8G5Nf1/N8V658wj96L1MjTFlwJF7mVY3HnjT8fE84FwRETeoyxbGmOXA3jp2GQ/MNpYfgTAR6eAGdbmcMWa3MWaV4+NirNbQnU7YzeXvVwPrsoXjfShxfOrveJy4qsLlP5MNrMvlRCQWuAh4vZZdnP5euXOg13Qv0xP/YR/dx1h924uACDeoC+BKx6/p80Skcw3b7dDQ2u0w1PEr8+ci0seVL+z4VXcg1siuOlvfrzrqApveL8cUQiqQC3xljKn1PXPhz2RD6gLX/0y+APwRqKplu9PfK3cOdE/2MRBvjOkPfMWx/4VVzVZh9acYALyEdQcslxCRNsB84PfGmP2uet361FOXbe+XMabSGJOMdSvKISLS11WvXZcG1OXSn0kRuRjINcasbM7XOZE7B3pD7mV6dB8R8QNCgea+U1K9dRljCowxhx2fvg4MauaaGqoh76nLGWP2H/mV2RjzGeAv1q0Mm5WI+GOF5jvGmAU17GLL+1VfXXa9XyfUUIh1d7JxJ2yy42ey3rps+JkcDlwqItuwpmVHi8jbJ+zj9PfKnQO9Ifcy/Qi4yfHxBGCJcZxhsLOuE+ZZL8WaB3UHHwE3OlZvnAkUGWN2212UiMQcmTsUkSFY/y6bNQQcr/cfYL0x5u+17Oby96shddnxfjleK0pEwhwftwLOAzacsJvLfyYbUperfyaNMX8yxsQaY+KxMmKJMeb6E3Zz+nvl15QnNydjTIWIHLmXqS8wyzjuZQqkGGM+wvqH/5aIbMI66XaNm9R1r1j3W61w1HVzc9cFICLvYa2AiBSRHOAvWCeIMMa8CnyGtXJjE3AQuMVN6poA3CUiFcAh4BoX/Mc8HLgBSHfMvQL8GYirVpcd71dD6rLj/QJrBc6bIuKL9Z/IHGPMJ3b/TDawLlt+Jk/U3O+VXvqvlFJewp2nXJRSSjWCBrpSSnkJDXSllPISGuhKKeUlNNCVUspLaKArryMildW66qVKDR0xm3DseKmla6RSdnPbdehKNcEhx2XgSrUoOkJXLYaIbBORZ0Uk3dE/u4fj6/EissTRuOlrEYlzfL29iCx0NMFKE5FhjkP5ishrYvXe/tJxdSIicq9YfczXiMj/bPo2VQumga68UasTplwmVttWZIzpB/wLqxseWA2u3nQ0bnoHeNHx9ReBbxxNsE4DMhxfTwD+bYzpAxQCVzq+Ph0Y6DjOnc31zSlVG71SVHkdESkxxrSp4evbgNHGmC2OBlh7jDERIpIPdDDGlDu+vtsYEykieUBstaZOR1rafmWMSXB8Pg3wN8Y8KSKLgBKs7ocfVOvRrZRL6AhdtTSmlo8b43C1jys5di7qIuDfWKP5Xxwd9JRyGQ101dJMrPbnCsfHP3CsMdJ1wLeOj78G7oKjN1AIre2gIuIDdDbGLAWmYbVCPem3BKWak44glDdqVa1TIcAiY8yRpYvhIrIGa5Q9yfG1e4D/ishUII9jXRXvA2aKyG1YI/G7gNra5/oCbztCX4AXHb25lXIZnUNXLYZjDn2wMSbf7lqUag465aKUUl5CR+hKKeUldISulFJeQgNdKaW8hAa6Ukp5CQ10pZTyEhroSinlJf4fkcjYKjJF/qsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoFwBySYDCMW"
      },
      "source": [
        "## Getting a feature vector from a trained model\n",
        "\n",
        "Let's demonstrate the GlovalAveragePooling2D layer...\n",
        "\n",
        "We have a tensor after our model goes through `base_model`of shape (None, 7, 7, 1280).\n",
        "\n",
        "But then when it passes through GlobalAveragePooling2D, it turns into (None, 1280)\n",
        "\n",
        "Let's use a similar shaped tensor of (1, 4, 4, 3) and then pass it to GlobalAveragePooling2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4BgkIOlZ30d"
      },
      "source": [
        "> ðŸ¤” **Question:** What happens with the `tf.keras.layers.GlobalAveragePooling2D()` layer? I haven't seen it before.\n",
        "\n",
        "The [`tf.keras.layers.GlobalAveragePooling2D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D) layer transforms a 4D tensor into a 2D tensor by averaging the values across the inner-axes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z9Ik7KDDCQA",
        "outputId": "ae601084-a6f8-462d-889b-93bed53cb2cc"
      },
      "source": [
        "# Define the input shape\n",
        "input_shape = (1, 4, 4, 3)\n",
        "\n",
        "# Create random tensor\n",
        "tf.random.set_seed(42)\n",
        "input_tensor = tf.random.normal(input_shape)\n",
        "print(f\"Random input tensor: \\n {input_tensor}\\n\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random input tensor: \n",
            " [[[[ 0.3274685  -0.8426258   0.3194337 ]\n",
            "   [-1.4075519  -2.3880599  -1.0392479 ]\n",
            "   [-0.5573232   0.539707    1.6994323 ]\n",
            "   [ 0.28893656 -1.5066116  -0.2645474 ]]\n",
            "\n",
            "  [[-0.59722406 -1.9171132  -0.62044144]\n",
            "   [ 0.8504023  -0.40604794 -3.0258412 ]\n",
            "   [ 0.9058464   0.29855987 -0.22561555]\n",
            "   [-0.7616443  -1.8917141  -0.93847126]]\n",
            "\n",
            "  [[ 0.77852213 -0.47338897  0.97772694]\n",
            "   [ 0.24694404  0.20573747 -0.5256233 ]\n",
            "   [ 0.32410017  0.02545409 -0.10638497]\n",
            "   [-0.6369475   1.1603122   0.2507359 ]]\n",
            "\n",
            "  [[-0.41728503  0.4012578  -1.4145443 ]\n",
            "   [-0.5931857  -1.6617213   0.33567193]\n",
            "   [ 0.10815629  0.23479682 -0.56668764]\n",
            "   [-0.35819843  0.88698614  0.52744764]]]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSL0sGbFDCTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58dc2ea-9ede-45bc-f454-a4465abc363c"
      },
      "source": [
        "# Pass the random tensor through a GlobalAveragePooling2D layer\n",
        "global_average_pooled_tensor = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
        "print(f\"2D global average pooled random tensor:\\n {global_average_pooled_tensor}\")\n",
        "\n",
        "# Check the shape of the different tensors\n",
        "print(f\"Shape of input tensor: {input_tensor.shape}\")\n",
        "print(f\"Shape of Global Average Pooled 2D tensor: {global_average_pooled_tensor.shape}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2D global average pooled random tensor:\n",
            " [[-0.09368646 -0.45840448 -0.2885598 ]]\n",
            "Shape of input tensor: (1, 4, 4, 3)\n",
            "Shape of Global Average Pooled 2D tensor: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PAqzsRXZ8cG"
      },
      "source": [
        "You can see the tf.keras.layers.GlobalAveragePooling2D() layer condensed the input tensor from shape (1, 4, 4, 3) to (1, 3). It did so by averaging the input_tensor across the middle two axes.\n",
        "\n",
        "We can replicate this operation using the tf.reduce_mean() operation and specifying the appropriate axes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaI14tUdRuPR",
        "outputId": "b25ce19a-02e3-4663-b61f-8a094b316b5d"
      },
      "source": [
        "# Let's replicate the Global Averare Pooling 2D layer\n",
        "tf.reduce_mean(input_tensor, axis=[1,2])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[-0.09368646, -0.45840448, -0.2885598 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tSh0d9URuTO"
      },
      "source": [
        "Doing this not only makes the output of the base model compatible with the input shape requirement of our output layer (tf.keras.layers.Dense()), it also condenses the information found by the base model into a lower dimension feature vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tApv56raQDW"
      },
      "source": [
        "> ðŸ”‘ **Note:** One of the reasons feature extraction transfer learning is named how it is is because what often happens is a pretrained model outputs a **feature vector** (a long tensor of numbers, in our case, this is the output of the [`tf.keras.layers.GlobalAveragePooling2D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D) layer) which can then be used to extract patterns out of."
      ]
    }
  ]
}