{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4kPlyAcNce6"
   },
   "source": [
    "# Scaling Up (Food Vision Mini)\n",
    "\n",
    "We've seen the power of transfer learning feature extraction and fine-tuning, now it's time to scale up to all of the classes in Food101 (101 total classes of food)\n",
    "\n",
    "Our goal is to beat the original Food101 papare with 10% of the training (leveraging the power of deep learning)\n",
    "\n",
    "Original Food101 paper: https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/static/bossard_eccv14_food-101.pdf\n",
    "\n",
    "The baseline to beat is 50.76% accuracy across 101 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-h2Mvx_HPPFI"
   },
   "source": [
    "## Creating helper functions\n",
    "\n",
    "In previous notebooks, we've created a series of helper functions to do different tasks, let's download them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved under helper_functions (1).py\n"
     ]
    }
   ],
   "source": [
    "!python -m wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Hj1XjncQPPSy"
   },
   "outputs": [],
   "source": [
    "# Import series of helper functions of our notebook\n",
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvWHZxgfPPWW"
   },
   "source": [
    "## 101 Food Classes: Working with less data\n",
    "\n",
    "The goal is to beat the original Food 101 paper with 10% of the data\n",
    "\n",
    "The data we're downloading comes from the original Food101 dataset but has been preprocessed using the image_data_modification notebook - https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/image_data_modification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tyd-cW94PPZr",
    "outputId": "27d8726b-45c7-4cc4-a6da-11fc247cff63"
   },
   "outputs": [],
   "source": [
    "!python -m wget https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
    "unzip_data(\"101_food_classes_10_percent.zip\")\n",
    "\n",
    "train_dir = \"101_food_classes_10_percent/train\"\n",
    "test_dir = \"101_food_classes_10_percent/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RifRTN0RPPc5",
    "outputId": "4673a56c-46b1-4993-dae7-78e0907fb277"
   },
   "outputs": [],
   "source": [
    "# How many images/classes we have?\n",
    "walk_through_dir(\"101_food_classes_10_percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oW5LhNroPPhl",
    "outputId": "34306ba5-b0dd-47ce-c499-d046b76ccbc9"
   },
   "outputs": [],
   "source": [
    "# Setup data inputs\n",
    "import tensorflow as tf\n",
    "IMG_SIZE = (224,224)\n",
    "train_data_all_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
    "                                                                                label_mode=\"categorical\",\n",
    "                                                                                image_size=IMG_SIZE)\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                               label_mode=\"categorical\",\n",
    "                                                               image_size=IMG_SIZE,\n",
    "                                                               shuffle=False) # don't shuffle test data for prediction analysis                                                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCAjTDD2UEmH"
   },
   "source": [
    "## Train a big dog model with transfer learning 10% of 101 food clases\n",
    "\n",
    "Here are the steps we're going to take:\n",
    "- Create a ModelCheckpoint Callback\n",
    "- Create a data augmentation layer to builad data augmentation right into the model\n",
    "- Build a headless (no top layers) Functional EfficientNetB0 backbone-model (we'll create our own output layer)\n",
    "- Compile the model\n",
    "- Feature extract for 5 full passes (5 epochs on train dataset and validate on 15% of test data, to save epoch time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daztAdaSUEpf"
   },
   "outputs": [],
   "source": [
    "# Create checkpoint callback\n",
    "checkpoint_path = \"101_classes_10_percent_data_model_checkpoint\"\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                         save_weights_only=True,\n",
    "                                                         monitor=\"val_accuracy\",\n",
    "                                                         save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SOC8Bx6uUEsv"
   },
   "outputs": [],
   "source": [
    "# Create data augmentation layer to incorporate it right into the model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Setup data augmentation\n",
    "data_augmentation = Sequential([\n",
    "  preprocessing.RandomFlip(\"horizontal\"),\n",
    "  preprocessing.RandomRotation(0.2),\n",
    "  preprocessing.RandomHeight(0.2),\n",
    "  preprocessing.RandomWidth(0.2),\n",
    "  preprocessing.RandomZoom(0.2),\n",
    "  # preprocessing.Rescaling(1/255.0) # rescale inputs of images to btw. 0 and 1, required for models like ResNet50\n",
    "], name=\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bwrQ3W3UEvk",
    "outputId": "1499f7d2-67de-4b79-96f3-59b0d5237fb3"
   },
   "outputs": [],
   "source": [
    "# Setup the base model and freeze (this will extract features)\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Setup model architecture with trainable top layers\n",
    "inputs = layers.Input(shape=(224,224,3), name=\"input_layer\")\n",
    "x = data_augmentation(inputs) # augment images (only happens during training phase)\n",
    "x = base_model(x, training=False) # put the base model in inference model so weights that need to stay frozen stay frozen\n",
    "x = layers.GlobalAveragePooling2D(name=\"global_avg_pool_layer\")(x)\n",
    "outputs = layers.Dense(len(train_data_all_10_percent.class_names), activation=\"softmax\", name=\"output_layer\")(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsn1w1wJUEyl",
    "outputId": "d1073004-8289-4459-d943-ffb8f4a1ec09"
   },
   "outputs": [],
   "source": [
    "# Get a summary of model we've created\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4glN3f7RUE1z",
    "outputId": "afe14a41-c967-4215-e189-3d7c2bcb858b"
   },
   "outputs": [],
   "source": [
    "# Compile\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit\n",
    "history_all_classes_10_percent = model.fit(train_data_all_10_percent,\n",
    "                                           epochs=5, # fit for 5 epochs to keep experiments quick\n",
    "                                           validation_data=test_data,\n",
    "                                           validation_steps=int(0.15*len(test_data)),\n",
    "                                           callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-lsoiiUUE46",
    "outputId": "96c0bb14-8a31-4428-e0fe-f947b262a8b3"
   },
   "outputs": [],
   "source": [
    "# Evaluate on the whole test dataset\n",
    "feature_extraction_results = model.evaluate(test_data)\n",
    "feature_extraction_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "GYzublYuUE76",
    "outputId": "a7d8fac5-5006-4c4b-d1bc-88fee923aaa7"
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(history_all_classes_10_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IMVzMJC-aif"
   },
   "source": [
    "> Ideally, two curves should be very similar to each other, if not it may suggest that our model is overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caHZWF1KErsv"
   },
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dJxKMsMH-aff"
   },
   "outputs": [],
   "source": [
    "# Unfreeze all of the layers in the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Refreeze every layer except the last 5\n",
    "for layer in base_model.layers[:-5]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xf3wbCvm-acP",
    "outputId": "78495392-f1f1-402e-8306-6f66a01c7b34"
   },
   "outputs": [],
   "source": [
    "# Recompile model with lower learning rate (it's typically best practice to lower the learning rate when fine-tuning)\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.0001), # learning rate lowered by 10x\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acaKeQkiIkzC"
   },
   "source": [
    "Every time you increase the number of unfrozen layers, lower the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PlsgFMZI-aZf",
    "outputId": "70d66bdf-5f35-423a-9786-0708e0b2f054"
   },
   "outputs": [],
   "source": [
    "# What layers in model trainable?\n",
    "for layer in model.layers:\n",
    "  print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hJPfnDVd-aWn",
    "outputId": "a9939ef5-b464-43e7-fcb8-0806b2107539"
   },
   "outputs": [],
   "source": [
    "# What layers are trainable in our base model?\n",
    "for layer_number, layer in enumerate(model.layers[2].layers):\n",
    "  print(layer_number, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TLTmcsG9IQWm",
    "outputId": "b4eee981-3421-4d10-bdb7-3b99713442c4"
   },
   "outputs": [],
   "source": [
    "# Fine-tune for 5 more epochs\n",
    "fine_tune_epochs = 10 # model has already done 5 epochs (feature extraction), this is the total number of epochs we're after (5+5=10)\n",
    "\n",
    "# Fine-tune the model\n",
    "history_all_classes_10_percent_fine_tune = model.fit(train_data_all_10_percent,\n",
    "                                                     epochs=fine_tune_epochs,\n",
    "                                                     validation_data=test_data,\n",
    "                                                     validation_steps=int(0.15*len(test_data)),\n",
    "                                                     initial_epoch=history_all_classes_10_percent.epoch[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eO1eWTenISD5",
    "outputId": "008bda01-129f-4e12-9816-12241260ca0f"
   },
   "outputs": [],
   "source": [
    "# Evaluate on the whole test data\n",
    "all_classes_10_percent_fine_tune_results = model.evaluate(test_data)\n",
    "all_classes_10_percent_fine_tune_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "umabr83UISA7",
    "outputId": "fce6f49c-d440-4ac5-aa4f-98edf42d5f8a"
   },
   "outputs": [],
   "source": [
    "# Compare histories of feature extraction model with fine tuning model\n",
    "compare_historys(original_history=history_all_classes_10_percent,\n",
    "                 new_history=history_all_classes_10_percent_fine_tune,\n",
    "                 initial_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6iAt4JHwlA7"
   },
   "source": [
    "## Saving our model\n",
    "\n",
    "To use our model in an external application, we'll need to save it and export it somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rupFVRRGwk-J",
    "outputId": "7fc85ed4-e91f-41d1-ae0e-bbf6ace2cbd3"
   },
   "outputs": [],
   "source": [
    "# Saving our fine-tuning model\n",
    "model.save(\"drive/MyDrive/Tensorflow Course/101_food_classes_10_percent_saved_big_dog_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adbZgdz-wk6e",
    "outputId": "9eff5345-f800-49a0-dfb3-549f10ae062a"
   },
   "outputs": [],
   "source": [
    "# Load and evaluate saved model\n",
    "loaded_model = tf.keras.models.load_model(\"drive/MyDrive/Tensorflow Course/101_food_classes_10_percent_saved_big_dog_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rGkA0u-Zwk5L",
    "outputId": "37399bf9-5d51-41d6-a8dd-9395bec85f48"
   },
   "outputs": [],
   "source": [
    "#Evaluate loaded model and compare performance with pre-saved model\n",
    "loaded_model_results = loaded_model.evaluate(test_data)\n",
    "loaded_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uTnFKrCCwk15",
    "outputId": "3da4e9ff-6539-490c-8728-fc21fbb8347f"
   },
   "outputs": [],
   "source": [
    "# The results from our loaded_model should be very similar to the saved model results\n",
    "all_classes_10_percent_fine_tune_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SufQMmj0wk0C"
   },
   "source": [
    "## Evaluating the performance of the big dog model across all different classes\n",
    "\n",
    "Let's make som predictions, visualize them and then later find out which predictions were the \"most\" wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QL72CfQ_wkwY",
    "outputId": "e7464f17-ee31-4f95-cd14-f02a0b12d728"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Download pretrained model (one that was prepared earlier, so all predictions are similar)\n",
    "!python -m wget https://storage.googleapis.com/ztm_tf_course/food_vision/06_101_food_class_10_percent_saved_big_dog_model.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmb12jpwwkvV"
   },
   "outputs": [],
   "source": [
    "unzip_data(\"/content/06_101_food_class_10_percent_saved_big_dog_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYKezuGkwkrW",
    "outputId": "3a317482-71d0-4a8c-de7c-248e8d435df9"
   },
   "outputs": [],
   "source": [
    "# Load in saved model\n",
    "model = tf.keras.models.load_model(\"/content/06_101_food_class_10_percent_saved_big_dog_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGQJcSL7wkpy",
    "outputId": "5b41e29a-9145-4dde-eb5f-fc350efaeb8b"
   },
   "outputs": [],
   "source": [
    "# Evaluate loaded model (the one we just downloaded on test data)\n",
    "results_downloaded_model = model.evaluate(test_data)\n",
    "results_downloaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJEZqF0D3SGo"
   },
   "source": [
    "## Making predictions with our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzDM6Vkt3SEb",
    "outputId": "0c1a7e9c-449f-4b7a-d833-9dd032102cb4"
   },
   "outputs": [],
   "source": [
    "# Make predictions with our model\n",
    "preds_probs = model.predict(test_data, verbose=1) # set verbosity to see how long is left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TNYgY_jw3SCT",
    "outputId": "534de909-c745-422e-c572-4c6b305dea9a"
   },
   "outputs": [],
   "source": [
    "len(preds_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gI-hiC8R7DTU",
    "outputId": "8b9a2185-6ee2-4ec7-c215-40f85fde5928"
   },
   "outputs": [],
   "source": [
    "# What's the shape of our predictions?\n",
    "preds_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R8FiBZJq7DQY",
    "outputId": "01a7f586-5400-494f-e70f-c54adc10d47e"
   },
   "outputs": [],
   "source": [
    "# What the first 10 predictions look like?\n",
    "preds_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tV36GxK47DNi",
    "outputId": "70ce4351-8bc0-4afb-e7f7-331cfc072517"
   },
   "outputs": [],
   "source": [
    "# What does the first prediction probability look like?\n",
    "preds_probs[0], len(preds_probs[0]), sum(preds_probs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKZA7CwA7DIV"
   },
   "source": [
    "Our model outputs a prediction probability array (with N number of variables, where N is the number of classes) for each sample pased to the predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BClufthu7DEk",
    "outputId": "dcba3ffd-ca43-4fc2-95e0-f6ce3b8cc995"
   },
   "outputs": [],
   "source": [
    "print(f\"Number of prediction probabilities for sample 0: {len(preds_probs[0])}\")\n",
    "print(f\"What prediction probability sample 0 looks like:\\n {preds_probs[0]}\")\n",
    "print(f\"The class with the highest predicted probability by the model for sample 0: {preds_probs[0].argmax()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRiio-Laf3e7",
    "outputId": "85659f8e-85b0-48b3-ac16-78aed17e36a7"
   },
   "outputs": [],
   "source": [
    "# Get the pred classes of each label\n",
    "pred_classes = preds_probs.argmax(axis=1)\n",
    "\n",
    "# How do they look?\n",
    "pred_classes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OamUTAgOf3cP",
    "outputId": "4e60b673-f763-42df-ac93-c00c2fd29991"
   },
   "outputs": [],
   "source": [
    "#how mant pred classes do we have?\n",
    "len(pred_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DglEGimyf3Y9"
   },
   "source": [
    "Now we've got a predictions array of all of our model's preidctions, to evaluate them, we need to comare them to the original dataset labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rmfJFJFwf3TC",
    "outputId": "16c73f9e-6190-46a4-eeac-ada8d37caf2a"
   },
   "outputs": [],
   "source": [
    "# To get our test labels we need to unravel our test_data BatchDataset\n",
    "y_labels = []\n",
    "for images, labels in test_data.unbatch():\n",
    "  y_labels.append(labels.numpy().argmax()) # currently test labels look like: [0, 0, 0, ... ,0, 1, 0, ... , 0, 0], we want the index value where the \"1\" occurs\n",
    "y_labels[-20:-10] # look at the last 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNk-cFPst1fu"
   },
   "source": [
    "Since we set shuffle=False when we were preprocessing, all test data are still in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05t5ZNrOf3Qv",
    "outputId": "d1ea4fd6-9ee4-421f-bd04-6e5efdc956c6"
   },
   "outputs": [],
   "source": [
    "len(y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bM3mO3tf3OH"
   },
   "source": [
    "## Evaluating our model's predictions\n",
    "\n",
    "One way to check that our model's predictions array is in the same order as our test labels array is to find the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9W98Vfa5my_Z",
    "outputId": "14529f3a-f242-4bca-e0ef-06c9308db398"
   },
   "outputs": [],
   "source": [
    "results_downloaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJ8ktg_-my92",
    "outputId": "2f08cd98-5538-4ff7-ec07-a8cd36691202"
   },
   "outputs": [],
   "source": [
    "# Let's try scikit-learn's accuracy score function and see what it comes up with\n",
    "from sklearn.metrics import accuracy_score\n",
    "sklearn_accuracy = accuracy_score(y_true=y_labels,\n",
    "                                  y_pred=pred_classes)\n",
    "sklearn_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H5NfXMAdmy6h",
    "outputId": "4f6808a0-9562-4257-f5e1-beca855bc6e0"
   },
   "outputs": [],
   "source": [
    "# Does this metric come close to our model's evaluate results\n",
    "import numpy as np\n",
    "np.isclose(results_downloaded_model[1], sklearn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVI-EUSTmy3y"
   },
   "source": [
    "## Let's get visual: Making a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mx0CkjaVu5wf",
    "outputId": "c3157a20-439e-429c-9566-43a9cbed8c89"
   },
   "outputs": [],
   "source": [
    "# Get a list of class names\n",
    "class_names = test_data.class_names\n",
    "class_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IfG-6sHmqehl",
    "outputId": "1c47c6cb-cca0-40bb-8873-40a3edf30e16"
   },
   "outputs": [],
   "source": [
    "from helper_functions import make_confusion_matrix\n",
    "make_confusion_matrix(y_true=y_labels,\n",
    "                      y_pred=pred_classes,\n",
    "                      classes=class_names,\n",
    "                      figsize=(100,100),\n",
    "                      text_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "55n5WFyhqee5"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# We need to make some changes to our make_confusion_matirx function to ensure the x-labels print vertically\n",
    "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False): \n",
    "  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
    "\n",
    "  If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
    "  will be used.\n",
    "\n",
    "  Args:\n",
    "    y_true: Array of truth labels (must be same shape as y_pred).\n",
    "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
    "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
    "    figsize: Size of output figure (default=(10, 10)).\n",
    "    text_size: Size of output figure text (default=15).\n",
    "    norm: normalize values or not (default=False).\n",
    "    savefig: save confusion matrix to file (default=False).\n",
    "  \n",
    "  Returns:\n",
    "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
    "\n",
    "  Example usage:\n",
    "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
    "                          y_pred=y_preds, # predicted labels\n",
    "                          classes=class_names, # array of class label names\n",
    "                          figsize=(15, 15),\n",
    "                          text_size=10)\n",
    "  \"\"\"  \n",
    "  # Create the confustion matrix\n",
    "  cm = confusion_matrix(y_true, y_pred)\n",
    "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
    "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
    "\n",
    "  # Plot the figure and make it pretty\n",
    "  fig, ax = plt.subplots(figsize=figsize)\n",
    "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
    "  fig.colorbar(cax)\n",
    "\n",
    "  # Are there a list of classes?\n",
    "  if classes:\n",
    "    labels = classes\n",
    "  else:\n",
    "    labels = np.arange(cm.shape[0])\n",
    "  \n",
    "  # Label the axes\n",
    "  ax.set(title=\"Confusion Matrix\",\n",
    "         xlabel=\"Predicted label\",\n",
    "         ylabel=\"True label\",\n",
    "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
    "         yticks=np.arange(n_classes), \n",
    "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
    "         yticklabels=labels)\n",
    "  \n",
    "  # Make x-axis labels appear on bottom\n",
    "  ax.xaxis.set_label_position(\"bottom\")\n",
    "  ax.xaxis.tick_bottom()\n",
    "\n",
    "  ### Changed (plot x-labels vertically) ###\n",
    "  plt.xticks(rotation=70, fontsize=text_size)\n",
    "  plt.yticks(fontsize=text_size)\n",
    "\n",
    "  # Set the threshold for different colors\n",
    "  threshold = (cm.max() + cm.min()) / 2.\n",
    "\n",
    "  # Plot the text on each cell\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    if norm:\n",
    "      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
    "              horizontalalignment=\"center\",\n",
    "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "              size=text_size)\n",
    "    else:\n",
    "      plt.text(j, i, f\"{cm[i, j]}\",\n",
    "              horizontalalignment=\"center\",\n",
    "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "              size=text_size)\n",
    "\n",
    "  # Save the figure to the current working directory\n",
    "  if savefig:\n",
    "    fig.savefig(\"confusion_matrix.png\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4vJhe6e-qecS",
    "outputId": "0db6a963-cae1-4dc1-dd38-d06e499e1716"
   },
   "outputs": [],
   "source": [
    "make_confusion_matrix(y_true=y_labels,\n",
    "                      y_pred=pred_classes,\n",
    "                      classes=class_names,\n",
    "                      figsize=(100,100),\n",
    "                      text_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qcQxKFpqeZx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZS7cNIGsU16"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blZA1nJvsU0e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSx6XOSgsUv-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohLixJ0xsUtZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "scaling_up.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
