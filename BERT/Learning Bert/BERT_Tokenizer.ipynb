{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Tokenizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaLyzGjf819p"
      },
      "source": [
        "##Stage 1: Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYUQZOWy8tFX"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import re\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlcp-Qmb9z0U",
        "outputId": "f168fa55-742e-46b6-c380-cd68cd923a6d"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[?25l\r\u001b[K     |████████                        | 10 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 41 kB 137 kB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.62.3)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30534 sha256=3ec24c66dff69adabc895f2de82e8b39203e6eec188d620b69b3caa903e3d9a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/b6/e5/8c76ec779f54bc5c2f1b57d2200bb9c77616da83873e8acb53\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19473 sha256=262a008d4385d3080fa2f91586376d8d7ac8febc26b0df6c3c28e3074b1a29c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/fc/d2/a44fff33af0f233d7def6e7de413006d57c10e10ad736fe8f5\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7912 sha256=a2d060c27aa392c85332bb407be38f638d930b8776db189d60db839c1470dc12\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/11/67/33cc51bbee127cb8fb2ba549cd29109b2f22da43ddf9969716\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwbvkTlf9XtE"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCMRF6YI_5TG"
      },
      "source": [
        "##Stage 2: Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTjfUjAeDwHD"
      },
      "source": [
        "### Get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuyVgMn39XyE",
        "outputId": "3cfb1df2-151c-450d-9513-da335e942dcd"
      },
      "source": [
        "!wget http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-23 20:51:23--  http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
            "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
            "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip [following]\n",
            "--2021-10-23 20:51:23--  https://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
            "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 81363704 (78M) [application/zip]\n",
            "Saving to: ‘trainingandtestdata.zip’\n",
            "\n",
            "trainingandtestdata 100%[===================>]  77.59M  45.1MB/s    in 1.7s    \n",
            "\n",
            "2021-10-23 20:51:25 (45.1 MB/s) - ‘trainingandtestdata.zip’ saved [81363704/81363704]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ll3vvP9m9Xvt",
        "outputId": "e18a7d11-07ca-43f5-e0f8-3d9b9d26e45b"
      },
      "source": [
        "!unzip /content/trainingandtestdata.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/trainingandtestdata.zip\n",
            "  inflating: testdata.manual.2009.06.14.csv  \n",
            "  inflating: training.1600000.processed.noemoticon.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advEwx_Z9XqV"
      },
      "source": [
        "#!unzip /content/trainingandtestdata.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su9SoxZBDyBG"
      },
      "source": [
        "### Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAj6mstY9Xns"
      },
      "source": [
        "cols = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
        "data = pd.read_csv(\"/content/training.1600000.processed.noemoticon.csv\",\n",
        "                   names=cols,\n",
        "                   encoding=\"latin1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUGgeJHA9Xk6"
      },
      "source": [
        "data.drop([\"id\", \"date\", \"query\", \"user\"], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "lPRV3LR29Xe6",
        "outputId": "f1c9446d-71c2-4e57-bebd-f1e5f522adb7"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                               text\n",
              "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  is upset that he can't update his Facebook by ...\n",
              "2          0  @Kenichan I dived many times for the ball. Man...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0  @nationwideclass no, it's not behaving at all...."
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s41fQH0bSd3Z",
        "outputId": "6bca3391-13c1-45e3-e5ad-4438ffb4105e"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1600000 entries, 0 to 1599999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count    Dtype \n",
            "---  ------     --------------    ----- \n",
            " 0   sentiment  1600000 non-null  int64 \n",
            " 1   text       1600000 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 24.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Muhm1dxzDzyR"
      },
      "source": [
        "### Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7dLKWSZ9XcZ"
      },
      "source": [
        "def clean_tweet(tweet):\n",
        "    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
        "    # Delete the @\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
        "    # Delete URL links\n",
        "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
        "    # Just keep letters and important punctuation\n",
        "    tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet)\n",
        "    # Remove additional spaces\n",
        "    tweet = re.sub(r\" +\", ' ', tweet)\n",
        "    return tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds6M9OOp9XZz"
      },
      "source": [
        "data_clean = [clean_tweet(tweet) for tweet in data.text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PdYOFlR9XXD"
      },
      "source": [
        "data_labels = data.sentiment.values\n",
        "data_labels[data_labels == 4] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oHLGR8fJItE"
      },
      "source": [
        "### Tokenization\n",
        "\n",
        "We need to create a BERT layer to have acces to meta data for the tokenize (like vocab size)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_1OqgYLHDI5"
      },
      "source": [
        "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RcVobomHDGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bd9652b-58b6-4d07-a43e-cf9f15c2490b"
      },
      "source": [
        "tokenizer.tokenize(\"my dog loves strawberries.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my', 'dog', 'loves', 'straw', '##berries', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezwjs1zCR_fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fb7e8d1-863b-4cbc-a40c-01a6fa5c1513"
      },
      "source": [
        "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"my dog loves strawberries.\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2026, 3899, 7459, 13137, 20968, 1012]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57eKr0GkHDEG"
      },
      "source": [
        "def encode_sentence(sent):\n",
        "  return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6ull4k2HDBw"
      },
      "source": [
        "data_inputs = [encode_sentence(sentence) for sentence in data_clean]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grb_v7xpTiJB"
      },
      "source": [
        "### Dataset Creation\n",
        "\n",
        "We will create padded batches (so we pad sentences for each batch inpedendently), this way we add the minimum of padding tokens possible. For that, we sort sentences by length, apply padded_batches and then shuffle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftTq13V6HC_R"
      },
      "source": [
        "import random\n",
        "data_with_len = [[sent, data_labels[i], len(sent)]\n",
        "                 for i, sent in enumerate(data_inputs)]\n",
        "random.shuffle(data_with_len)\n",
        "data_with_len.sort(key=lambda x: x[2])\n",
        "sorted_all = [(sent_lab[0], sent_lab[1])\n",
        "              for sent_lab in data_with_len if sent_lab[2] > 7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LWeKRKdSb8p"
      },
      "source": [
        "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\n",
        "                                             output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1WbvgIqSb6u"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "all_batched = all_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxn5aLl8Sb4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd8f0779-bcd4-4850-e32b-89e86f2b75c8"
      },
      "source": [
        "next(iter(all_batched))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 8), dtype=int32, numpy=\n",
              " array([[ 6865,  2378,  2007,  2026,  2190,  2666, 10514,  5831],\n",
              "        [ 9089,  5243,  1998,  1056,  9148,  2595,  9805,  7382],\n",
              "        [ 2145,  2012,  2147,  4394, 25550,  2172,  1012,  1012],\n",
              "        [ 4485,  1045,  2131,  2125,  2012,  2809,  2085,  1012],\n",
              "        [ 2017,  2064,  2272,  2058,  7188,  2017,  2215,   999],\n",
              "        [11498,  2497, 24978, 19538,  2050,  6846,  2206, 22399],\n",
              "        [ 4553,  2000,  4875,  3020,  1012,  1012,  1012,   999],\n",
              "        [ 2397,  2305, 22715,  9956,  2015,  2007,  2564,   999],\n",
              "        [ 1996,  9592,  1997,  2008,  2025,  6230,  2003,  2471],\n",
              "        [ 5458,  6016,  2026,  5001,  7685,  1999,  2005, 10315],\n",
              "        [ 2053,  1012,  1012,  1012,  2026,  3274,  3844,  2091],\n",
              "        [15203,  1029,  2106,  2017, 15301,  1996,  8872,  1029],\n",
              "        [ 1996,  8505, 19718,  2074,  8271,  2033,  2039,  1012],\n",
              "        [15854,  4283,  2000,  2005,  1996,  4620,   999,  1060],\n",
              "        [10047,  3374,  2000,  2963,  2008,  1012,  1012,  1012],\n",
              "        [22834, 25789,  2054,  2015,  2183,  2006,  2564,  4402],\n",
              "        [12447,  2039,  3475,  1005,  1056, 25933,  4371, 18510],\n",
              "        [ 1045,  2228,  1045,  2288,  1996, 16268,  3308,  1012],\n",
              "        [ 4604,  1996,  4957,  2000,  2000,  2008,   999,   999],\n",
              "        [ 4283,  1043,  5856,  6137, 12171,  3363,  2140,   999],\n",
              "        [ 1045, 10587,  2156,  2017,  6170,  2009,  2045,  1012],\n",
              "        [ 2200,  2919,  6888,  1998,  2061,  2172,  2894,  1012],\n",
              "        [10869,  2748,   999,   999,  2003,  2008,  2919,  1029],\n",
              "        [ 2074,  3852,  2152,  2082,  2003,  3985,  2058,  1012],\n",
              "        [16215,  2595,  7010,  1045,  1005,  1049,  2428,  7568],\n",
              "        [ 2045,  2016,  2003, 17111,  9541,  2080, 23677,   999],\n",
              "        [ 5580,  2000,  2031,  2017,  1996,  3274,  2067,   999],\n",
              "        [ 2003,  2006,  1996,  2126,  2000,  2679,  2005,  2166],\n",
              "        [ 2339,  2052,  2017,  2215,  2000,  2681,  2033,  1029],\n",
              "        [ 2185,  2000,  2338,  9735,  2005,  3345,  2005,  2244],\n",
              "        [24471,  2025,  2206,  2033,  2021,  1045,  2572,  2334],\n",
              "        [ 2065,  2017,  2409,  2033,  1045,  2089,  2031,  2908]],\n",
              "       dtype=int32)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
              "        0, 1, 1, 1, 1, 1, 0, 1, 1, 0], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTkpiRJVSb1d"
      },
      "source": [
        "NB_BATCHES = math.ceil(len(sorted_all) / BATCH_SIZE)\n",
        "NB_BATCHES_TEST = NB_BATCHES // 10\n",
        "all_batched.shuffle(NB_BATCHES)\n",
        "test_dataset = all_batched.take(NB_BATCHES_TEST)\n",
        "train_dataset = all_batched.skip(NB_BATCHES_TEST)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDlhdAS9FCHs"
      },
      "source": [
        "##Stage 3: Model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzlHt43vSby-"
      },
      "source": [
        "class DCNN(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 vocab_size,\n",
        "                 emb_dim=128,\n",
        "                 nb_filters=50,\n",
        "                 FFN_units=512,\n",
        "                 nb_classes=2,\n",
        "                 dropout_rate=0.1,\n",
        "                 training=False,\n",
        "                 name=\"dcnn\"):\n",
        "        super(DCNN, self).__init__(name=name)\n",
        "        \n",
        "        self.embedding = layers.Embedding(vocab_size,\n",
        "                                          emb_dim)\n",
        "        self.bigram = layers.Conv1D(filters=nb_filters,\n",
        "                                    kernel_size=2,\n",
        "                                    padding=\"valid\",\n",
        "                                    activation=\"relu\")\n",
        "        self.trigram = layers.Conv1D(filters=nb_filters,\n",
        "                                     kernel_size=3,\n",
        "                                     padding=\"valid\",\n",
        "                                     activation=\"relu\")\n",
        "        self.fourgram = layers.Conv1D(filters=nb_filters,\n",
        "                                      kernel_size=4,\n",
        "                                      padding=\"valid\",\n",
        "                                      activation=\"relu\")\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "        \n",
        "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if nb_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=nb_classes,\n",
        "                                           activation=\"softmax\")\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        x = self.embedding(inputs)\n",
        "        x_1 = self.bigram(x) # (batch_size, nb_filters, seq_len-1)\n",
        "        x_1 = self.pool(x_1) # (batch_size, nb_filters)\n",
        "        x_2 = self.trigram(x) # (batch_size, nb_filters, seq_len-2)\n",
        "        x_2 = self.pool(x_2) # (batch_size, nb_filters)\n",
        "        x_3 = self.fourgram(x) # (batch_size, nb_filters, seq_len-3)\n",
        "        x_3 = self.pool(x_3) # (batch_size, nb_filters)\n",
        "        \n",
        "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\n",
        "        merged = self.dense_1(merged)\n",
        "        merged = self.dropout(merged, training)\n",
        "        output = self.last_dense(merged)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL8ba47-LDKf"
      },
      "source": [
        "##Stage 4: Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KFu_3K9LGZp"
      },
      "source": [
        "VOCAB_SIZE = len(tokenizer.vocab)\n",
        "EMBED_DIM = 200\n",
        "NB_FILTERS = 96\n",
        "FFN_UNITS = 256\n",
        "NB_CLASSES = 2\n",
        "DROPOUT_RATE = 0.2\n",
        "NB_EPOCHS = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S48g6S9SbwY"
      },
      "source": [
        "Dcnn = DCNN(vocab_size=VOCAB_SIZE,\n",
        "            emb_dim=EMBED_DIM,\n",
        "            nb_filters=NB_FILTERS,\n",
        "            FFN_units=FFN_UNITS,\n",
        "            nb_classes=NB_CLASSES,\n",
        "            dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-8gd4pPSbt9"
      },
      "source": [
        "if NB_CLASSES == 2:\n",
        "    Dcnn.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])\n",
        "else:\n",
        "    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtZSah9_Sbrk"
      },
      "source": [
        "checkpoint_path = \"./content/checkpoints/\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest Checkpoint restored!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2Vh6I5aFfem"
      },
      "source": [
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        ckpt_manager.save()\n",
        "        print(\"Checkpoint saved at {}.\".format(checkpoint_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DESxAXULFfb-",
        "outputId": "dd798697-14f2-4d94-9fc9-e0f8388f1f35"
      },
      "source": [
        "Dcnn.fit(train_dataset,\n",
        "         epochs=NB_EPOCHS,\n",
        "         callbacks=[MyCustomCallback()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "37196/37196 [==============================] - 792s 20ms/step - loss: 0.4292 - accuracy: 0.8020\n",
            "Checkpoint saved at ./content/checkpoints/.\n",
            "Epoch 2/5\n",
            "37196/37196 [==============================] - 771s 20ms/step - loss: 0.3810 - accuracy: 0.8309\n",
            "Checkpoint saved at ./content/checkpoints/.\n",
            "Epoch 3/5\n",
            "37196/37196 [==============================] - 758s 20ms/step - loss: 0.3406 - accuracy: 0.8519\n",
            "Checkpoint saved at ./content/checkpoints/.\n",
            "Epoch 4/5\n",
            "37196/37196 [==============================] - 751s 19ms/step - loss: 0.3002 - accuracy: 0.8715\n",
            "Checkpoint saved at ./content/checkpoints/.\n",
            "Epoch 5/5\n",
            "37196/37196 [==============================] - 746s 19ms/step - loss: 0.2625 - accuracy: 0.8889\n",
            "Checkpoint saved at ./content/checkpoints/.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f79182758d0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqqolGzGjUBD"
      },
      "source": [
        "##Stage 5: Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZOLu8RbFfZn",
        "outputId": "d0553049-fff9-4a42-fd67-505b677fa96a"
      },
      "source": [
        "results = Dcnn.evaluate(test_dataset)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4132/4132 [==============================] - 47s 11ms/step - loss: 0.4364 - accuracy: 0.8263\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4363931715488434, 0.8263099193572998]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioKXcDUtFfXG"
      },
      "source": [
        "def get_prediction(sentence):\n",
        "  tokens = encode_sentence(sentence)\n",
        "  inputs = tf.expand_dims(tokens, 0)\n",
        "\n",
        "  output = Dcnn(inputs, training=False)\n",
        "  sentiment = math.floor(output*2)\n",
        "\n",
        "  if sentiment == 0:\n",
        "    print(\"Output of the model: {}\\nPredicted sentiment: negative\".format(output))\n",
        "  elif sentiment == 1:\n",
        "    print(\"Output of the model: {}\\nPredicted sentiment: positive\".format(output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CLOnxYGFfUo",
        "outputId": "240af972-640c-4adc-b0bc-18af48d614e4"
      },
      "source": [
        "get_prediction(\"This movie is pretty interesting\")\n",
        "get_prediction(\"My dog likes to go to the park\")\n",
        "get_prediction(\"This traffic is killing me\")\n",
        "get_prediction(\"I bought medicine from pharmacy\")\n",
        "get_prediction(\"I bought medicine from pharmacy to heal\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output of the model: [[0.9992894]]\n",
            "Predicted sentiment: positive\n",
            "Output of the model: [[0.9408146]]\n",
            "Predicted sentiment: positive\n",
            "Output of the model: [[0.00045076]]\n",
            "Predicted sentiment: negative\n",
            "Output of the model: [[0.01798723]]\n",
            "Predicted sentiment: negative\n",
            "Output of the model: [[0.0001173]]\n",
            "Predicted sentiment: negative\n"
          ]
        }
      ]
    }
  ]
}