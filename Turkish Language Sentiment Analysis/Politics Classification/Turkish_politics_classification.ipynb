{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "c63b9c31b1e96fc19d2a13fbdf4ff075e8ca3441f99cb01fe5283baad6e722e3"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('DL': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Turkish_politics_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "983cd82dc1db493ab1bb2bab4b02b51f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_33d8eb2a7120401aa594da581491fe1c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7109e6ff189542438a8da162d3223634",
              "IPY_MODEL_25a853f47f684b268aa38d970be36f41",
              "IPY_MODEL_f742197f8f9f45b09f25856ba15ce00f"
            ]
          }
        },
        "33d8eb2a7120401aa594da581491fe1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7109e6ff189542438a8da162d3223634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_96ef9500952f439889fb59dbeba69805",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d4592485b8d84f19b9767acb59285cfc"
          }
        },
        "25a853f47f684b268aa38d970be36f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d602112b50014be7aede900780187ce7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1135358592,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1135358592,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_528bcb9b99864c229913e23a78402812"
          }
        },
        "f742197f8f9f45b09f25856ba15ce00f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_06286e2e6851463987ff78872e846369",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.06G/1.06G [00:36&lt;00:00, 30.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6fa151cc50b49b4a210e8b81b412310"
          }
        },
        "96ef9500952f439889fb59dbeba69805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d4592485b8d84f19b9767acb59285cfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d602112b50014be7aede900780187ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "528bcb9b99864c229913e23a78402812": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06286e2e6851463987ff78872e846369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6fa151cc50b49b4a210e8b81b412310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b72379c0698c47918db02a5a0697d1b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a421f77c9a074bce99bff031eeecd813",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff02092fe361420cba422a95ba378177",
              "IPY_MODEL_43a155338e014ef1825396c498d7fafa",
              "IPY_MODEL_e263de325eb44c07ac3a5badaa93f922"
            ]
          }
        },
        "a421f77c9a074bce99bff031eeecd813": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff02092fe361420cba422a95ba378177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_43549ce0a28b4b3589bc74c1a4b594a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc38e0b351af4d33ba77108c3cf201f3"
          }
        },
        "43a155338e014ef1825396c498d7fafa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_82d3573978814f08b0b0454f63987f82",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 385,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 385,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e2ce5ff1d934c8087279be82899ed7c"
          }
        },
        "e263de325eb44c07ac3a5badaa93f922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b42bbb68c624719ad9692b48efa9ed8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 385/385 [00:00&lt;00:00, 9.52kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad3b4f073c9b426dbe0697d943eb00ea"
          }
        },
        "43549ce0a28b4b3589bc74c1a4b594a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc38e0b351af4d33ba77108c3cf201f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82d3573978814f08b0b0454f63987f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e2ce5ff1d934c8087279be82899ed7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b42bbb68c624719ad9692b48efa9ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad3b4f073c9b426dbe0697d943eb00ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "944ff42b5193412ba712404979000986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8481a78552e442d0ae9b41efab43ff1c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_580a73b0b12d46fd917377645f7c9146",
              "IPY_MODEL_4ac6613be00a4100b950aba9fc342256",
              "IPY_MODEL_83503dafc5744159a6162c0e7e37bd7c"
            ]
          }
        },
        "8481a78552e442d0ae9b41efab43ff1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "580a73b0b12d46fd917377645f7c9146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6ead44362f6c48bb8b6c3c2534eb7e9a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10b7b23bd1d5459fb1d0933a26ecaba6"
          }
        },
        "4ac6613be00a4100b950aba9fc342256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bc2d581101354e08a26f74e3d9fade67",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 545150592,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 545150592,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_197432ca8ce540fe801e7f36c9268931"
          }
        },
        "83503dafc5744159a6162c0e7e37bd7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_74251337a9254e2799898f9bebfec549",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 520M/520M [00:36&lt;00:00, 18.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15fbfc4956174b5b9421a6b597d237be"
          }
        },
        "6ead44362f6c48bb8b6c3c2534eb7e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10b7b23bd1d5459fb1d0933a26ecaba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc2d581101354e08a26f74e3d9fade67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "197432ca8ce540fe801e7f36c9268931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74251337a9254e2799898f9bebfec549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15fbfc4956174b5b9421a6b597d237be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRYxgY74nfUD",
        "outputId": "4a52a617-5af0-4afc-fef3-81098a10892e"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-121c93d8-f366-16c2-dfeb-4e61bd808a9b)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAZmmLtw6TBt"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RYH8D_zCnfUK",
        "outputId": "70cb4cea-30c3-40d2-b7ba-0f46bf48a9ea"
      },
      "source": [
        "# Get data\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"siyaset.csv\")\n",
        "df.head()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>siyaset</td>\n",
              "      <td>3 milyon ile ön seçim vaadi mhp nin 10 olağan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>siyaset</td>\n",
              "      <td>mesut_yılmaz yüce_divan da ceza alabilirdi pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>siyaset</td>\n",
              "      <td>disko lar kaldırılıyor başbakan_yardımcısı ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>siyaset</td>\n",
              "      <td>sarıgül anayasa_mahkemesi ne gidiyor mustafa_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>siyaset</td>\n",
              "      <td>erdoğan idamın bir haklılık sebebi var demek ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   category                                               text\n",
              "0  siyaset    3 milyon ile ön seçim vaadi mhp nin 10 olağan...\n",
              "1  siyaset    mesut_yılmaz yüce_divan da ceza alabilirdi pr...\n",
              "2  siyaset    disko lar kaldırılıyor başbakan_yardımcısı ar...\n",
              "3  siyaset    sarıgül anayasa_mahkemesi ne gidiyor mustafa_...\n",
              "4  siyaset    erdoğan idamın bir haklılık sebebi var demek ..."
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCmNVld-wMOQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91ec195e-0c70-4e27-87b9-ad135461486b"
      },
      "source": [
        "# Check the DataFrame to see the number of lines and non-null objects\n",
        "df.info()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4900 entries, 0 to 4899\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   category  4900 non-null   object\n",
            " 1   text      4900 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 76.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSpPvCRsnfUM",
        "outputId": "e593096a-8498-47fb-9bd8-529319a45e47"
      },
      "source": [
        "# Check value counts to see whether the data is balanced or not\n",
        "df.category.value_counts()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "saglik        700\n",
              "spor          700\n",
              "dunya         700\n",
              "kultur        700\n",
              "siyaset       700\n",
              "ekonomi       700\n",
              "teknoloji     700\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXWBsxgu6dOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba1a820d-7114-423a-9963-bc72a813a1d1"
      },
      "source": [
        "# Since some nulls might be seen as a float, drop na to not face any problems.\n",
        "df.dropna(inplace=True)\n",
        "df.info()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 4900 entries, 0 to 4899\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   category  4900 non-null   object\n",
            " 1   text      4900 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 114.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1cOcB2Q6faO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "2d50af0f-532a-4123-ab1e-dce90b30e025"
      },
      "source": [
        "# Check the first line in df.text\n",
        "df.text[0]"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' 3 milyon ile ön seçim vaadi mhp nin 10 olağan büyük kurultayı nda konuşan genel başkan adayı koray_aydın seçimlerden önce partinin üye sayısının 3 milyona ulaştırılması hedefini koyarak ön seçim uygulaması vaadinde bulundu mhp nin 10 olağan büyük kurultayı nda konuşan genel başkan adayı koray_aydın seçimlerden önce partinin üye sayısının 3 milyona ulaştırılması hedefini koyarak ön seçim uygulaması vaadinde bulundu genel_başkan adayı koray_aydın kürsüye beklenirken yapılan tezahüratlar ve ıslıklamalar üzerine divan başkanı tuğrul_türkeş mhp nin genel başkanlığı da genel başkan adaylığı da saygıdeğer işlerdir bu salondaki herkes ciddiye almak zorundadır dedi ve taşkınlıklara izin verilmeyeceğini salonda sükunet sağlanmadan konuşmaların başlamayacağını vurguladı türkeş devlet_bahçeli nin kurultay açılışında konuştuğu için adaylık nedeniyle ikinci bir konuşma yapmayacağını açıkladı konuşmasında kurultayın mhp nin tek başına iktidarına vesile olmasını dileyen aydın ak_parti nin mhp yi eleştirirken kaleleri bir bir fethederek yollarına devam ettiklerini söylediğini hatırlatarak iktidarın basın ve sivil toplumu susturduğunu ifade etti ak_parti nin bürokraside taş üstüne taş bırakmadığını ileri süren aydın ülkücüleri düşman kabule ederek onları kıyma makinelerinden geçirecek bir zihniyetle sürgün ederek oraya buraya saldırarak bürokrasideki ülkücü kadrolara savaş açtılar dedi yaşanan bütün skandalların ardından devleti çete mantığıyla yöneten siyasi iktidarın olduğunu savunan aydın iktidarın belediyelere sahte raporlarla ve dinlemelerle saldırdığını savunan aydın arkasından habur dan içeri soktukları vatan hainlerine karşılama törenleri yetmez gibi oslo da teröristlerle kurdukları pazarlık masalarında suçüstü yakalanınca da ben görmedim diyerek bunu ispat edecek biri varsa şerefle ispat etsin diyerek ses kayıtları çıkınca da kıvırarak sahiplenemeyerek yaptığı işin üzerine şal örtmeye çalışarak siyasi riyakarlıkta sınır tanımayan siyasi iktidarla karşı karşıyayız diye konuştu mintika temizliği yapiyorlar ak_parti nin ne yaptığını iyi bildiğini türkiye de ihtilal teşebbüsü var diyerek ordunun subaylarını yargılama adı altında cezaevine koyduğunu savunan aydın önce milletin bu darbeciler ortadan kalksın diyerek desteklediği sonra plan gereği sürek avına çevirerek türk ordusunun neredeyse yarısını içeri atan bu zihniyet mıntıka temizliği yapıyor kuracakları yeni türkiye modeline engel olmasın diye bunları kaldırıyorlar bu işi haince yapanlar ne zaman ki şehit cenazeleri türkiye yi ağlatmaya başlarken acılarımızla yaşarken türkiye nin başbakanı gerekirse öcalan la yeniden görüşebilirim diyor sayın_başbakan ne görüşeceksin öcalan la ne söyleyeceksin oraya bir masa koymuşsun masanın üstünde türkiye karşında öcalan ne kadar istiyorsun şu kadar versem yeter mi diyeceksin öcalan yüzsüzlük eder de türkiye nin tamamını isterse ne yapacaksın diye konuştu o zaman ne yapacağiz yeni anayasa kapsamında türk milletinin adının anayasadan çıkarılarak bir alt kimlik haline getirileceğini türk milletine etnisite temelli yaklaşılacağını savunan aydın bu_türk milletinin varlığını ötüken de söğüt te türk olan türk milletinin varlığını ortadan kaldırma çabasıdır bu işin sonudur çünkü şu anda kendisiyle benzeşen anamuhalefetle anlaşıp anayasadan türk milletinin adını çıkarırlarsa yapılacak bir şey kalmaz meclis sayısal çoğunlukla yönetiliyor bunlar sinsi her işi alttan alttan götürüyorlar böyle bir adım atar bu büyük milletin adını çıkararak türk milletini bir alt kimlik haline dönüştürürlerse ne yapacağız bunu yaparlarsa 5 yıl 10 yıl sonra bu ülkenin adının türkiye olmasına gerek yoktur derlerse ne yapacağız bu sinsi planı iyi görelim bunu için bir şeyler yapmamız harekete geçmemiz lazım dedi şubat ta 1 milyon olarak toplanirsak … kimsenin türkiye de olanlara arkasını dönemeyeceğini ifade eden aydın özetle şunları söyledi meydanlara ineceğiz türk milletine gideceğiz milletle bütünleşeceğiz onu bekleyen bu tehlikeler hakkında uyaracağız anlatacağız onu yanımıza almaya çalışacağız o büyük gücü harekete geçirir meydanlara iner onların dikkatini çekip yanımıza alırsak şubat ayında 1 milyon olarak toplanırsak hangi vatan hainleri bunu yapmaya cesaret edebilir türk milletinin bunu anlamasını sağlamamız lazım bunun için güçlü bir mhp ye ihtiyaç var 43 yıllık fikri birikimi üzerinden türk milletini bütün problemlerine getireceği çözüm önerilerini bir iktidar projesine dönüştürerek türk milletini karşısına çıkıp iktidar istersek bu coşku ve heyecanı ona aksettirirsek bu millet bu şaşkınlıkla etrafına bakınırken ben nereye bakacağım sorusunu sorarken bu millet elimizi tutacak ve mhp ile yeniden ayağa kalkacaktır hedef 3 milyon üye bu mücadelede ilk doğru adımın ülkücü hareketin birliğini ve dirliğini sağlamak olduğunu kaydeden aydın harekete bir gün bile hizmet etmiş her ülküdaşlarıyla kucaklaşmak ve bir araya gelmek mecburiyetinde olduklarını ifade etti ülkücüleri ülküdaşlık hukuku temelinde kaynaştırmadan büyük hedeflere yürüyemeyeceklerini anlatan aydın bunu temel hareket noktası kabul ediyoruz birey temelli bir hareketin başlaması için önce partide üyelik sistemini bir kampanyaya çevireceğiz seçime kadar 3 milyon üye yaparak ailelerimizin fertlerini genişleteceğiz bunu iller arası yarışa çevireceğiz mhp nin 3 milyon üyeli geniş aile haline gelmesini sağlayacağız dedi önseçim vaadi genel_başkan seçilmesi halinde mhp ailesini genişleteceğini kaydeden aydın bunu yapınca bu 3 milyon kişi kurulan sandıklarla yapacağı bir ön seçimi size vaat ediyorum bunu taban güvenmek demektir böyle bir ön seçim yapıldı mı ankara da kimse genel merkez katlarında dolaşmayacak tabana size gidecek hasta olanın düğünü olanın yanında olacak yere düşeni ayağa kaldıracak böylece bu büyük aile fertleri bir birini anlayacak bu güzel sözün olduğu ortamın inşası demektir bu kötü söz olanın tasfiye edileceği liyakatın esas alınacağı yeni bir sistemin gelmesin demektir bu adımı atar aile fertleri arasında huzuru sağlarsak örgütlenme modelini buna paralel değiştirirsek mhp nin içinde huzur sağlanır diye konuştu bu bir kişiyi korumak için kelle avcısı rolü üstlenip ülküdaşlarını yok farz ederek küskünler ordusu yarattığın bir sitemin anlaşılması demektir diyen aydın mhp her yerde sloganıyla parti içinde hareketlilik sağlayacaklarını halka dokunacaklarını ifade etti ve tabanla bütünleşmiş mhp ye ihtiyaç var bunun içi bir iktidar projesi koyarak aday olduk biz iktidar olmak istiyoruz dedi aydın türk milletinin yalnızlığı yaşadığı bir durumda etrafına bakındığı kendini kaldıracak birini bekleyen türkiye nin mhp nin kendisine ulaşmasıyla yarın elbet bizimdir diye haykıracağını ifade etti haber anka foto emre senoglu murat oztek'"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4trssk306pYy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ad7b1c8f-488d-49df-dbdb-4e5faa5fbc16"
      },
      "source": [
        "# Remove punctuation for our model to learn better\n",
        "df['text'] = df['text'].str.replace(r'[^\\w\\s]+', '')\n",
        "df.text[0]"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' 3 milyon ile ön seçim vaadi mhp nin 10 olağan büyük kurultayı nda konuşan genel başkan adayı koray_aydın seçimlerden önce partinin üye sayısının 3 milyona ulaştırılması hedefini koyarak ön seçim uygulaması vaadinde bulundu mhp nin 10 olağan büyük kurultayı nda konuşan genel başkan adayı koray_aydın seçimlerden önce partinin üye sayısının 3 milyona ulaştırılması hedefini koyarak ön seçim uygulaması vaadinde bulundu genel_başkan adayı koray_aydın kürsüye beklenirken yapılan tezahüratlar ve ıslıklamalar üzerine divan başkanı tuğrul_türkeş mhp nin genel başkanlığı da genel başkan adaylığı da saygıdeğer işlerdir bu salondaki herkes ciddiye almak zorundadır dedi ve taşkınlıklara izin verilmeyeceğini salonda sükunet sağlanmadan konuşmaların başlamayacağını vurguladı türkeş devlet_bahçeli nin kurultay açılışında konuştuğu için adaylık nedeniyle ikinci bir konuşma yapmayacağını açıkladı konuşmasında kurultayın mhp nin tek başına iktidarına vesile olmasını dileyen aydın ak_parti nin mhp yi eleştirirken kaleleri bir bir fethederek yollarına devam ettiklerini söylediğini hatırlatarak iktidarın basın ve sivil toplumu susturduğunu ifade etti ak_parti nin bürokraside taş üstüne taş bırakmadığını ileri süren aydın ülkücüleri düşman kabule ederek onları kıyma makinelerinden geçirecek bir zihniyetle sürgün ederek oraya buraya saldırarak bürokrasideki ülkücü kadrolara savaş açtılar dedi yaşanan bütün skandalların ardından devleti çete mantığıyla yöneten siyasi iktidarın olduğunu savunan aydın iktidarın belediyelere sahte raporlarla ve dinlemelerle saldırdığını savunan aydın arkasından habur dan içeri soktukları vatan hainlerine karşılama törenleri yetmez gibi oslo da teröristlerle kurdukları pazarlık masalarında suçüstü yakalanınca da ben görmedim diyerek bunu ispat edecek biri varsa şerefle ispat etsin diyerek ses kayıtları çıkınca da kıvırarak sahiplenemeyerek yaptığı işin üzerine şal örtmeye çalışarak siyasi riyakarlıkta sınır tanımayan siyasi iktidarla karşı karşıyayız diye konuştu mintika temizliği yapiyorlar ak_parti nin ne yaptığını iyi bildiğini türkiye de ihtilal teşebbüsü var diyerek ordunun subaylarını yargılama adı altında cezaevine koyduğunu savunan aydın önce milletin bu darbeciler ortadan kalksın diyerek desteklediği sonra plan gereği sürek avına çevirerek türk ordusunun neredeyse yarısını içeri atan bu zihniyet mıntıka temizliği yapıyor kuracakları yeni türkiye modeline engel olmasın diye bunları kaldırıyorlar bu işi haince yapanlar ne zaman ki şehit cenazeleri türkiye yi ağlatmaya başlarken acılarımızla yaşarken türkiye nin başbakanı gerekirse öcalan la yeniden görüşebilirim diyor sayın_başbakan ne görüşeceksin öcalan la ne söyleyeceksin oraya bir masa koymuşsun masanın üstünde türkiye karşında öcalan ne kadar istiyorsun şu kadar versem yeter mi diyeceksin öcalan yüzsüzlük eder de türkiye nin tamamını isterse ne yapacaksın diye konuştu o zaman ne yapacağiz yeni anayasa kapsamında türk milletinin adının anayasadan çıkarılarak bir alt kimlik haline getirileceğini türk milletine etnisite temelli yaklaşılacağını savunan aydın bu_türk milletinin varlığını ötüken de söğüt te türk olan türk milletinin varlığını ortadan kaldırma çabasıdır bu işin sonudur çünkü şu anda kendisiyle benzeşen anamuhalefetle anlaşıp anayasadan türk milletinin adını çıkarırlarsa yapılacak bir şey kalmaz meclis sayısal çoğunlukla yönetiliyor bunlar sinsi her işi alttan alttan götürüyorlar böyle bir adım atar bu büyük milletin adını çıkararak türk milletini bir alt kimlik haline dönüştürürlerse ne yapacağız bunu yaparlarsa 5 yıl 10 yıl sonra bu ülkenin adının türkiye olmasına gerek yoktur derlerse ne yapacağız bu sinsi planı iyi görelim bunu için bir şeyler yapmamız harekete geçmemiz lazım dedi şubat ta 1 milyon olarak toplanirsak  kimsenin türkiye de olanlara arkasını dönemeyeceğini ifade eden aydın özetle şunları söyledi meydanlara ineceğiz türk milletine gideceğiz milletle bütünleşeceğiz onu bekleyen bu tehlikeler hakkında uyaracağız anlatacağız onu yanımıza almaya çalışacağız o büyük gücü harekete geçirir meydanlara iner onların dikkatini çekip yanımıza alırsak şubat ayında 1 milyon olarak toplanırsak hangi vatan hainleri bunu yapmaya cesaret edebilir türk milletinin bunu anlamasını sağlamamız lazım bunun için güçlü bir mhp ye ihtiyaç var 43 yıllık fikri birikimi üzerinden türk milletini bütün problemlerine getireceği çözüm önerilerini bir iktidar projesine dönüştürerek türk milletini karşısına çıkıp iktidar istersek bu coşku ve heyecanı ona aksettirirsek bu millet bu şaşkınlıkla etrafına bakınırken ben nereye bakacağım sorusunu sorarken bu millet elimizi tutacak ve mhp ile yeniden ayağa kalkacaktır hedef 3 milyon üye bu mücadelede ilk doğru adımın ülkücü hareketin birliğini ve dirliğini sağlamak olduğunu kaydeden aydın harekete bir gün bile hizmet etmiş her ülküdaşlarıyla kucaklaşmak ve bir araya gelmek mecburiyetinde olduklarını ifade etti ülkücüleri ülküdaşlık hukuku temelinde kaynaştırmadan büyük hedeflere yürüyemeyeceklerini anlatan aydın bunu temel hareket noktası kabul ediyoruz birey temelli bir hareketin başlaması için önce partide üyelik sistemini bir kampanyaya çevireceğiz seçime kadar 3 milyon üye yaparak ailelerimizin fertlerini genişleteceğiz bunu iller arası yarışa çevireceğiz mhp nin 3 milyon üyeli geniş aile haline gelmesini sağlayacağız dedi önseçim vaadi genel_başkan seçilmesi halinde mhp ailesini genişleteceğini kaydeden aydın bunu yapınca bu 3 milyon kişi kurulan sandıklarla yapacağı bir ön seçimi size vaat ediyorum bunu taban güvenmek demektir böyle bir ön seçim yapıldı mı ankara da kimse genel merkez katlarında dolaşmayacak tabana size gidecek hasta olanın düğünü olanın yanında olacak yere düşeni ayağa kaldıracak böylece bu büyük aile fertleri bir birini anlayacak bu güzel sözün olduğu ortamın inşası demektir bu kötü söz olanın tasfiye edileceği liyakatın esas alınacağı yeni bir sistemin gelmesin demektir bu adımı atar aile fertleri arasında huzuru sağlarsak örgütlenme modelini buna paralel değiştirirsek mhp nin içinde huzur sağlanır diye konuştu bu bir kişiyi korumak için kelle avcısı rolü üstlenip ülküdaşlarını yok farz ederek küskünler ordusu yarattığın bir sitemin anlaşılması demektir diyen aydın mhp her yerde sloganıyla parti içinde hareketlilik sağlayacaklarını halka dokunacaklarını ifade etti ve tabanla bütünleşmiş mhp ye ihtiyaç var bunun içi bir iktidar projesi koyarak aday olduk biz iktidar olmak istiyoruz dedi aydın türk milletinin yalnızlığı yaşadığı bir durumda etrafına bakındığı kendini kaldıracak birini bekleyen türkiye nin mhp nin kendisine ulaşmasıyla yarın elbet bizimdir diye haykıracağını ifade etti haber anka foto emre senoglu murat oztek'"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yii2MFn6wPA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "db3b4ddf-82a0-4154-ff1f-f44035699adc"
      },
      "source": [
        "# Lower the inputs for our model to learn better\n",
        "df[\"text\"] = df[\"text\"].str.lower()\n",
        "df.head()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>siyaset</td>\n",
              "      <td>3 milyon ile ön seçim vaadi mhp nin 10 olağan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>siyaset</td>\n",
              "      <td>mesut_yılmaz yüce_divan da ceza alabilirdi pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>siyaset</td>\n",
              "      <td>disko lar kaldırılıyor başbakan_yardımcısı ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>siyaset</td>\n",
              "      <td>sarıgül anayasa_mahkemesi ne gidiyor mustafa_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>siyaset</td>\n",
              "      <td>erdoğan idamın bir haklılık sebebi var demek ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   category                                               text\n",
              "0  siyaset    3 milyon ile ön seçim vaadi mhp nin 10 olağan...\n",
              "1  siyaset    mesut_yılmaz yüce_divan da ceza alabilirdi pr...\n",
              "2  siyaset    disko lar kaldırılıyor başbakan_yardımcısı ar...\n",
              "3  siyaset    sarıgül anayasa_mahkemesi ne gidiyor mustafa_...\n",
              "4  siyaset    erdoğan idamın bir haklılık sebebi var demek ..."
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "2Dk1nq-InfUM",
        "outputId": "f610a583-a566-4c09-91ec-25fb7bee5181"
      },
      "source": [
        "# Get train sentences from df.comment\n",
        "train_sentences = df[\"text\"].tolist()\n",
        "\n",
        "train_sentences[0]"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' 3 milyon ile ön seçim vaadi mhp nin 10 olağan büyük kurultayı nda konuşan genel başkan adayı koray_aydın seçimlerden önce partinin üye sayısının 3 milyona ulaştırılması hedefini koyarak ön seçim uygulaması vaadinde bulundu mhp nin 10 olağan büyük kurultayı nda konuşan genel başkan adayı koray_aydın seçimlerden önce partinin üye sayısının 3 milyona ulaştırılması hedefini koyarak ön seçim uygulaması vaadinde bulundu genel_başkan adayı koray_aydın kürsüye beklenirken yapılan tezahüratlar ve ıslıklamalar üzerine divan başkanı tuğrul_türkeş mhp nin genel başkanlığı da genel başkan adaylığı da saygıdeğer işlerdir bu salondaki herkes ciddiye almak zorundadır dedi ve taşkınlıklara izin verilmeyeceğini salonda sükunet sağlanmadan konuşmaların başlamayacağını vurguladı türkeş devlet_bahçeli nin kurultay açılışında konuştuğu için adaylık nedeniyle ikinci bir konuşma yapmayacağını açıkladı konuşmasında kurultayın mhp nin tek başına iktidarına vesile olmasını dileyen aydın ak_parti nin mhp yi eleştirirken kaleleri bir bir fethederek yollarına devam ettiklerini söylediğini hatırlatarak iktidarın basın ve sivil toplumu susturduğunu ifade etti ak_parti nin bürokraside taş üstüne taş bırakmadığını ileri süren aydın ülkücüleri düşman kabule ederek onları kıyma makinelerinden geçirecek bir zihniyetle sürgün ederek oraya buraya saldırarak bürokrasideki ülkücü kadrolara savaş açtılar dedi yaşanan bütün skandalların ardından devleti çete mantığıyla yöneten siyasi iktidarın olduğunu savunan aydın iktidarın belediyelere sahte raporlarla ve dinlemelerle saldırdığını savunan aydın arkasından habur dan içeri soktukları vatan hainlerine karşılama törenleri yetmez gibi oslo da teröristlerle kurdukları pazarlık masalarında suçüstü yakalanınca da ben görmedim diyerek bunu ispat edecek biri varsa şerefle ispat etsin diyerek ses kayıtları çıkınca da kıvırarak sahiplenemeyerek yaptığı işin üzerine şal örtmeye çalışarak siyasi riyakarlıkta sınır tanımayan siyasi iktidarla karşı karşıyayız diye konuştu mintika temizliği yapiyorlar ak_parti nin ne yaptığını iyi bildiğini türkiye de ihtilal teşebbüsü var diyerek ordunun subaylarını yargılama adı altında cezaevine koyduğunu savunan aydın önce milletin bu darbeciler ortadan kalksın diyerek desteklediği sonra plan gereği sürek avına çevirerek türk ordusunun neredeyse yarısını içeri atan bu zihniyet mıntıka temizliği yapıyor kuracakları yeni türkiye modeline engel olmasın diye bunları kaldırıyorlar bu işi haince yapanlar ne zaman ki şehit cenazeleri türkiye yi ağlatmaya başlarken acılarımızla yaşarken türkiye nin başbakanı gerekirse öcalan la yeniden görüşebilirim diyor sayın_başbakan ne görüşeceksin öcalan la ne söyleyeceksin oraya bir masa koymuşsun masanın üstünde türkiye karşında öcalan ne kadar istiyorsun şu kadar versem yeter mi diyeceksin öcalan yüzsüzlük eder de türkiye nin tamamını isterse ne yapacaksın diye konuştu o zaman ne yapacağiz yeni anayasa kapsamında türk milletinin adının anayasadan çıkarılarak bir alt kimlik haline getirileceğini türk milletine etnisite temelli yaklaşılacağını savunan aydın bu_türk milletinin varlığını ötüken de söğüt te türk olan türk milletinin varlığını ortadan kaldırma çabasıdır bu işin sonudur çünkü şu anda kendisiyle benzeşen anamuhalefetle anlaşıp anayasadan türk milletinin adını çıkarırlarsa yapılacak bir şey kalmaz meclis sayısal çoğunlukla yönetiliyor bunlar sinsi her işi alttan alttan götürüyorlar böyle bir adım atar bu büyük milletin adını çıkararak türk milletini bir alt kimlik haline dönüştürürlerse ne yapacağız bunu yaparlarsa 5 yıl 10 yıl sonra bu ülkenin adının türkiye olmasına gerek yoktur derlerse ne yapacağız bu sinsi planı iyi görelim bunu için bir şeyler yapmamız harekete geçmemiz lazım dedi şubat ta 1 milyon olarak toplanirsak  kimsenin türkiye de olanlara arkasını dönemeyeceğini ifade eden aydın özetle şunları söyledi meydanlara ineceğiz türk milletine gideceğiz milletle bütünleşeceğiz onu bekleyen bu tehlikeler hakkında uyaracağız anlatacağız onu yanımıza almaya çalışacağız o büyük gücü harekete geçirir meydanlara iner onların dikkatini çekip yanımıza alırsak şubat ayında 1 milyon olarak toplanırsak hangi vatan hainleri bunu yapmaya cesaret edebilir türk milletinin bunu anlamasını sağlamamız lazım bunun için güçlü bir mhp ye ihtiyaç var 43 yıllık fikri birikimi üzerinden türk milletini bütün problemlerine getireceği çözüm önerilerini bir iktidar projesine dönüştürerek türk milletini karşısına çıkıp iktidar istersek bu coşku ve heyecanı ona aksettirirsek bu millet bu şaşkınlıkla etrafına bakınırken ben nereye bakacağım sorusunu sorarken bu millet elimizi tutacak ve mhp ile yeniden ayağa kalkacaktır hedef 3 milyon üye bu mücadelede ilk doğru adımın ülkücü hareketin birliğini ve dirliğini sağlamak olduğunu kaydeden aydın harekete bir gün bile hizmet etmiş her ülküdaşlarıyla kucaklaşmak ve bir araya gelmek mecburiyetinde olduklarını ifade etti ülkücüleri ülküdaşlık hukuku temelinde kaynaştırmadan büyük hedeflere yürüyemeyeceklerini anlatan aydın bunu temel hareket noktası kabul ediyoruz birey temelli bir hareketin başlaması için önce partide üyelik sistemini bir kampanyaya çevireceğiz seçime kadar 3 milyon üye yaparak ailelerimizin fertlerini genişleteceğiz bunu iller arası yarışa çevireceğiz mhp nin 3 milyon üyeli geniş aile haline gelmesini sağlayacağız dedi önseçim vaadi genel_başkan seçilmesi halinde mhp ailesini genişleteceğini kaydeden aydın bunu yapınca bu 3 milyon kişi kurulan sandıklarla yapacağı bir ön seçimi size vaat ediyorum bunu taban güvenmek demektir böyle bir ön seçim yapıldı mı ankara da kimse genel merkez katlarında dolaşmayacak tabana size gidecek hasta olanın düğünü olanın yanında olacak yere düşeni ayağa kaldıracak böylece bu büyük aile fertleri bir birini anlayacak bu güzel sözün olduğu ortamın inşası demektir bu kötü söz olanın tasfiye edileceği liyakatın esas alınacağı yeni bir sistemin gelmesin demektir bu adımı atar aile fertleri arasında huzuru sağlarsak örgütlenme modelini buna paralel değiştirirsek mhp nin içinde huzur sağlanır diye konuştu bu bir kişiyi korumak için kelle avcısı rolü üstlenip ülküdaşlarını yok farz ederek küskünler ordusu yarattığın bir sitemin anlaşılması demektir diyen aydın mhp her yerde sloganıyla parti içinde hareketlilik sağlayacaklarını halka dokunacaklarını ifade etti ve tabanla bütünleşmiş mhp ye ihtiyaç var bunun içi bir iktidar projesi koyarak aday olduk biz iktidar olmak istiyoruz dedi aydın türk milletinin yalnızlığı yaşadığı bir durumda etrafına bakındığı kendini kaldıracak birini bekleyen türkiye nin mhp nin kendisine ulaşmasıyla yarın elbet bizimdir diye haykıracağını ifade etti haber anka foto emre senoglu murat oztek'"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K46d9PIx65aj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "cc8c14da-357a-43ce-e439-fac3283989cc"
      },
      "source": [
        "# Shuffle the data so our model can learn in a proper way\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "df = shuffle(df)\n",
        "df.head()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1575</th>\n",
              "      <td>ekonomi</td>\n",
              "      <td>harcamalar istanbul dan türkiye_istatistik_ku...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4361</th>\n",
              "      <td>teknoloji</td>\n",
              "      <td>chrome 24 yayınlandı google web tarayıcısının...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>649</th>\n",
              "      <td>siyaset</td>\n",
              "      <td>türkiye dönülmesi zor bir sürece girdi mhp ge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>siyaset</td>\n",
              "      <td>kışanak tan suriye kürtlerine toprak mesajı b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2512</th>\n",
              "      <td>kultur</td>\n",
              "      <td>carla pires salon_iksv istanbul 15 11 2012 21...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category                                               text\n",
              "1575    ekonomi    harcamalar istanbul dan türkiye_istatistik_ku...\n",
              "4361  teknoloji    chrome 24 yayınlandı google web tarayıcısının...\n",
              "649     siyaset    türkiye dönülmesi zor bir sürece girdi mhp ge...\n",
              "130     siyaset    kışanak tan suriye kürtlerine toprak mesajı b...\n",
              "2512     kultur    carla pires salon_iksv istanbul 15 11 2012 21..."
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-P5RE5b67dv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6690b3e-e305-4f62-8839-ad91247b3f2e"
      },
      "source": [
        "# Check the DataFrame for one last time\n",
        "df.info()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 4900 entries, 1575 to 2968\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   category  4900 non-null   object\n",
            " 1   text      4900 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 114.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VkGoG-a6860"
      },
      "source": [
        "## Input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oJt-xP3nfUN",
        "outputId": "b718f088-5f27-4ed1-8244-437aae9e4245"
      },
      "source": [
        "# Get the average and the max length of the inputs\n",
        "import numpy as np\n",
        "\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "max_sent_len = np.max(sent_lens)\n",
        "avg_sent_len, max_sent_len"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(263.39897959183673, 2640)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oomEpC0anfUO",
        "outputId": "f0fc19e3-dcb0-4c9f-c0d8-cfe32d498919"
      },
      "source": [
        "import numpy as np\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "\n",
        "output_seq_len"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "656"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBylhKfY7GXU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f50d1384-e812-48d9-c8bd-d8333ac304f5"
      },
      "source": [
        "# Get transformers\n",
        "!pip install transformers"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhJy7vPwnfUP"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-128k-uncased', do_lower_case=True)\n",
        "sentences = df.text.values\n",
        "max_len = 250"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rurNLeRnfUQ",
        "outputId": "beec1437-5433-4ce0-abf7-ffd2d67e14fa"
      },
      "source": [
        "# Encode inputs\n",
        "import tensorflow as tf\n",
        "\n",
        "input_ids = []\n",
        "attention_mask = []\n",
        "\n",
        "for txt in df.text.values:\n",
        "    encoded = tokenizer.encode_plus(\n",
        "        text=txt, # the sentence to be encoded \n",
        "        add_special_tokens=True, # Add [CLS] and [SEP]\n",
        "        max_length=250, # max length of a sentence\n",
        "        truncation=True, # truncate if sentence length is bigger than max_length\n",
        "        pad_to_max_length=True, # Add [PAD]s\n",
        "        return_attention_mask=True, # Generate attention mask\n",
        "        return_tensors=\"tf\" # return TensorFlow tensors\n",
        "    )\n",
        "\n",
        "    # Append input_ids and attention_masks to their own lists\n",
        "    input_ids.append(encoded[\"input_ids\"])\n",
        "    attention_mask.append(encoded[\"attention_mask\"])\n",
        "\n",
        "# Concatenate\n",
        "input_ids = tf.concat(input_ids, 0)\n",
        "attention_mask = tf.concat(attention_mask, 0)\n",
        "\n",
        "print(\"Original: \", df.text.values[0])\n",
        "print(\"Token IDs: \", input_ids[0])"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:   harcamalar istanbul dan türkiye_istatistik_kurumu tüik 2011 yılında toplam tüketim harcamasının yüzde 23 3 ünün istanbul da oturan hanehalkları tarafından yapıldığını açıkladı türkiye de 2011 yılı sonu itibariyle toplam tüketim harcamasının yüzde 23 3 ü istanbul daki hanehalkları tarafından yapıldı istanbul u yüzde 14 5 ile ege yüzde 11 6 ile akdeniz_bölgesi izledi türkiye_istatistik_kurumu tüik 2011 yılına ilişkin bölgesel bazda hanehalkı tüketim harcaması araştırması nın sonuçlarını açıkladı hanehalkı bütçe araştırması verilerinden bölge bazında tahmin üretmek üzere 2009 2010 ve 2011 yılı hanehalkı bütçe araştırmalarının uygulandığı örnek hanelerin tamamı birleştirilerek 2009 2010 2011 yıllarına ait hanehalkı harcamaları elde edilirken 2009 ve 2010 yıllarındaki harcama değerleri 2011 yılının ilgili ayındaki fiyatlarına çekildi bu sonuçlara göre toplam tüketim harcamasının yüzde 23 3 ü istanbul da oturan hanehalkları tarafından yapıldı istanbul u yüzde 14 5 ile ege yüzde 11 6 ile akdeniz_bölgesi izledi harcamaların sadece yüzde 1 8 i kuzeydoğu_anadolu_bölgesi ndeki hanehalkları tarafından gerçekleştirildi gıda ve alkolsüz içeceklerde kuzeydoğu_anadolu lider 2009 2010 2011 birleşik verilerine göre istatistiki bölge birimleri sınıflaması düzey 1 bazında bölge içindeki harcama gruplarının dağılımına bakıldığında kuzeydoğu_anadolu_bölgesi ndeki hanehalklarının tüketim amaçlı yaptığı harcamalar içinde en yüksek payı yüzde 29 7 oranıyla gıda ve alkolsüz içecekler aldı en düşük paya sahip harcama kalemi ise yüzde 1 1 eğitim hizmetleri olarak belirlendi istanbul daki harcama grupları içerisinde en yüksek payı yüzde 32 6 ile konut ve kira alırken gıda ve alkolsüz içecekler grubu yüzde 17 6 ile ikinci sırada yer aldı orta_anadolu bölgesi ulaştırma harcamalarında en yüksek payı elde ederken güneydoğu_anadolu bölgesi nde aynı harcama kalemi en düşük payı elde etti güneydoğu_anadolu haberleşme harcamalarına kuzeydoğu_anadolu da konut ve kira ile eğlence ve kültür harcamalarına en az payı ayırdı eğitim harcamalarına en düşük payı ayıran bölgeler batı marmara ve kuzeydoğu_anadolu olurken en yüksek payı ayıran il istanbul oldu\n",
            "Token IDs:  tf.Tensor(\n",
            "[     2  25347   6810   2642  22918     41   9194     41   6133 119199\n",
            "   1013   5196   2919   3527 117058   1950 127518   1009 104300   3924\n",
            "     23  22959   6810   1972  10487 122278   1994   2418   5427  22328\n",
            "  20314   2986  22918   1961   5196   4028   2530   6466   3527 117058\n",
            "   1950 127518   1009 104300   3924     23     63   6810   3535 122278\n",
            "   1994   2418   5427   6810     63 104300   3225     25   2037   6984\n",
            " 104300   2960     26   2037   7024     41  75575   2017  15030  22918\n",
            "     41   9194     41   6133 119199   1013   5196   8482  89805  75575\n",
            "   3986  20156  74401 117058   1950  37082 116858   2094   2437   4582\n",
            "   2226  20314   2986  74401  15186   2052 116858   2094  56342  75575\n",
            "   1011  12301   4933  54735   2044  67408   6224   5589   1946   5196\n",
            "   4028  74401  15186   2052 116858  33619  33914   2893  56899 119641\n",
            "   9033 105834   4240   6224   5589   5196  36786   3283  74401  20577\n",
            "   3516  15753   6224   1946   5589  61609   9134  19680   2023   5196\n",
            "   7615   2516  27170  22787  93844   9910   1010   1964   4582   2228\n",
            "  22586   3527 117058   1950 127518   1009 104300   3924     23     63\n",
            "   6810   1972  10487 122278   1994   2418   5427   6810     63 104300\n",
            "   3225     25   2037   6984 104300   2960     26   2037   7024     41\n",
            "  75575   2017  15030  38828   2577 104300     21     28     51   4326\n",
            " 108723     41   4048     41  75575   2017   7887 122278   1994   2418\n",
            " 100867   2756   4813   1946   7171   3049  37077 104734   1942   4326\n",
            " 108723     41   4048   3855   6224   5589   5196 112894   1954  12360\n",
            "  22586  46996  75575   1011  14020 112954  26679   1973     21  12301\n",
            "  75575   1011 114614   9134  23698  37112  33817   2061  95967  60043\n",
            "   4326 108723     41   4048     41  75575   2017   7887 122278      3], shape=(250,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv5Egvj_nfUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a690ad5-3e5d-4b35-a4ed-62532b5924f8"
      },
      "source": [
        "# Convert tokens to ids to check if the encoding operation is done correctly\n",
        "tokenizer.convert_ids_to_tokens(input_ids[0])"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'harcamalar',\n",
              " 'istanbul',\n",
              " 'dan',\n",
              " 'turkiye',\n",
              " '_',\n",
              " 'istatistik',\n",
              " '_',\n",
              " 'kurumu',\n",
              " 'tui',\n",
              " '##k',\n",
              " '2011',\n",
              " 'yılında',\n",
              " 'toplam',\n",
              " 'tuket',\n",
              " '##im',\n",
              " 'harcamasını',\n",
              " '##n',\n",
              " 'yuzde',\n",
              " '23',\n",
              " '3',\n",
              " 'unun',\n",
              " 'istanbul',\n",
              " 'da',\n",
              " 'oturan',\n",
              " 'hanehalk',\n",
              " '##ları',\n",
              " 'tarafından',\n",
              " 'yapıldı',\n",
              " '##gını',\n",
              " 'acık',\n",
              " '##ladı',\n",
              " 'turkiye',\n",
              " 'de',\n",
              " '2011',\n",
              " 'yılı',\n",
              " 'sonu',\n",
              " 'itibariyle',\n",
              " 'toplam',\n",
              " 'tuket',\n",
              " '##im',\n",
              " 'harcamasını',\n",
              " '##n',\n",
              " 'yuzde',\n",
              " '23',\n",
              " '3',\n",
              " 'u',\n",
              " 'istanbul',\n",
              " 'daki',\n",
              " 'hanehalk',\n",
              " '##ları',\n",
              " 'tarafından',\n",
              " 'yapıldı',\n",
              " 'istanbul',\n",
              " 'u',\n",
              " 'yuzde',\n",
              " '14',\n",
              " '5',\n",
              " 'ile',\n",
              " 'ege',\n",
              " 'yuzde',\n",
              " '11',\n",
              " '6',\n",
              " 'ile',\n",
              " 'akdeniz',\n",
              " '_',\n",
              " 'bolg',\n",
              " '##esi',\n",
              " 'izledi',\n",
              " 'turkiye',\n",
              " '_',\n",
              " 'istatistik',\n",
              " '_',\n",
              " 'kurumu',\n",
              " 'tui',\n",
              " '##k',\n",
              " '2011',\n",
              " 'yılına',\n",
              " 'iliskin',\n",
              " 'bolg',\n",
              " '##esel',\n",
              " 'bazda',\n",
              " 'hanehalkı',\n",
              " 'tuket',\n",
              " '##im',\n",
              " 'harcaması',\n",
              " 'arastır',\n",
              " '##ması',\n",
              " 'nın',\n",
              " 'sonuc',\n",
              " '##larını',\n",
              " 'acık',\n",
              " '##ladı',\n",
              " 'hanehalkı',\n",
              " 'but',\n",
              " '##ce',\n",
              " 'arastır',\n",
              " '##ması',\n",
              " 'verilerinden',\n",
              " 'bolg',\n",
              " '##e',\n",
              " 'bazında',\n",
              " 'tahmin',\n",
              " 'uret',\n",
              " '##mek',\n",
              " 'uzere',\n",
              " '2009',\n",
              " '2010',\n",
              " 've',\n",
              " '2011',\n",
              " 'yılı',\n",
              " 'hanehalkı',\n",
              " 'but',\n",
              " '##ce',\n",
              " 'arastır',\n",
              " '##malarının',\n",
              " 'uygulandı',\n",
              " '##gı',\n",
              " 'ornek',\n",
              " 'hanelerin',\n",
              " 'tamamı',\n",
              " 'birlestir',\n",
              " '##ilerek',\n",
              " '2009',\n",
              " '2010',\n",
              " '2011',\n",
              " 'yıllarına',\n",
              " 'ait',\n",
              " 'hanehalkı',\n",
              " 'harcamaları',\n",
              " 'elde',\n",
              " 'edilirken',\n",
              " '2009',\n",
              " 've',\n",
              " '2010',\n",
              " 'yıllarındaki',\n",
              " 'harcama',\n",
              " 'deger',\n",
              " '##leri',\n",
              " '2011',\n",
              " 'yılının',\n",
              " 'ilgili',\n",
              " 'ayındaki',\n",
              " 'fiyatlarına',\n",
              " 'ceki',\n",
              " '##ld',\n",
              " '##i',\n",
              " 'bu',\n",
              " 'sonuc',\n",
              " '##lara',\n",
              " 'gore',\n",
              " 'toplam',\n",
              " 'tuket',\n",
              " '##im',\n",
              " 'harcamasını',\n",
              " '##n',\n",
              " 'yuzde',\n",
              " '23',\n",
              " '3',\n",
              " 'u',\n",
              " 'istanbul',\n",
              " 'da',\n",
              " 'oturan',\n",
              " 'hanehalk',\n",
              " '##ları',\n",
              " 'tarafından',\n",
              " 'yapıldı',\n",
              " 'istanbul',\n",
              " 'u',\n",
              " 'yuzde',\n",
              " '14',\n",
              " '5',\n",
              " 'ile',\n",
              " 'ege',\n",
              " 'yuzde',\n",
              " '11',\n",
              " '6',\n",
              " 'ile',\n",
              " 'akdeniz',\n",
              " '_',\n",
              " 'bolg',\n",
              " '##esi',\n",
              " 'izledi',\n",
              " 'harcamaların',\n",
              " 'sadece',\n",
              " 'yuzde',\n",
              " '1',\n",
              " '8',\n",
              " 'i',\n",
              " 'kuzey',\n",
              " '##dogu',\n",
              " '_',\n",
              " 'anadolu',\n",
              " '_',\n",
              " 'bolg',\n",
              " '##esi',\n",
              " 'ndeki',\n",
              " 'hanehalk',\n",
              " '##ları',\n",
              " 'tarafından',\n",
              " 'gerceklestir',\n",
              " '##ildi',\n",
              " 'gıda',\n",
              " 've',\n",
              " 'alkol',\n",
              " '##suz',\n",
              " 'ice',\n",
              " '##cekler',\n",
              " '##de',\n",
              " 'kuzey',\n",
              " '##dogu',\n",
              " '_',\n",
              " 'anadolu',\n",
              " 'lider',\n",
              " '2009',\n",
              " '2010',\n",
              " '2011',\n",
              " 'birles',\n",
              " '##ik',\n",
              " 'verilerine',\n",
              " 'gore',\n",
              " 'istatistiki',\n",
              " 'bolg',\n",
              " '##e',\n",
              " 'birimleri',\n",
              " 'sınıflaması',\n",
              " 'duz',\n",
              " '##ey',\n",
              " '1',\n",
              " 'bazında',\n",
              " 'bolg',\n",
              " '##e',\n",
              " 'icindeki',\n",
              " 'harcama',\n",
              " 'gruplarının',\n",
              " 'dag',\n",
              " '##ılım',\n",
              " '##ına',\n",
              " 'bakıldı',\n",
              " '##gında',\n",
              " 'kuzey',\n",
              " '##dogu',\n",
              " '_',\n",
              " 'anadolu',\n",
              " '_',\n",
              " 'bolg',\n",
              " '##esi',\n",
              " 'ndeki',\n",
              " 'hanehalk',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKYZXtBxnfUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bb19c82-98ea-4a6b-8d40-96be11e92e09"
      },
      "source": [
        "# Check input_ids and shape of input_ids\n",
        "input_ids, input_ids.shape"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(4900, 250), dtype=int32, numpy=\n",
              " array([[     2,  25347,   6810, ...,   7887, 122278,      3],\n",
              "        [     2,  22772,   3444, ...,  22586,   3043,      3],\n",
              "        [     2,  22918,   3720, ...,  83872,   1939,      3],\n",
              "        ...,\n",
              "        [     2,     21,   3898, ...,      0,      0,      0],\n",
              "        [     2,  29622,  13643, ...,  17336,   2242,      3],\n",
              "        [     2,  23836,     41, ...,      0,      0,      0]], dtype=int32)>,\n",
              " TensorShape([4900, 250]))"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtEXB6ocnfUU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74456317-b5ae-493e-f355-c76980d7e9ac"
      },
      "source": [
        "# Check attention_mask and shape of attention_mask\n",
        "attention_mask, attention_mask.shape"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(4900, 250), dtype=int32, numpy=\n",
              " array([[1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>, TensorShape([4900, 250]))"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTcWfqFv7iZ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7f0b827-9789-4f02-b320-7582377e62c3"
      },
      "source": [
        "# Seperate test df from original df\n",
        "test_df = df.iloc[:490]\n",
        "df = df.iloc[490:]\n",
        "len(df), len(test_df)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4410, 490)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpbDN2St7vKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22c22630-4a02-4bc9-b760-c426c4f13d45"
      },
      "source": [
        "# Seperate test input ids and test attention mask from the original ones\n",
        "test_input_ids = input_ids[:490]\n",
        "test_attention_mask = attention_mask[:490]\n",
        "\n",
        "input_ids = input_ids[490:]\n",
        "attention_mask = attention_mask[490:]\n",
        "\n",
        "input_ids.shape, test_input_ids.shape, attention_mask.shape, test_attention_mask.shape"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([4410, 250]),\n",
              " TensorShape([490, 250]),\n",
              " TensorShape([4410, 250]),\n",
              " TensorShape([490, 250]))"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh58tH1enfUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8af9f4db-df8d-4d02-a9ad-095d88ec0fef"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "labels_one_hot = one_hot_encoder.fit_transform(df[\"category\"].to_numpy().reshape(-1,1))\n",
        "labels_one_hot"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MML6Kz9n78Tx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b75b331-f9a9-4df1-8bfa-03a44c4b9cf4"
      },
      "source": [
        "# One hot encode test labels\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "test_labels_one_hot = one_hot_encoder.fit_transform(test_df[\"category\"].to_numpy().reshape(-1,1))\n",
        "test_labels_one_hot.shape"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(490, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrgTvA7b8NBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d2f114-cc2a-4b71-e93b-183d7ae4a5ec"
      },
      "source": [
        "# Label encode test labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "test_labels_encoded = label_encoder.fit_transform(test_df[\"category\"].to_numpy())\n",
        "\n",
        "test_labels_encoded"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 6, 4, 4, 2, 5, 4, 0, 5, 1, 0, 2, 6, 6, 5, 5, 1, 3, 2, 3, 4, 6,\n",
              "       5, 3, 3, 2, 3, 5, 3, 6, 1, 6, 0, 3, 2, 2, 6, 2, 1, 3, 4, 2, 0, 4,\n",
              "       3, 4, 1, 2, 2, 5, 4, 2, 5, 2, 3, 2, 5, 0, 0, 4, 5, 4, 0, 5, 5, 0,\n",
              "       3, 4, 0, 3, 2, 3, 4, 2, 3, 1, 0, 2, 1, 5, 5, 6, 4, 6, 2, 2, 3, 6,\n",
              "       1, 2, 0, 3, 2, 1, 6, 0, 6, 4, 1, 4, 0, 2, 2, 6, 3, 3, 0, 5, 0, 6,\n",
              "       3, 0, 6, 5, 4, 6, 1, 6, 2, 5, 0, 6, 5, 2, 0, 5, 0, 4, 1, 1, 1, 0,\n",
              "       5, 6, 1, 4, 6, 4, 4, 2, 6, 3, 3, 4, 3, 1, 0, 2, 2, 2, 4, 5, 5, 4,\n",
              "       3, 2, 0, 6, 4, 2, 1, 5, 3, 6, 3, 4, 4, 2, 5, 1, 3, 2, 6, 4, 2, 6,\n",
              "       3, 4, 5, 4, 1, 2, 1, 1, 2, 2, 0, 2, 5, 3, 1, 2, 4, 3, 5, 0, 1, 1,\n",
              "       3, 2, 4, 6, 5, 0, 0, 4, 0, 3, 1, 1, 2, 2, 2, 2, 0, 1, 3, 0, 1, 4,\n",
              "       2, 2, 1, 5, 3, 0, 0, 4, 5, 1, 1, 1, 6, 4, 1, 1, 2, 4, 1, 0, 4, 6,\n",
              "       6, 4, 6, 4, 5, 6, 2, 0, 4, 0, 4, 6, 3, 3, 5, 3, 5, 5, 5, 3, 3, 6,\n",
              "       4, 0, 3, 2, 6, 4, 3, 0, 0, 1, 4, 6, 5, 5, 0, 1, 6, 4, 1, 2, 2, 0,\n",
              "       2, 6, 2, 3, 6, 0, 5, 5, 6, 0, 6, 3, 2, 2, 5, 3, 4, 6, 6, 3, 0, 1,\n",
              "       5, 0, 0, 4, 5, 6, 5, 0, 4, 1, 1, 3, 1, 6, 2, 6, 5, 4, 0, 0, 6, 6,\n",
              "       0, 2, 1, 4, 0, 6, 0, 6, 3, 4, 1, 5, 6, 5, 2, 1, 1, 3, 5, 5, 1, 1,\n",
              "       5, 5, 4, 3, 3, 6, 5, 2, 5, 2, 6, 6, 1, 6, 6, 3, 3, 2, 6, 1, 3, 3,\n",
              "       0, 4, 1, 2, 1, 0, 6, 1, 6, 4, 6, 0, 2, 2, 4, 2, 0, 0, 2, 1, 3, 5,\n",
              "       2, 0, 6, 3, 2, 2, 0, 3, 6, 6, 2, 6, 3, 4, 5, 0, 4, 3, 5, 5, 0, 3,\n",
              "       1, 0, 1, 0, 3, 1, 4, 2, 5, 2, 4, 1, 3, 6, 4, 1, 6, 1, 2, 1, 2, 2,\n",
              "       6, 6, 1, 3, 1, 1, 4, 2, 2, 0, 3, 2, 2, 4, 6, 0, 5, 5, 1, 4, 4, 1,\n",
              "       4, 4, 4, 6, 4, 5, 1, 6, 4, 5, 1, 5, 0, 6, 6, 1, 0, 0, 2, 2, 6, 6,\n",
              "       5, 5, 1, 0, 0, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gs0p4GWnfUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c740debf-1366-4607-b088-9b9f4b29bf03"
      },
      "source": [
        "# Create TensorFlow Datasets\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_mask, labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_input_ids, test_attention_mask, test_labels_one_hot))\n",
        "dataset, test_dataset"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<TensorSliceDataset shapes: ((250,), (250,), (7,)), types: (tf.int32, tf.int32, tf.float64)>,\n",
              " <TensorSliceDataset shapes: ((250,), (250,), (7,)), types: (tf.int32, tf.int32, tf.float64)>)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBXZFhSVnfUV"
      },
      "source": [
        "# Create a function to map our dataset\n",
        "def map_func(input_ids, masks, labels):\n",
        "    # We convert our three-item tuple into a two-item tuple where the input item is a dictionary\n",
        "    return {\"input_ids\": input_ids,\n",
        "            \"attention_mask\": masks}, labels"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd51mbKJnfUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ff5330-2e07-4812-b95b-936ee95d3350"
      },
      "source": [
        "# Map the dataset using the function we created and check the dataset\n",
        "dataset = dataset.map(map_func)\n",
        "test_dataset = test_dataset.map(map_func)\n",
        "dataset, test_dataset"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<MapDataset shapes: ({input_ids: (250,), attention_mask: (250,)}, (7,)), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.float64)>,\n",
              " <MapDataset shapes: ({input_ids: (250,), attention_mask: (250,)}, (7,)), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.float64)>)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0ExIHun8wza"
      },
      "source": [
        "# Get the length of our dataset\n",
        "len_dataset_unbatched = len(dataset)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDWXDNS18y4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2102ee93-6651-46bf-c707-72aa15a77650"
      },
      "source": [
        "# Batch our datasets\n",
        "batch_size=16\n",
        "dataset = dataset.batch(batch_size) #.shuffle(10000) , drop_remainder=True\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "\n",
        "dataset.take, test_dataset"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<bound method DatasetV2.take of <BatchDataset shapes: ({input_ids: (None, 250), attention_mask: (None, 250)}, (None, 7)), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.float64)>>,\n",
              " <BatchDataset shapes: ({input_ids: (None, 250), attention_mask: (None, 250)}, (None, 7)), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.float64)>)"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bje4AnYH82ll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "639e0834-ff54-4c71-cfb0-81fb25eef4a6"
      },
      "source": [
        "# Split our dataset into train, validation and test datasets\n",
        "split = 0.9\n",
        "size = int((input_ids.shape[0] / batch_size) * split)\n",
        "\n",
        "train_ds = dataset.take(size) # 85% of the dataset\n",
        "val_ds = dataset.skip(size) # 15% of the dataset\n",
        "\n",
        "len(dataset), len(train_ds), len(val_ds)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(276, 248, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pztOEahn8_wp"
      },
      "source": [
        "## Build and train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "983cd82dc1db493ab1bb2bab4b02b51f",
            "33d8eb2a7120401aa594da581491fe1c",
            "7109e6ff189542438a8da162d3223634",
            "25a853f47f684b268aa38d970be36f41",
            "f742197f8f9f45b09f25856ba15ce00f",
            "96ef9500952f439889fb59dbeba69805",
            "d4592485b8d84f19b9767acb59285cfc",
            "d602112b50014be7aede900780187ce7",
            "528bcb9b99864c229913e23a78402812",
            "06286e2e6851463987ff78872e846369",
            "a6fa151cc50b49b4a210e8b81b412310"
          ]
        },
        "id": "xcoSXcJznfUa",
        "outputId": "1842606c-898e-48a3-c7cd-0f74093019f5"
      },
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "bert128k = TFAutoModel.from_pretrained(\"dbmdz/bert-base-turkish-128k-uncased\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "983cd82dc1db493ab1bb2bab4b02b51f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.06G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY2HqtlenfUm"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# two input layers, we ensure layer name variables match to dictionary keys in TF dataset\n",
        "input_ids = tf.keras.layers.Input(shape=(250,), name='input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(250,), name='attention_mask', dtype='int32')\n",
        "\n",
        "# we access the transformer model within our bert object using the bert attribute (eg bert.bert instead of bert)\n",
        "embeddings = bert128k.bert(input_ids, attention_mask=mask)[1]  # access final activations (already max-pooled) [1]\n",
        "# convert bert embeddings into 6 output classes\n",
        "#x = tf.keras.layers.Dropout(0.1)(embeddings)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(embeddings)\n",
        "outputs = tf.keras.layers.Dense(7, activation='softmax', name='outputs')(x)\n",
        "\n",
        "# model\n",
        "model_1 = tf.keras.Model(inputs=[input_ids, mask], outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMPOdhbFnfUn",
        "outputId": "11af03bb-7b67-4fd2-cac9-71c97f031b9c"
      },
      "source": [
        "model_1.layers[2].trainable=False\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 250)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 250)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  184345344   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 250,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1024)         787456      ['bert[0][1]']                   \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 7)            7175        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 185,139,975\n",
            "Trainable params: 794,631\n",
            "Non-trainable params: 184,345,344\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FjzO1JVnfUn"
      },
      "source": [
        "# Get learning rate using PolynomialDecay\n",
        "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
        "\n",
        "x = len_dataset_unbatched*0.9 # length of train_ds (unbatched)\n",
        "\n",
        "num_epochs = 3\n",
        "num_train_steps = x * num_epochs\n",
        "lr_scheduler = PolynomialDecay(\n",
        "    initial_learning_rate=5e-5,\n",
        "    end_learning_rate=0.,\n",
        "    decay_steps=num_train_steps\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bITf_TPanfUn"
      },
      "source": [
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
        "\n",
        "model_1.compile(optimizer=optimizer, \n",
        "              loss=loss, \n",
        "              metrics=[acc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YNldWXGnfUq",
        "outputId": "81750373-66ad-4b18-9698-860ca5f8d9d9"
      },
      "source": [
        "# Fit the model\n",
        "history = model_1.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=4,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "248/248 [==============================] - 177s 650ms/step - loss: 1.5116 - accuracy: 0.4997 - val_loss: 1.1907 - val_accuracy: 0.7036\n",
            "Epoch 2/4\n",
            "248/248 [==============================] - 158s 638ms/step - loss: 1.0444 - accuracy: 0.7004 - val_loss: 0.9109 - val_accuracy: 0.7738\n",
            "Epoch 3/4\n",
            "248/248 [==============================] - 158s 638ms/step - loss: 0.8576 - accuracy: 0.7409 - val_loss: 0.8047 - val_accuracy: 0.7715\n",
            "Epoch 4/4\n",
            "248/248 [==============================] - 159s 639ms/step - loss: 0.7816 - accuracy: 0.7548 - val_loss: 0.7282 - val_accuracy: 0.7805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test_ds\n",
        "model_1.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDL3gkI9BP_H",
        "outputId": "8f01a893-7d53-4afa-e498-5abffddecd79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 16s 518ms/step - loss: 0.6884 - accuracy: 0.7755\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6884288787841797, 0.7755101919174194]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download helper functions\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQX9dnZSE1aT",
        "outputId": "ba4fc3f9-6217-4bf1-c292-794a91013ba2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-07 23:40:26--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-07 23:40:26 (37.5 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import calculate_results"
      ],
      "metadata": {
        "id": "VEnrVfBJFeD3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "model_1_pred_probs = model_1.predict(test_dataset)\n",
        "model_1_pred_probs[0], model_1_pred_probs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DInY84-cFjAe",
        "outputId": "e9d11428-6b2e-40b7-9c6e-06cf5c9d4726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.0337254 , 0.01682904, 0.76626486, 0.03436323, 0.08349808,\n",
              "        0.01023222, 0.05508713], dtype=float32), (490, 7))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert pred_probs to classes\n",
        "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
        "model_1_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dCJqHewFjyM",
        "outputId": "8bd99499-6a49-4fbc-edbb-a1db449867e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(490,), dtype=int64, numpy=\n",
              "array([2, 4, 6, 0, 0, 3, 3, 0, 1, 3, 5, 2, 5, 5, 2, 6, 6, 6, 0, 1, 2, 6,\n",
              "       2, 2, 4, 3, 2, 2, 0, 0, 1, 0, 4, 1, 3, 1, 4, 3, 4, 0, 1, 1, 0, 0,\n",
              "       0, 4, 0, 2, 2, 0, 3, 4, 4, 6, 5, 1, 6, 1, 2, 4, 0, 0, 2, 0, 0, 1,\n",
              "       0, 4, 3, 0, 5, 3, 6, 5, 4, 4, 2, 3, 2, 0, 6, 6, 1, 3, 0, 6, 0, 3,\n",
              "       6, 4, 0, 3, 2, 2, 5, 2, 0, 2, 2, 3, 3, 0, 2, 0, 0, 4, 1, 3, 5, 0,\n",
              "       1, 1, 3, 4, 5, 3, 1, 0, 5, 1, 5, 1, 1, 5, 0, 6, 2, 0, 4, 3, 0, 0,\n",
              "       4, 2, 4, 4, 0, 6, 0, 4, 0, 0, 1, 2, 5, 4, 0, 0, 5, 2, 5, 3, 0, 5,\n",
              "       1, 0, 3, 6, 2, 5, 5, 5, 4, 1, 5, 0, 2, 3, 6, 6, 6, 1, 4, 0, 1, 4,\n",
              "       2, 1, 6, 1, 4, 0, 6, 6, 4, 6, 4, 0, 4, 0, 6, 2, 5, 2, 2, 2, 5, 1,\n",
              "       5, 3, 0, 0, 3, 3, 5, 1, 4, 6, 3, 1, 4, 6, 5, 2, 6, 6, 0, 5, 4, 2,\n",
              "       0, 0, 1, 6, 0, 6, 0, 3, 4, 1, 1, 2, 1, 1, 6, 3, 4, 0, 6, 1, 4, 1,\n",
              "       0, 3, 5, 0, 5, 1, 2, 0, 0, 0, 6, 2, 6, 0, 1, 6, 3, 0, 3, 3, 1, 5,\n",
              "       0, 0, 0, 3, 5, 3, 0, 3, 1, 4, 3, 0, 2, 4, 0, 2, 5, 5, 3, 0, 3, 3,\n",
              "       5, 3, 6, 2, 5, 0, 2, 2, 0, 1, 1, 3, 0, 3, 5, 1, 5, 0, 3, 2, 0, 4,\n",
              "       0, 3, 0, 4, 0, 0, 3, 6, 4, 1, 2, 4, 0, 5, 3, 2, 3, 4, 0, 1, 3, 5,\n",
              "       3, 3, 0, 2, 3, 0, 5, 6, 0, 2, 4, 3, 6, 4, 2, 3, 6, 2, 2, 5, 4, 0,\n",
              "       5, 2, 3, 4, 0, 0, 1, 2, 1, 0, 4, 4, 6, 1, 5, 5, 6, 2, 4, 5, 3, 2,\n",
              "       3, 5, 6, 0, 3, 3, 5, 3, 6, 6, 1, 4, 2, 1, 6, 1, 0, 4, 5, 4, 0, 1,\n",
              "       2, 1, 3, 2, 3, 3, 2, 0, 0, 0, 4, 1, 6, 4, 2, 5, 3, 2, 5, 1, 5, 0,\n",
              "       4, 6, 4, 5, 3, 0, 0, 5, 2, 4, 4, 3, 4, 6, 6, 5, 2, 3, 0, 5, 1, 3,\n",
              "       3, 5, 2, 0, 6, 2, 1, 2, 3, 2, 2, 5, 6, 3, 4, 2, 2, 6, 4, 3, 2, 5,\n",
              "       3, 1, 6, 1, 1, 4, 3, 3, 6, 2, 2, 3, 1, 0, 4, 4, 5, 2, 2, 0, 2, 6,\n",
              "       2, 6, 5, 6, 1, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model results\n",
        "model_1_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhJ4xKxFFj1r",
        "outputId": "6d457dd4-69ba-412c-8666-1d0ae86a5e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.55102040816327,\n",
              " 'f1': 0.7805864672014955,\n",
              " 'precision': 0.8025049044099667,\n",
              " 'recall': 0.7755102040816326}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# two input layers, we ensure layer name variables match to dictionary keys in TF dataset\n",
        "input_ids = tf.keras.layers.Input(shape=(250,), name='input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(250,), name='attention_mask', dtype='int32')\n",
        "\n",
        "# we access the transformer model within our bert object using the bert attribute (eg bert.bert instead of bert)\n",
        "embeddings = bert128k.bert(input_ids, attention_mask=mask)[1]  # access final activations (already max-pooled) [1]\n",
        "# convert bert embeddings into 6 output classes\n",
        "#x = tf.keras.layers.Dropout(0.1)(embeddings)\n",
        "x = tf.keras.layers.Dense(48, activation='relu')(embeddings)\n",
        "outputs = tf.keras.layers.Dense(7, activation='softmax', name='outputs')(x)\n",
        "\n",
        "# model\n",
        "model_2 = tf.keras.Model(inputs=[input_ids, mask], outputs=outputs)"
      ],
      "metadata": {
        "id": "DGeZAKTdFj5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.layers[2].trainable=True\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MATYL8WFj8b",
        "outputId": "fe5c8c59-38d9-4634-d45e-dea90e23e85e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 250)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 250)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  184345344   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 250,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 48)           36912       ['bert[0][1]']                   \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 7)            343         ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 184,382,599\n",
            "Trainable params: 184,382,599\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
        "\n",
        "model_2.compile(optimizer=optimizer, \n",
        "              loss=loss, \n",
        "              metrics=[acc])"
      ],
      "metadata": {
        "id": "_tUxGpIPFj_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_2 = model_2.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=3,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-YoQhzJHuvY",
        "outputId": "475078ea-3ec7-483a-d2a4-b528514bb3ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "248/248 [==============================] - 549s 2s/step - loss: 0.5084 - accuracy: 0.8387 - val_loss: 0.2215 - val_accuracy: 0.9434\n",
            "Epoch 2/3\n",
            "248/248 [==============================] - 528s 2s/step - loss: 0.1802 - accuracy: 0.9481 - val_loss: 0.2299 - val_accuracy: 0.9367\n",
            "Epoch 3/3\n",
            "248/248 [==============================] - 527s 2s/step - loss: 0.0907 - accuracy: 0.9740 - val_loss: 0.3371 - val_accuracy: 0.9118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test_ds\n",
        "model_2.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9bRtQwzP0xN",
        "outputId": "4c76ae24-b4fe-4a58-a87d-f728120def80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 21s 665ms/step - loss: 0.2575 - accuracy: 0.9306\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2575474977493286, 0.9306122660636902]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "model_2_pred_probs = model_2.predict(test_dataset)\n",
        "model_2_pred_probs[0], model_2_pred_probs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaZNFPjSP0u6",
        "outputId": "3cfd9422-b36a-47a5-eee4-2fe9cab70a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.6984274e-03, 9.9714798e-01, 1.5023623e-04, 3.8604983e-04,\n",
              "        2.8157854e-04, 1.3128079e-04, 2.0441656e-04], dtype=float32), (490, 7))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert pred_probs to classes\n",
        "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
        "model_2_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXAY6J96P0sU",
        "outputId": "1cc9b15f-5824-4240-818c-f2b4da30b863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(490,), dtype=int64, numpy=\n",
              "array([1, 4, 6, 2, 0, 6, 3, 0, 4, 1, 1, 0, 3, 2, 4, 3, 0, 2, 0, 5, 2, 6,\n",
              "       0, 1, 5, 4, 5, 6, 4, 5, 4, 6, 2, 5, 6, 5, 4, 4, 1, 1, 1, 6, 2, 5,\n",
              "       6, 2, 5, 3, 3, 6, 1, 4, 4, 2, 3, 2, 1, 4, 4, 2, 5, 6, 3, 2, 4, 0,\n",
              "       6, 4, 6, 4, 6, 0, 4, 3, 3, 0, 4, 0, 2, 4, 2, 2, 2, 5, 4, 6, 1, 0,\n",
              "       3, 4, 1, 4, 6, 6, 5, 3, 4, 3, 0, 3, 5, 2, 3, 5, 3, 4, 3, 4, 1, 2,\n",
              "       4, 5, 4, 5, 6, 6, 1, 5, 6, 0, 5, 0, 4, 0, 1, 1, 6, 5, 2, 1, 2, 2,\n",
              "       2, 3, 4, 5, 0, 6, 3, 0, 3, 3, 1, 0, 3, 1, 5, 1, 1, 3, 1, 0, 0, 3,\n",
              "       2, 4, 3, 1, 2, 3, 4, 3, 5, 1, 4, 1, 3, 6, 4, 2, 0, 4, 4, 3, 1, 6,\n",
              "       4, 3, 3, 1, 2, 3, 2, 6, 5, 1, 0, 5, 5, 3, 6, 1, 6, 0, 5, 1, 3, 3,\n",
              "       0, 0, 1, 6, 1, 3, 0, 1, 0, 3, 1, 3, 5, 3, 6, 0, 1, 3, 5, 0, 6, 1,\n",
              "       1, 2, 1, 1, 2, 0, 1, 5, 6, 5, 5, 2, 5, 3, 4, 5, 4, 6, 1, 5, 6, 3,\n",
              "       0, 4, 6, 5, 2, 0, 4, 2, 3, 3, 4, 6, 1, 0, 2, 6, 6, 0, 0, 6, 4, 3,\n",
              "       2, 6, 0, 0, 0, 4, 4, 2, 5, 4, 0, 0, 4, 2, 1, 4, 3, 3, 1, 6, 4, 2,\n",
              "       0, 1, 2, 2, 2, 1, 1, 4, 1, 2, 6, 1, 6, 1, 1, 2, 1, 2, 2, 1, 1, 1,\n",
              "       2, 3, 6, 0, 5, 3, 1, 0, 0, 2, 0, 4, 1, 3, 1, 0, 5, 1, 2, 6, 3, 6,\n",
              "       1, 3, 3, 5, 2, 1, 0, 1, 1, 3, 5, 2, 4, 5, 3, 1, 3, 4, 4, 6, 0, 0,\n",
              "       4, 0, 3, 1, 6, 0, 6, 2, 4, 5, 1, 4, 2, 6, 5, 3, 4, 5, 1, 5, 5, 2,\n",
              "       3, 0, 1, 3, 4, 5, 1, 6, 6, 4, 5, 6, 6, 2, 4, 6, 6, 4, 2, 3, 3, 3,\n",
              "       5, 1, 6, 6, 6, 0, 6, 6, 4, 3, 6, 5, 3, 4, 0, 4, 2, 2, 3, 1, 4, 0,\n",
              "       2, 2, 0, 1, 2, 6, 4, 2, 3, 2, 5, 0, 3, 0, 6, 2, 6, 5, 0, 5, 5, 0,\n",
              "       2, 6, 5, 5, 3, 2, 2, 3, 6, 3, 1, 4, 0, 4, 3, 1, 1, 5, 1, 3, 2, 4,\n",
              "       1, 0, 2, 6, 6, 5, 5, 6, 4, 4, 3, 6, 4, 6, 4, 0, 0, 5, 1, 3, 3, 0,\n",
              "       3, 3, 2, 4, 5, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model results\n",
        "model_2_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU5xoBUUP0py",
        "outputId": "f240b94d-46e7-4ee8-dda6-622226195b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 93.06122448979592,\n",
              " 'f1': 0.9313862997916361,\n",
              " 'precision': 0.9334231576116824,\n",
              " 'recall': 0.9306122448979591}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "bert = TFAutoModel.from_pretrained(\"dbmdz/bert-base-turkish-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "b72379c0698c47918db02a5a0697d1b7",
            "a421f77c9a074bce99bff031eeecd813",
            "ff02092fe361420cba422a95ba378177",
            "43a155338e014ef1825396c498d7fafa",
            "e263de325eb44c07ac3a5badaa93f922",
            "43549ce0a28b4b3589bc74c1a4b594a9",
            "fc38e0b351af4d33ba77108c3cf201f3",
            "82d3573978814f08b0b0454f63987f82",
            "4e2ce5ff1d934c8087279be82899ed7c",
            "8b42bbb68c624719ad9692b48efa9ed8",
            "ad3b4f073c9b426dbe0697d943eb00ea",
            "944ff42b5193412ba712404979000986",
            "8481a78552e442d0ae9b41efab43ff1c",
            "580a73b0b12d46fd917377645f7c9146",
            "4ac6613be00a4100b950aba9fc342256",
            "83503dafc5744159a6162c0e7e37bd7c",
            "6ead44362f6c48bb8b6c3c2534eb7e9a",
            "10b7b23bd1d5459fb1d0933a26ecaba6",
            "bc2d581101354e08a26f74e3d9fade67",
            "197432ca8ce540fe801e7f36c9268931",
            "74251337a9254e2799898f9bebfec549",
            "15fbfc4956174b5b9421a6b597d237be"
          ]
        },
        "id": "wIdUQ23k0hbE",
        "outputId": "d891657b-8d0f-429c-ec96-2151807ac749"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b72379c0698c47918db02a5a0697d1b7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "944ff42b5193412ba712404979000986",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/520M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at dbmdz/bert-base-turkish-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at dbmdz/bert-base-turkish-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# two input layers, we ensure layer name variables match to dictionary keys in TF dataset\n",
        "input_ids = tf.keras.layers.Input(shape=(250,), name='input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(250,), name='attention_mask', dtype='int32')\n",
        "\n",
        "# we access the transformer model within our bert object using the bert attribute (eg bert.bert instead of bert)\n",
        "embeddings = bert.bert(input_ids, attention_mask=mask)[1]  # access final activations (already max-pooled) [1]\n",
        "# convert bert embeddings into 6 output classes\n",
        "#x = tf.keras.layers.Dropout(0.1)(embeddings)\n",
        "x = tf.keras.layers.Dense(112, activation='relu')(embeddings)\n",
        "outputs = tf.keras.layers.Dense(7, activation='softmax', name='outputs')(x)\n",
        "\n",
        "# model\n",
        "model_3 = tf.keras.Model(inputs=[input_ids, mask], outputs=outputs)"
      ],
      "metadata": {
        "id": "KNjpRtFB0hYW"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.layers[2].trainable=True\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcNoP0CB0hWE",
        "outputId": "91c42321-80dd-4a8a-ebd7-a0977f225039"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 250)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 250)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  110617344   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 250,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 112)          86128       ['bert[3][1]']                   \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 7)            791         ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 110,704,263\n",
            "Trainable params: 110,704,263\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
        "\n",
        "model_3.compile(optimizer=optimizer, \n",
        "              loss=loss, \n",
        "              metrics=[acc])"
      ],
      "metadata": {
        "id": "aehDqpL90hTj"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history_3 = model_3.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=3,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IiOV8x70hC0",
        "outputId": "479738c4-e126-42c9-b09c-0e791e02a41d"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "248/248 [==============================] - 439s 2s/step - loss: 1.1780 - accuracy: 0.5499 - val_loss: 1.1073 - val_accuracy: 0.6041\n",
            "Epoch 2/3\n",
            "248/248 [==============================] - 415s 2s/step - loss: 0.7019 - accuracy: 0.7737 - val_loss: 0.8573 - val_accuracy: 0.7330\n",
            "Epoch 3/3\n",
            "248/248 [==============================] - 417s 2s/step - loss: 0.4692 - accuracy: 0.8589 - val_loss: 0.6381 - val_accuracy: 0.8190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test_ds\n",
        "model_3.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnPTb7RMbVoZ",
        "outputId": "1acf4a23-aa23-4a2d-8275-740aa6d518f1"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 17s 550ms/step - loss: 0.6548 - accuracy: 0.8224\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.65479576587677, 0.8224489688873291]"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "model_3_pred_probs = model_3.predict(test_dataset)\n",
        "model_3_pred_probs[0], model_3_pred_probs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWqcnDBzbVl7",
        "outputId": "abbbc91f-387f-41a2-db9d-272e125caf69"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.3398643e-02, 9.3429285e-01, 1.4642811e-02, 7.1787969e-03,\n",
              "        7.0928917e-03, 4.2697377e-04, 2.2966960e-02], dtype=float32), (490, 7))"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert pred_probs to classes\n",
        "model_3_preds = tf.argmax(model_3_pred_probs, axis=1)\n",
        "model_3_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3r1zm84bVjZ",
        "outputId": "f0fe016f-b388-497d-d7e5-cb2e5e15538a"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(490,), dtype=int64, numpy=\n",
              "array([1, 6, 4, 4, 2, 5, 4, 0, 5, 1, 0, 2, 6, 0, 5, 5, 1, 3, 2, 3, 4, 2,\n",
              "       5, 3, 1, 6, 3, 5, 3, 6, 4, 6, 0, 3, 2, 2, 6, 2, 1, 0, 4, 2, 0, 4,\n",
              "       3, 4, 1, 0, 2, 4, 4, 2, 5, 2, 0, 2, 5, 0, 0, 4, 5, 4, 0, 5, 5, 0,\n",
              "       6, 4, 0, 3, 2, 3, 4, 2, 3, 1, 0, 2, 1, 5, 5, 2, 4, 6, 2, 2, 3, 6,\n",
              "       1, 2, 0, 3, 2, 1, 6, 1, 6, 4, 1, 4, 0, 2, 2, 6, 3, 3, 0, 5, 0, 6,\n",
              "       3, 1, 6, 0, 4, 6, 0, 6, 4, 5, 0, 6, 5, 2, 0, 5, 0, 4, 0, 1, 1, 0,\n",
              "       5, 6, 1, 4, 6, 4, 5, 2, 6, 3, 3, 4, 6, 1, 1, 1, 2, 2, 6, 5, 1, 4,\n",
              "       6, 2, 3, 0, 4, 2, 4, 5, 3, 6, 3, 4, 4, 2, 5, 3, 3, 2, 6, 4, 1, 6,\n",
              "       3, 4, 5, 3, 1, 2, 2, 1, 2, 0, 4, 2, 0, 3, 3, 2, 4, 3, 5, 0, 1, 1,\n",
              "       3, 2, 4, 3, 5, 3, 0, 4, 0, 3, 1, 6, 2, 2, 2, 2, 0, 0, 3, 0, 1, 4,\n",
              "       2, 2, 0, 4, 3, 0, 0, 4, 5, 0, 1, 1, 6, 4, 1, 1, 2, 4, 1, 0, 4, 6,\n",
              "       6, 3, 6, 2, 5, 6, 2, 0, 4, 0, 4, 3, 3, 3, 5, 3, 5, 5, 5, 3, 3, 3,\n",
              "       4, 0, 3, 2, 6, 4, 3, 0, 0, 1, 4, 6, 5, 5, 0, 1, 6, 4, 1, 2, 1, 3,\n",
              "       2, 6, 2, 3, 6, 0, 5, 5, 6, 0, 6, 3, 2, 2, 5, 3, 4, 6, 6, 3, 0, 1,\n",
              "       5, 0, 3, 4, 5, 6, 5, 1, 4, 1, 1, 3, 1, 6, 2, 0, 5, 1, 2, 1, 6, 6,\n",
              "       0, 2, 1, 4, 0, 6, 1, 6, 3, 4, 1, 5, 6, 5, 0, 0, 4, 3, 5, 5, 1, 1,\n",
              "       5, 5, 4, 3, 3, 6, 5, 2, 5, 2, 6, 6, 1, 1, 6, 3, 3, 0, 6, 1, 3, 3,\n",
              "       0, 0, 1, 0, 2, 0, 6, 0, 6, 4, 0, 0, 2, 0, 4, 2, 0, 0, 2, 1, 3, 5,\n",
              "       2, 0, 6, 3, 2, 5, 0, 3, 6, 6, 2, 6, 1, 4, 0, 0, 4, 3, 5, 5, 0, 3,\n",
              "       1, 0, 4, 0, 3, 1, 4, 2, 1, 2, 4, 3, 3, 0, 4, 1, 3, 1, 2, 1, 2, 0,\n",
              "       6, 6, 0, 3, 1, 0, 4, 2, 2, 0, 3, 2, 2, 4, 6, 1, 5, 5, 1, 4, 1, 0,\n",
              "       4, 4, 4, 6, 4, 5, 6, 4, 4, 5, 0, 5, 0, 6, 1, 1, 0, 0, 2, 2, 6, 1,\n",
              "       5, 5, 4, 0, 4, 5])>"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model results\n",
        "model_3_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbVpmzHSbVgw",
        "outputId": "251cfe80-8a77-49d8-9c53-fbd0b9e3728c"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 82.24489795918367,\n",
              " 'f1': 0.8243684226528627,\n",
              " 'precision': 0.8308263461882649,\n",
              " 'recall': 0.8224489795918367}"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    }
  ]
}