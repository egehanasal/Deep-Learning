{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Turkish_sentiment_analysis_KTRAIN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWAM-m35Xoer"
      },
      "source": [
        "Data: https://www.kaggle.com/mustfkeskin/turkish-movie-sentiment-analysis-dataset/code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DbOIZTKpUfJ",
        "outputId": "4c9b9012-1a27-40eb-948c-c9a30f74b150"
      },
      "source": [
        "!pip install ktrain"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ktrain\n",
            "  Downloading ktrain-0.28.3.tar.gz (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 1.5 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 14.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.2.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.1.5)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ktrain) (21.3)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 30.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.42.1)\n",
            "Collecting cchardet\n",
            "  Downloading cchardet-2.1.7-cp37-cp37m-manylinux2010_x86_64.whl (263 kB)\n",
            "\u001b[K     |████████████████████████████████| 263 kB 51.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.0.4)\n",
            "Collecting syntok\n",
            "  Downloading syntok-1.3.1.tar.gz (23 kB)\n",
            "Collecting seqeval==0.0.19\n",
            "  Downloading seqeval-0.0.19.tar.gz (30 kB)\n",
            "Collecting transformers<=4.10.3,>=4.0.0\n",
            "  Downloading transformers-4.10.3-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 48.9 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 50.1 MB/s \n",
            "\u001b[?25hCollecting keras_bert>=0.86.0\n",
            "  Downloading keras-bert-0.88.0.tar.gz (26 kB)\n",
            "Collecting whoosh\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[K     |████████████████████████████████| 468 kB 43.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.4.1)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.19->ktrain) (2.7.0)\n",
            "Collecting keras-transformer>=0.39.0\n",
            "  Downloading keras-transformer-0.39.0.tar.gz (11 kB)\n",
            "Collecting keras-pos-embd>=0.12.0\n",
            "  Downloading keras-pos-embd-0.12.0.tar.gz (6.0 kB)\n",
            "Collecting keras-multi-head>=0.28.0\n",
            "  Downloading keras-multi-head-0.28.0.tar.gz (14 kB)\n",
            "Collecting keras-layer-normalization>=0.15.0\n",
            "  Downloading keras-layer-normalization-0.15.0.tar.gz (4.2 kB)\n",
            "Collecting keras-position-wise-feed-forward>=0.7.0\n",
            "  Downloading keras-position-wise-feed-forward-0.7.0.tar.gz (4.5 kB)\n",
            "Collecting keras-embed-sim>=0.9.0\n",
            "  Downloading keras-embed-sim-0.9.0.tar.gz (4.1 kB)\n",
            "Collecting keras-self-attention>=0.50.0\n",
            "  Downloading keras-self-attention-0.50.0.tar.gz (12 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0.0->ktrain) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (3.4.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 48.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 30.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (4.8.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 50.0 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers<=4.10.3,>=4.0.0->ktrain) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.10.3,>=4.0.0->ktrain) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.10.3,>=4.0.0->ktrain) (7.1.2)\n",
            "Building wheels for collected packages: ktrain, seqeval, keras-bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect, syntok\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.28.3-py3-none-any.whl size=25292659 sha256=2cf2a06398a2c424a6f9e43e66dd929eece7014e97000802c0a637dd6cf06440\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/7e/c3/f46cdfc2b81c54424923b1405d7e670c35cacc11ada9a47b1c\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.19-py3-none-any.whl size=9929 sha256=04d716761182616924c2f5b3328a06ea5fd2c7c60f3cbf3427638833b7f99790\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/ac/f1/4e13d7aff05c722d142b7d20a88ad63f9aab11b895411241a4\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.88.0-py3-none-any.whl size=34204 sha256=1740d69f3722f11145f9e7d656f262cd2c20de70b0293d8edd7b010aa7918e44\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/90/cd/c038f2366929a3a5e3414a303b673e10235e802d871d29a835\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.39.0-py3-none-any.whl size=12842 sha256=b290eb6ea8452b4a97968a08d2dd6e9f1b8cefd57127afe6066f3626af40f021\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/01/e0/5a1a14bed6726f2ed73f7917d2d2c2d4081d2c88426dea07ce\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.9.0-py3-none-any.whl size=4504 sha256=20e86b0dcbc3808e4e0de9d6d5fd546c38a3e569fa5153dfcc3d72a67565b92d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/1e/d2/9bc15513dd2f8b9de3e628b3aa9d2de49e721deef6bbd1497e\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.15.0-py3-none-any.whl size=5224 sha256=edc1c2c4b129918ee900e7c808e97293b691e820e412d5c021fb3567d3f7d480\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/be/fe/55422f77ac11fe6ddcb471198038de8a26b5a4dd1557883c1e\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.28.0-py3-none-any.whl size=15559 sha256=f99bc8fd1c41a46c77e4e87cbe53ce299bab569133ff68feb0436ed220d0b604\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/4a/ea/9503ab5a02201dfb8635ba2cc8f30844661623c684a5b44472\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.12.0-py3-none-any.whl size=7469 sha256=f1ac8fe238b233913aded54ab4e3cad7d4031e87066c3ea6f233a4c43eb3fc83\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/99/fd/dd98f4876c3ebbef7aab0dbfbd37bca41d7db37d3a28b2cb09\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.7.0-py3-none-any.whl size=5541 sha256=aa6b566403491e643b4ca01d50c44f1a7a127668dca20289185ead78149151fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/12/02/1ad455c4f181cda1a4e60c5445855853d5c2ea91f942586a04\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.50.0-py3-none-any.whl size=19414 sha256=6d7aae79716bf2dc02fd64cc59e3e2eae5edd0b4d12451e26fb2009e6fc0da4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/7a/a3/231bef5803298e7ec1815215bc0613239cb1e9c03c57b13c14\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=ee558e3435dc5d74edbcca5f5512ea7e0cad7765f5305a84e733feb76f76f209\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for syntok: filename=syntok-1.3.1-py3-none-any.whl size=20917 sha256=f2cb2ca8e13931c645b0edb0c7d73a3fb6347c7e680e18d19d9aba09f31e1862\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/c2/33/e5d7d8f2f8b0c391d76bf82b844c3151bf23a84d75d02b185f\n",
            "Successfully built ktrain seqeval keras-bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect syntok\n",
            "Installing collected packages: keras-self-attention, pyyaml, keras-position-wise-feed-forward, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-embed-sim, tokenizers, sacremoses, keras-transformer, huggingface-hub, whoosh, transformers, syntok, seqeval, sentencepiece, scikit-learn, langdetect, keras-bert, cchardet, ktrain\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\u001b[0m\n",
            "Successfully installed cchardet-2.1.7 huggingface-hub-0.1.2 keras-bert-0.88.0 keras-embed-sim-0.9.0 keras-layer-normalization-0.15.0 keras-multi-head-0.28.0 keras-pos-embd-0.12.0 keras-position-wise-feed-forward-0.7.0 keras-self-attention-0.50.0 keras-transformer-0.39.0 ktrain-0.28.3 langdetect-1.0.9 pyyaml-6.0 sacremoses-0.0.46 scikit-learn-0.23.2 sentencepiece-0.1.96 seqeval-0.0.19 syntok-1.3.1 tokenizers-0.10.3 transformers-4.10.3 whoosh-2.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XV_OgZRK7tT0",
        "outputId": "40890d85-981b-4317-f914-4ed317173b29"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"turkish_movie_sentiment_dataset.csv\")\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>film_name</th>\n",
              "      <th>point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\n                      Jean Reno denince zate...</td>\n",
              "      <td>Sevginin Gücü</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n                      Ekşın falan izlemek is...</td>\n",
              "      <td>Sevginin Gücü</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\n                      Bu yapım hakkında öyle...</td>\n",
              "      <td>Sevginin Gücü</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\n                      finali yeter... (sting...</td>\n",
              "      <td>Sevginin Gücü</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\n                      Jean Reno..\\r\\nbu adam...</td>\n",
              "      <td>Sevginin Gücü</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment      film_name point\n",
              "0  \\n                      Jean Reno denince zate...  Sevginin Gücü   5,0\n",
              "1  \\n                      Ekşın falan izlemek is...  Sevginin Gücü   5,0\n",
              "2  \\n                      Bu yapım hakkında öyle...  Sevginin Gücü   5,0\n",
              "3  \\n                      finali yeter... (sting...  Sevginin Gücü   5,0\n",
              "4  \\n                      Jean Reno..\\r\\nbu adam...  Sevginin Gücü   5,0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSLTSmUj7tRD",
        "outputId": "ac8ad1d5-172e-4272-a7c2-1e01a77aca59"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 83227 entries, 0 to 83226\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   comment    83227 non-null  object\n",
            " 1   film_name  83227 non-null  object\n",
            " 2   point      83227 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 1.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMc2XrZVOBBw"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUI9LV3bpIHc"
      },
      "source": [
        "### Preprocessing guide:\n",
        "\n",
        "* 1: Organize the dataset and comment column\n",
        "* 2: Drop film_name column\n",
        "* 3: Change point column's rows to integers\n",
        "* 4: Remove punctuation (comment column) and lower the inputs\n",
        "* 5: Remove stopwords and make sentences lower(comment column)\n",
        "* 6: Stemming (comment column)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfW7r5LW7tOD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e50bf9d9-3813-44b9-f583-efb0e4784db6"
      },
      "source": [
        "# Remove the unnecessary characters (space chars, \\n and etc.) from the beginning and at the end\n",
        "df[\"comment\"] = df[\"comment\"].str[23:-22]\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>film_name</th>\n",
              "      <th>point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jean Reno denince zaten leon filmi gelir akla ...</td>\n",
              "      <td>Sevginin Gücü</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ekşın falan izlemek istiyorsanız eğer bunu izl...</td>\n",
              "      <td>Sevginin Gücü</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bu yapım hakkında öyle çok şey yazabilirim ki ...</td>\n",
              "      <td>Sevginin Gücü</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>finali yeter... (sting - shape of my heart)\\r\\...</td>\n",
              "      <td>Sevginin Gücü</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jean Reno..\\r\\nbu adam kusursuz biri..\\r\\nve o...</td>\n",
              "      <td>Sevginin Gücü</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment      film_name point\n",
              "0  Jean Reno denince zaten leon filmi gelir akla ...  Sevginin Gücü   5,0\n",
              "1  Ekşın falan izlemek istiyorsanız eğer bunu izl...  Sevginin Gücü   5,0\n",
              "2  Bu yapım hakkında öyle çok şey yazabilirim ki ...  Sevginin Gücü   5,0\n",
              "3  finali yeter... (sting - shape of my heart)\\r\\...  Sevginin Gücü   5,0\n",
              "4  Jean Reno..\\r\\nbu adam kusursuz biri..\\r\\nve o...  Sevginin Gücü   5,0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "a00-2ThQHLBV",
        "outputId": "1b848730-5602-4ea1-c0b6-c06898710a09"
      },
      "source": [
        "# Drop \"film_name\" column\n",
        "df.drop(\"film_name\", axis=1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jean Reno denince zaten leon filmi gelir akla ...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ekşın falan izlemek istiyorsanız eğer bunu izl...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bu yapım hakkında öyle çok şey yazabilirim ki ...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>finali yeter... (sting - shape of my heart)\\r\\...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jean Reno..\\r\\nbu adam kusursuz biri..\\r\\nve o...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment point\n",
              "0  Jean Reno denince zaten leon filmi gelir akla ...   5,0\n",
              "1  Ekşın falan izlemek istiyorsanız eğer bunu izl...   5,0\n",
              "2  Bu yapım hakkında öyle çok şey yazabilirim ki ...   5,0\n",
              "3  finali yeter... (sting - shape of my heart)\\r\\...   5,0\n",
              "4  Jean Reno..\\r\\nbu adam kusursuz biri..\\r\\nve o...   5,0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_vvmT_uOf7c"
      },
      "source": [
        "### Remove punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9icG6wCiOhvW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "cbcfc0ba-1ab8-4237-ab45-9e29e4b99919"
      },
      "source": [
        "df['comment'] = df['comment'].str.replace(r'[^\\w\\s]+', '')\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jean Reno denince zaten leon filmi gelir akla ...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ekşın falan izlemek istiyorsanız eğer bunu izl...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bu yapım hakkında öyle çok şey yazabilirim ki ...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>finali yeter sting  shape of my heart\\r\\n\\r\\nb...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jean Reno\\r\\nbu adam kusursuz biri\\r\\nve oyunc...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment point\n",
              "0  Jean Reno denince zaten leon filmi gelir akla ...   5,0\n",
              "1  Ekşın falan izlemek istiyorsanız eğer bunu izl...   5,0\n",
              "2  Bu yapım hakkında öyle çok şey yazabilirim ki ...   5,0\n",
              "3  finali yeter sting  shape of my heart\\r\\n\\r\\nb...   5,0\n",
              "4  Jean Reno\\r\\nbu adam kusursuz biri\\r\\nve oyunc...   5,0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9esrwE9pIHk"
      },
      "source": [
        "### Lower the inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "33zw11WopIHl",
        "outputId": "a41e2383-4f2d-4f0d-e258-711daf3c0448"
      },
      "source": [
        "df[\"comment\"] = df[\"comment\"].str.lower()\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jean reno denince zaten leon filmi gelir akla ...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ekşın falan izlemek istiyorsanız eğer bunu izl...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bu yapım hakkında öyle çok şey yazabilirim ki ...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>finali yeter sting  shape of my heart\\r\\n\\r\\nb...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jean reno\\r\\nbu adam kusursuz biri\\r\\nve oyunc...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment point\n",
              "0  jean reno denince zaten leon filmi gelir akla ...   5,0\n",
              "1  ekşın falan izlemek istiyorsanız eğer bunu izl...   5,0\n",
              "2  bu yapım hakkında öyle çok şey yazabilirim ki ...   5,0\n",
              "3  finali yeter sting  shape of my heart\\r\\n\\r\\nb...   5,0\n",
              "4  jean reno\\r\\nbu adam kusursuz biri\\r\\nve oyunc...   5,0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKDzOEVkpIHm"
      },
      "source": [
        "### Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFl75kfdHK_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0790553e-5918-47e8-e14f-a427c43396e2"
      },
      "source": [
        "# Import the nltk library and download stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9FMp5AfHK2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f68ebef-411e-4b86-e19c-fe9a9e78cbde"
      },
      "source": [
        "# Get the stopwords\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words(\"turkish\")\n",
        "stop_words[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['acaba',\n",
              " 'ama',\n",
              " 'aslında',\n",
              " 'az',\n",
              " 'bazı',\n",
              " 'belki',\n",
              " 'biri',\n",
              " 'birkaç',\n",
              " 'birşey',\n",
              " 'biz']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp6DvTaWpIHo",
        "outputId": "5c27c5ca-9523-496f-db4a-cd39fe8d92c8"
      },
      "source": [
        "# Create a function to print each line of the inputs\n",
        "def print_lines(column, n): \n",
        "    counter = 0\n",
        "    for i in column:\n",
        "        print(i)\n",
        "        print(\"########\\n\")\n",
        "        counter+=1\n",
        "        if counter == n:\n",
        "            break\n",
        "\n",
        "print_lines(df[\"comment\"], 3)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jean reno denince zaten leon filmi gelir akla izlemeyen kalmamıştır ama kaldıysada ee ne duruyorsun hemen izle \n",
            "########\n",
            "\n",
            "ekşın falan izlemek istiyorsanız eğer bunu izlemeyiin dostlarım keza ilk sahne hariç ekşın filmde yerini gittikçe duygusallığa bırakır mathildanın leonun evine geldiğinde ağladığı sahnede ben de ağlamış olabilirim tamam olabilirim değil ağladım ama sen de izle ağlarsın dostooom \r\n",
            "etkileyici bir film sıkmıyor hiçbir salise boyunca sizi\r\n",
            " ben artık büyüdüm leon yaşlanıyorum \r\n",
            " hayat hep böyle zor mu yoksa sadece çocukken mi \n",
            "########\n",
            "\n",
            "bu yapım hakkında öyle çok şey yazabilirim ki kitap olur o yüzden kısa kesmem lazım bir kere ağladığım iki filmden birisidirdiğeri  yeşil yol i̇zlediğim en iyi film midir karar veremeyeceğim ama izlediğim en sanatsal sahneleri barındıran luc besson harikası olduğu kesindir \r\n",
            "\r\n",
            "oyunculardan sıkça bahseldilmiş o konuya girmeyeceğim ama luc besson abi sen de ne cevher varmış demekten kendimi alamıyorum yönetmenlikten çabuk çekilerek kıytırık aksiyon filmlerine senaryo yazman çok yazık oldu gerçekten tüm bu övgülerim eric serra içinde geçerlidir nitekim hiç abartmıyorum filmin  50 si eric serra nın hakkıdır muhteşem melodilerine hayranım \r\n",
            "\r\n",
            "son olarak natalie portman a değineyim sen ne kadar tatlı munis bir şeymişsin yahu küçükken ayrı bir havan şimdi ayrı bir havan var az yazalım dedik ama döktürmüşüm görüyorumki buradan da anlayabilirsiniz hayatımın filmi olduğunu\n",
            "########\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnmHDrDDHK0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c8f039-4fe6-4cca-d296-da45d193e920"
      },
      "source": [
        "# Remove stopwords from each line and check the lines\n",
        "stop_words = set(stop_words)\n",
        "df['comment'] = df['comment'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
        "\n",
        "print_lines(df[\"comment\"], 3)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jean reno denince zaten leon filmi gelir akla izlemeyen kalmamıştır kaldıysada ee duruyorsun hemen izle\n",
            "########\n",
            "\n",
            "ekşın falan izlemek istiyorsanız bunu izlemeyiin dostlarım keza ilk sahne hariç ekşın filmde yerini gittikçe duygusallığa bırakır mathildanın leonun evine geldiğinde ağladığı sahnede ben ağlamış olabilirim tamam olabilirim değil ağladım sen izle ağlarsın dostooom etkileyici bir film sıkmıyor hiçbir salise boyunca sizi ben artık büyüdüm leon yaşlanıyorum hayat böyle zor yoksa sadece çocukken mi\n",
            "########\n",
            "\n",
            "yapım hakkında öyle yazabilirim kitap olur yüzden kısa kesmem lazım bir kere ağladığım iki filmden birisidirdiğeri yeşil yol i̇zlediğim iyi film midir karar veremeyeceğim izlediğim sanatsal sahneleri barındıran luc besson harikası olduğu kesindir oyunculardan sıkça bahseldilmiş konuya girmeyeceğim luc besson abi sen cevher varmış demekten kendimi alamıyorum yönetmenlikten çabuk çekilerek kıytırık aksiyon filmlerine senaryo yazman yazık oldu gerçekten övgülerim eric serra içinde geçerlidir nitekim abartmıyorum filmin 50 si eric serra nın hakkıdır muhteşem melodilerine hayranım son olarak natalie portman a değineyim sen kadar tatlı munis bir şeymişsin yahu küçükken ayrı bir havan şimdi ayrı bir havan var yazalım dedik döktürmüşüm görüyorumki buradan anlayabilirsiniz hayatımın filmi olduğunu\n",
            "########\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRXwia04pIHp"
      },
      "source": [
        "### Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_te73xVFsVax",
        "outputId": "b65271fa-f40f-4834-c8db-0a9e24deb974"
      },
      "source": [
        "!pip install TurkishStemmer"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting TurkishStemmer\n",
            "  Downloading TurkishStemmer-1.3-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: TurkishStemmer\n",
            "Successfully installed TurkishStemmer-1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiZSi75iJ0tb"
      },
      "source": [
        "# Import the library and get the stemmer for Turkish Language\n",
        "from TurkishStemmer import TurkishStemmer\n",
        "\n",
        "stemmer = TurkishStemmer()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9QpFNsmXpIHq",
        "outputId": "32db9b41-7860-47f4-dde6-501fa9d3efb3"
      },
      "source": [
        "# To use stemmer on each word, turn each line into a list\n",
        "df['comment'] = df['comment'].str.split()\n",
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[jean, reno, denince, zaten, leon, filmi, geli...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[ekşın, falan, izlemek, istiyorsanız, bunu, iz...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[yapım, hakkında, öyle, yazabilirim, kitap, ol...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[finali, yeter, sting, shape, of, my, heart, b...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[jean, reno, adam, kusursuz, oyunculugu, müthi...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment point\n",
              "0  [jean, reno, denince, zaten, leon, filmi, geli...   5,0\n",
              "1  [ekşın, falan, izlemek, istiyorsanız, bunu, iz...   5,0\n",
              "2  [yapım, hakkında, öyle, yazabilirim, kitap, ol...   5,0\n",
              "3  [finali, yeter, sting, shape, of, my, heart, b...   5,0\n",
              "4  [jean, reno, adam, kusursuz, oyunculugu, müthi...   5,0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MjQePkDApIHq",
        "outputId": "e301e719-76fa-4fe5-b2a0-88626279e7fe"
      },
      "source": [
        "# Apply stemmer\n",
        "df['comment'] = df['comment'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[jean, reno, deni, zaten, leon, film, gelir, a...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[ekşı, falan, izlemek, istiyor, bun, izlemey, ...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[yap, hakk, öyl, yazabilir, kitap, olur, yüz, ...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[finali, yeter, sting, shape, of, my, heart, b...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[jean, reno, ada, kusurs, oyunculug, müthiş, f...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment point\n",
              "0  [jean, reno, deni, zaten, leon, film, gelir, a...   5,0\n",
              "1  [ekşı, falan, izlemek, istiyor, bun, izlemey, ...   5,0\n",
              "2  [yap, hakk, öyl, yazabilir, kitap, olur, yüz, ...   5,0\n",
              "3  [finali, yeter, sting, shape, of, my, heart, b...   5,0\n",
              "4  [jean, reno, ada, kusurs, oyunculug, müthiş, f...   5,0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mm95-WepIHr",
        "outputId": "aa0daa98-2ff3-4559-d052-098037258d5c"
      },
      "source": [
        "# Check the lines\n",
        "print_lines(df[\"comment\"], 3)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['jean', 'reno', 'deni', 'zaten', 'leon', 'film', 'gelir', 'akl', 'izlemeyen', 'kalm', 'kaldıysa', 'e', 'duruyor', 'hemen', 'izl']\n",
            "########\n",
            "\n",
            "['ekşı', 'falan', 'izlemek', 'istiyor', 'bun', 'izlemey', 'dost', 'keza', 'ilk', 'sahne', 'hariç', 'ekşı', 'film', 'yer', 'gittikç', 'duygusallık', 'bırakır', 'mathilda', 'leon', 'ev', 'geldik', 'ağladık', 'sahne', 'ben', 'ağla', 'olabilir', 'tama', 'olabilir', 'değil', 'ağla', 'sen', 'izl', 'ağlar', 'dostooom', 'etkileyiç', 'bir', 'film', 'sıkmıyor', 'hiçbir', 'sali', 'boyu', 'siz', 'ben', 'ar', 'büyü', 'leon', 'yaşlanıyor', 'hayat', 'böyl', 'zor', 'yoks', 'sade', 'çocukken', 'mi']\n",
            "########\n",
            "\n",
            "['yap', 'hakk', 'öyl', 'yazabilir', 'kitap', 'olur', 'yüz', 'kıs', 'kesme', 'lazım', 'bir', 'ker', 'ağladık', 'ik', 'film', 'birisidirdiğer', 'yeşil', 'yol', 'i̇zlediğim', 'iyi', 'film', 'mi', 'karar', 'veremeyecek', 'izledik', 'sanatsal', 'sahne', 'barındıran', 'luc', 'besson', 'harika', 'olduk', 'kes', 'oyuncu', 'sıkç', 'bahseldil', 'konu', 'girmeyecek', 'luc', 'besson', 'abi', 'sen', 'cevher', 'var', 'demek', 'kent', 'alamıyor', 'yönetmenlik', 'çabuk', 'çekilerek', 'kıytırık', 'aksiyon', 'film', 'senaryo', 'yazman', 'yazık', 'olt', 'gerçek', 'övgü', 'eric', 'serra', 'iç', 'geçer', 'nitek', 'abartmıyor', 'film', '50', 'si', 'eric', 'serra', 'nın', 'hakk', 'muhteşe', 'melodi', 'hayran', 'son', 'olarak', 'natali', 'portman', 'a', 'dek', 'sen', 'kadar', 'tatl', 'munis', 'bir', 'şe', 'yahu', 'küçük', 'ayr', 'bir', 'havan', 'şimt', 'ayr', 'bir', 'havan', 'var', 'yazal', 'de', 'döktür', 'görüyorumki', 'bura', 'anlayabilir', 'hayat', 'film', 'olduk']\n",
            "########\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh4uP4FiMZlq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "980207bc-f986-486f-b316-f2d4ed057568"
      },
      "source": [
        "# Turn back each line to a string (from list)\n",
        "df['comment'] = df['comment'].apply(lambda x: ' '.join(word for word in x))\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jean reno deni zaten leon film gelir akl izlem...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ekşı falan izlemek istiyor bun izlemey dost ke...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yap hakk öyl yazabilir kitap olur yüz kıs kesm...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>finali yeter sting shape of my heart bazı film...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jean reno ada kusurs oyunculug müthiş film baş...</td>\n",
              "      <td>5,0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment point\n",
              "0  jean reno deni zaten leon film gelir akl izlem...   5,0\n",
              "1  ekşı falan izlemek istiyor bun izlemey dost ke...   5,0\n",
              "2  yap hakk öyl yazabilir kitap olur yüz kıs kesm...   5,0\n",
              "3  finali yeter sting shape of my heart bazı film...   5,0\n",
              "4  jean reno ada kusurs oyunculug müthiş film baş...   5,0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYT6et_ipIHs",
        "outputId": "2e104c88-cabe-4aea-ab34-fe51efa31b7f"
      },
      "source": [
        "# Get train sentences from df.comment\n",
        "train_sentences = df[\"comment\"].tolist()\n",
        "\n",
        "train_sentences[:3]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jean reno deni zaten leon film gelir akl izlemeyen kalm kaldıysa e duruyor hemen izl',\n",
              " 'ekşı falan izlemek istiyor bun izlemey dost keza ilk sahne hariç ekşı film yer gittikç duygusallık bırakır mathilda leon ev geldik ağladık sahne ben ağla olabilir tama olabilir değil ağla sen izl ağlar dostooom etkileyiç bir film sıkmıyor hiçbir sali boyu siz ben ar büyü leon yaşlanıyor hayat böyl zor yoks sade çocukken mi',\n",
              " 'yap hakk öyl yazabilir kitap olur yüz kıs kesme lazım bir ker ağladık ik film birisidirdiğer yeşil yol i̇zlediğim iyi film mi karar veremeyecek izledik sanatsal sahne barındıran luc besson harika olduk kes oyuncu sıkç bahseldil konu girmeyecek luc besson abi sen cevher var demek kent alamıyor yönetmenlik çabuk çekilerek kıytırık aksiyon film senaryo yazman yazık olt gerçek övgü eric serra iç geçer nitek abartmıyor film 50 si eric serra nın hakk muhteşe melodi hayran son olarak natali portman a dek sen kadar tatl munis bir şe yahu küçük ayr bir havan şimt ayr bir havan var yazal de döktür görüyorumki bura anlayabilir hayat film olduk']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vJ577eApIHs"
      },
      "source": [
        "### Organize point column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qgcwmruRpIHs",
        "outputId": "218b840b-2d25-48ed-914e-04dcb45e3ae0"
      },
      "source": [
        "# Replace \".\" with \",\"\n",
        "df['point'] = df['point'].str.replace(',','.')\n",
        "# Change data type to float\n",
        "df[\"point\"] = df[\"point\"].astype(float)\n",
        "# Rond every number and make them integers.\n",
        "df[\"point\"] = df[\"point\"].round().astype('int')\n",
        "df.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jean reno deni zaten leon film gelir akl izlem...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ekşı falan izlemek istiyor bun izlemey dost ke...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yap hakk öyl yazabilir kitap olur yüz kıs kesm...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>finali yeter sting shape of my heart bazı film...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jean reno ada kusurs oyunculug müthiş film baş...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  point\n",
              "0  jean reno deni zaten leon film gelir akl izlem...      5\n",
              "1  ekşı falan izlemek istiyor bun izlemey dost ke...      5\n",
              "2  yap hakk öyl yazabilir kitap olur yüz kıs kesm...      5\n",
              "3  finali yeter sting shape of my heart bazı film...      5\n",
              "4  jean reno ada kusurs oyunculug müthiş film baş...      5"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhI9-9lXpIHs",
        "outputId": "fcc7b85d-366f-43cb-ff5e-e1a937ded854"
      },
      "source": [
        "# Get the average and the max length of the inputs\n",
        "import numpy as np\n",
        "\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "max_sent_len = np.max(sent_lens)\n",
        "avg_sent_len, max_sent_len"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36.48517908851695, 3608)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ydd2zLmypIHt",
        "outputId": "c73ea550-d218-46ae-eccc-ac13b4f55fb9"
      },
      "source": [
        "# How long of a sentence lenght covers 95% of examples?\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "\n",
        "output_seq_len"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "113"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyx8n4PdpIHt",
        "outputId": "a6062f53-247c-462e-a7ce-05e4a42dba28"
      },
      "source": [
        "# How long of a sentence lenght covers 97% of examples?\n",
        "x = int(np.percentile(sent_lens, 97))\n",
        "\n",
        "x"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "159"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GYjvKlGpIHu"
      },
      "source": [
        "# Setting it 160 instead of 159 since 160 is divisible to 8.\n",
        "output_seq_len = 160"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk0z8DLopIHu"
      },
      "source": [
        "# Import AutoTokenizer\n",
        "from transformers import AutoTokenizer\n",
        "# Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-128k-uncased\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVKUk1zmpIHu"
      },
      "source": [
        "### Test the tokizer on a sample sentence "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqCtwuQepIHu"
      },
      "source": [
        "# Convert tokens to ids\n",
        "sample_sentence = \"Bu film berbat. Cidden en kötü film ama izlenir yine de\"\n",
        "sample_tokenized_sentence = tokenizer.tokenize(sample_sentence)\n",
        "sample_tokenized_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8LCm3tBpIHv"
      },
      "source": [
        "# Convert ids to tokens\n",
        "sample_ids = tokenizer.convert_tokens_to_ids(sample_tokenized_sentence)\n",
        "sample_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhaPmZLtpIHw"
      },
      "source": [
        "sample_encoded_sentence = tokenizer.encode_plus(\n",
        "    text=sample_sentence, \n",
        "    add_special_tokens=True,\n",
        "    max_length=32,\n",
        "    truncation=True,\n",
        "    pad_to_max_length=True,\n",
        "    return_attention_mask=True,\n",
        "    return_tensors=\"np\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhDNkTxvpIHw"
      },
      "source": [
        "# Get keys for the sample encoded sentence\n",
        "sample_encoded_sentence.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbLw4SnlpIHw"
      },
      "source": [
        "sample_input_ids = sample_encoded_sentence[\"input_ids\"]\n",
        "sample_attention_mask = sample_encoded_sentence[\"attention_mask\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AABuE3lDpIHx"
      },
      "source": [
        "sample_input_ids[:1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj4QgWNupIHx"
      },
      "source": [
        "tokenizer.convert_ids_to_tokens(sample_input_ids[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_dzOcwbpIHx"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGyp_ZGPpIHx"
      },
      "source": [
        "df.dropna(axis=0, inplace=True)\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75HRmp3epIHx"
      },
      "source": [
        "## Encode inputs\n",
        "\n",
        "After experimenting the encoding operation on the sample sentence, now we're ready to encode our inputs (tf.comments)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au4RWfh0pIHy"
      },
      "source": [
        "df.comment.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiDJsieQpIHy"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "input_ids = []\n",
        "attention_mask = []\n",
        "\n",
        "for txt in df.comment.values:\n",
        "    encoded = tokenizer.encode_plus(\n",
        "        text=txt, # the sentence to be encoded \n",
        "        add_special_tokens=True, # Add [CLS] and [SEP]\n",
        "        max_length=160, # max length of a sentence\n",
        "        truncation=True, # truncate if sentence length is bigger than max_length\n",
        "        pad_to_max_length=True, # Add [PAD]s\n",
        "        return_attention_mask=True, # Generate attention mask\n",
        "        return_tensors=\"np\" # return NumPy tensors\n",
        "    )\n",
        "\n",
        "    # Append input_ids and attention_masks to their own lists\n",
        "    input_ids.append(encoded[\"input_ids\"])\n",
        "    attention_mask.append(encoded[\"attention_mask\"])\n",
        "\n",
        "# Concatenate\n",
        "input_ids = tf.concat(input_ids, 0)\n",
        "attention_mask = tf.concat(attention_mask, 0)\n",
        "\n",
        "print(\"Original: \", df.comment.values[0])\n",
        "print(\"Token IDs: \", input_ids[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fDOOrTQpIHy"
      },
      "source": [
        "# Convert tokens to ids to check\n",
        "tokenizer.convert_ids_to_tokens(input_ids[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kcgek_GipIHz"
      },
      "source": [
        "# Check input_ids and shape of input_ids\n",
        "input_ids, input_ids.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qjXlmo6pIHz"
      },
      "source": [
        "# Check attention_mask and shape of attention_mask\n",
        "attention_mask, attention_mask.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWp_INOFpIHz"
      },
      "source": [
        "attention_mask[1], attention_mask[1].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx-IHm7MpIH0"
      },
      "source": [
        "# Save input_ids and attention_mask\n",
        "with open('movie-xids.npy', 'wb') as f:\n",
        "    np.save(f, input_ids)\n",
        "with open('movie-xmask.npy', 'wb') as f:\n",
        "    np.save(f, attention_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qGrWIHZpIH0"
      },
      "source": [
        "## One-hot-encode labels    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdF1uxgvpIH0"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "labels_one_hot = one_hot_encoder.fit_transform(df[\"point\"].to_numpy().reshape(-1,1))\n",
        "labels_one_hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHb1P62zpIH1"
      },
      "source": [
        "# Save the labels\n",
        "with open(\"movie-labels.npy\", \"wb\") as f:\n",
        "    np.save(f, labels_one_hot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4_pjg32skbI"
      },
      "source": [
        "##Course"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBWzn-XrtRPv"
      },
      "source": [
        "df.to_csv(\"use_this.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NNCSMFfsjrq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ktrain\n",
        "from ktrain import text\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yKlTo56rsjop",
        "outputId": "16616d02-a2d6-4243-f66b-147c6d5617c5"
      },
      "source": [
        "df = pd.read_csv(\"use_this.csv\")\n",
        "df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>point</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jean reno deni zaten leon film gelir akl izlem...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ekşı falan izlemek istiyor bun izlemey dost ke...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yap hakk öyl yazabilir kitap olur yüz kıs kesm...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>finali yeter sting shape of my heart bazı film...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jean reno ada kusurs oyunculug müthiş film baş...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  point\n",
              "0  jean reno deni zaten leon film gelir akl izlem...      5\n",
              "1  ekşı falan izlemek istiyor bun izlemey dost ke...      5\n",
              "2  yap hakk öyl yazabilir kitap olur yüz kıs kesm...      5\n",
              "3  finali yeter sting shape of my heart bazı film...      5\n",
              "4  jean reno ada kusurs oyunculug müthiş film baş...      5"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEIlQcoUt1A0",
        "outputId": "dedde396-43b4-4756-e22b-b050138aff05"
      },
      "source": [
        "df = df.dropna()\n",
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 82566 entries, 0 to 83226\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   comment  82566 non-null  object\n",
            " 1   point    82566 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 1.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjcM7fhysjlx",
        "outputId": "7ffe5fb2-06fa-43f4-fe32-3d2243595765"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(82566, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TNaI-dywzLh",
        "outputId": "c8aceb54-bf4a-4ddc-b865-49920e85fcfe"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2)\n",
        "\n",
        "train_df.shape, test_df.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((66052, 2), (16514, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "-DmDRjawsjil",
        "outputId": "97ec3f76-2660-4fc7-82fb-8a2e55b8a34b"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test), preproc = text.texts_from_df(train_df = train_df,\n",
        "                                                                   text_column=\"comment\",\n",
        "                                                                   label_columns=\"point\",\n",
        "                                                                   val_df=test_df,\n",
        "                                                                   maxlen=160,\n",
        "                                                                   preprocess_mode=\"bert\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['point_0', 'point_1', 'point_2', 'point_3', 'point_4', 'point_5']\n",
            "       point_0  point_1  point_2  point_3  point_4  point_5\n",
            "16083      0.0      0.0      0.0      0.0      1.0      0.0\n",
            "10844      0.0      0.0      0.0      0.0      0.0      1.0\n",
            "72955      0.0      0.0      0.0      0.0      1.0      0.0\n",
            "30245      0.0      0.0      1.0      0.0      0.0      0.0\n",
            "51977      0.0      0.0      0.0      1.0      0.0      0.0\n",
            "['point_0', 'point_1', 'point_2', 'point_3', 'point_4', 'point_5']\n",
            "       point_0  point_1  point_2  point_3  point_4  point_5\n",
            "23075      0.0      0.0      1.0      0.0      0.0      0.0\n",
            "2533       0.0      0.0      0.0      0.0      1.0      0.0\n",
            "53699      0.0      0.0      1.0      0.0      0.0      0.0\n",
            "5966       0.0      0.0      0.0      0.0      1.0      0.0\n",
            "69758      0.0      0.0      1.0      0.0      0.0      0.0\n",
            "preprocessing train...\n",
            "language: tr\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: tr\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3cqhjAtsjf_",
        "outputId": "d774a027-4920-4d99-d816-fb1ef850b4d1"
      },
      "source": [
        "model = text.text_classifier(name=\"bert\",\n",
        "                             train_data = (X_train, y_train),\n",
        "                             preproc=preproc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 160\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWOby2oSsjcl"
      },
      "source": [
        "learner = ktrain.get_learner(model=model,\n",
        "                   train_data=(X_train, y_train),\n",
        "                   val_data=(X_test, y_test),\n",
        "                   batch_size=16)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KFZ6d_T83qQ",
        "outputId": "8fea8e26-6172-42bb-d01d-6241b8742021"
      },
      "source": [
        "learner.fit_onecycle(lr=2e-5, epochs=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "4129/4129 [==============================] - 4991s 1s/step - loss: 1.2879 - accuracy: 0.4948 - val_loss: 1.1723 - val_accuracy: 0.5361\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdbd00783d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}