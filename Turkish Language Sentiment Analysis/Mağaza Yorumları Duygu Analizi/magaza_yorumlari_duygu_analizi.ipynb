{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "magaza_yorumlari_duygu_analizi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4670ef70f26042a384ad8496cbef53e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_885e476f896b4edfa451dc2a5a774079",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3cb3fe7c18ad4a308c25bd62123424b2",
              "IPY_MODEL_a9e5a27d849f42c6807d042789617194",
              "IPY_MODEL_db406cd0b5d848d3bb8f9091e3d8078e"
            ]
          }
        },
        "885e476f896b4edfa451dc2a5a774079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3cb3fe7c18ad4a308c25bd62123424b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_db38324f7a4c42ec9ab34609aa8f5f25",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09d922c80157474682bc5415c3fdca88"
          }
        },
        "a9e5a27d849f42c6807d042789617194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_122115154c374368b8ee237395743b6e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 59,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 59,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32709176038c43f3862b84b82dac06d3"
          }
        },
        "db406cd0b5d848d3bb8f9091e3d8078e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_55b5e90b98864b978e4029151c8a57ec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 59.0/59.0 [00:00&lt;00:00, 1.27kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58449db57fe94ef4a4e91f281d94c69f"
          }
        },
        "db38324f7a4c42ec9ab34609aa8f5f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09d922c80157474682bc5415c3fdca88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "122115154c374368b8ee237395743b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32709176038c43f3862b84b82dac06d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55b5e90b98864b978e4029151c8a57ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58449db57fe94ef4a4e91f281d94c69f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ac12375835e46228ae4a1aac2bb1dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_90894ef3895b49f985427ce9ec8005de",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9170bf9383694664b72b9526688acc0b",
              "IPY_MODEL_558d301672604ea696171a5d913288fb",
              "IPY_MODEL_06deab6259234345b7fbed1fc00831a9"
            ]
          }
        },
        "90894ef3895b49f985427ce9ec8005de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9170bf9383694664b72b9526688acc0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a0951413be3b46338baf2e71292bb5f8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_47a84a68b2aa465ebe3e788d058d0f0d"
          }
        },
        "558d301672604ea696171a5d913288fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1460cad9d0894c94a6f0ab2cad7e751c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 386,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 386,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8429276cc5ba43229701f8e3fb625dab"
          }
        },
        "06deab6259234345b7fbed1fc00831a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_38a7eda172c944f289206ae896127e78",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 386/386 [00:00&lt;00:00, 7.73kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b8f1ecf74db4da9bbabf0cf399ac360"
          }
        },
        "a0951413be3b46338baf2e71292bb5f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "47a84a68b2aa465ebe3e788d058d0f0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1460cad9d0894c94a6f0ab2cad7e751c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8429276cc5ba43229701f8e3fb625dab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38a7eda172c944f289206ae896127e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b8f1ecf74db4da9bbabf0cf399ac360": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0525a28862b45efb4bc51d1d287049a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9c0d445cce974d2984a1e31634790900",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_81f9e048f6594f88a929b2ad7597cc1f",
              "IPY_MODEL_022ae1c37889402690bfaee8d370ca19",
              "IPY_MODEL_9a2d0b40858b41c4a0543288c665e74b"
            ]
          }
        },
        "9c0d445cce974d2984a1e31634790900": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81f9e048f6594f88a929b2ad7597cc1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f1a23a73371d4380844cecd99218aa66",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b7446e3bbae41678e3643388e5b107d"
          }
        },
        "022ae1c37889402690bfaee8d370ca19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2415ebf4f6b444de980bd010842ca1e2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1233088,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1233088,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_759606cc132d4a5c95d18ec7281e81fa"
          }
        },
        "9a2d0b40858b41c4a0543288c665e74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_70dae3739dd2474eaaf2aeccf6983f2c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.18M/1.18M [00:00&lt;00:00, 1.24MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7187d7b450c74c48ba7509c8d76ff4ba"
          }
        },
        "f1a23a73371d4380844cecd99218aa66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b7446e3bbae41678e3643388e5b107d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2415ebf4f6b444de980bd010842ca1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "759606cc132d4a5c95d18ec7281e81fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70dae3739dd2474eaaf2aeccf6983f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7187d7b450c74c48ba7509c8d76ff4ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6bb4bc3d84cf4c828abf0bb6feae4ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0223f337e3a543beaf73f97ee101386d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ae97031bf90c43b48f3ebc9f21b25e43",
              "IPY_MODEL_c71ec55a65d94b028411a2ef25dc3a08",
              "IPY_MODEL_d80ce956a9f14d448424451502512488"
            ]
          }
        },
        "0223f337e3a543beaf73f97ee101386d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae97031bf90c43b48f3ebc9f21b25e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_57bbec1435474e84b85a2c64a5f48c73",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2ee2f2ce0424ea1a85c88d2359d9696"
          }
        },
        "c71ec55a65d94b028411a2ef25dc3a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_68ca6970b3294a5a9debd8ec67d48c1b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1135358592,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1135358592,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff0a743d2abc418b9239c094659ff53f"
          }
        },
        "d80ce956a9f14d448424451502512488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1d0f1ee10e02405e967af4865cddb559",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.06G/1.06G [00:47&lt;00:00, 8.05MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd529eeeceb44fc08cf9dc25bb35c22d"
          }
        },
        "57bbec1435474e84b85a2c64a5f48c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2ee2f2ce0424ea1a85c88d2359d9696": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68ca6970b3294a5a9debd8ec67d48c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff0a743d2abc418b9239c094659ff53f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d0f1ee10e02405e967af4865cddb559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd529eeeceb44fc08cf9dc25bb35c22d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWAM-m35Xoer"
      },
      "source": [
        "Data: https://www.kaggle.com/mustfkeskin/turkish-movie-sentiment-analysis-dataset/code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1mt-K5Ahn_y",
        "outputId": "45c3f5b3-5491-4869-ebae-da91693ab7df"
      },
      "source": [
        "# Check the GPU colab gave to us.\n",
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-aaffa2a1-f876-6201-5001-4ba083f68319)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1VwWbL43Pwh"
      },
      "source": [
        "### Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XV_OgZRK7tT0",
        "outputId": "aa9ab525-6dc4-4f8f-f572-a00f2783a393"
      },
      "source": [
        "# Get data\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"magaza_yorumlari_duygu_analizi.csv\", encoding=\"utf-16\")\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Görüş</th>\n",
              "      <th>Durum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ses kalitesi ve ergonomisi rezalet, sony olduğ...</td>\n",
              "      <td>Olumsuz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hizli teslimat tesekkürler</td>\n",
              "      <td>Tarafsız</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ses olayı süper....gece çalıştır sıkıntı yok.....</td>\n",
              "      <td>Olumlu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>geldi bigün kullandık hemen bozoldu hiçtavsiye...</td>\n",
              "      <td>Olumsuz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kulaklığın sesi kaliteli falan değil. Aleti öv...</td>\n",
              "      <td>Olumsuz</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Görüş     Durum\n",
              "0  ses kalitesi ve ergonomisi rezalet, sony olduğ...   Olumsuz\n",
              "1                         hizli teslimat tesekkürler  Tarafsız\n",
              "2  ses olayı süper....gece çalıştır sıkıntı yok.....    Olumlu\n",
              "3  geldi bigün kullandık hemen bozoldu hiçtavsiye...   Olumsuz\n",
              "4  Kulaklığın sesi kaliteli falan değil. Aleti öv...   Olumsuz"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqG7iax5hn_4",
        "outputId": "dc7a994d-7e5b-4255-9082-2f419fe24911"
      },
      "source": [
        "# Check the DataFrame to see the number of lines and non-null objects\n",
        "df.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11429 entries, 0 to 11428\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Görüş   11426 non-null  object\n",
            " 1   Durum   11429 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 178.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2fHlfir3Pwl",
        "outputId": "89454153-5a9b-4218-b007-f3188503c5ca"
      },
      "source": [
        "# Check value counts to see whether the data is balanced or not\n",
        "df.Durum.value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Olumlu      4253\n",
              "Olumsuz     4238\n",
              "Tarafsız    2938\n",
              "Name: Durum, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzcdGXAsiIQX",
        "outputId": "ba6b4435-b494-4503-ce23-ab0f434da890"
      },
      "source": [
        "# Since some nulls might be seen as a float, drop na to not face any problems.\n",
        "df.dropna(inplace=True)\n",
        "df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 11426 entries, 0 to 11428\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Görüş   11426 non-null  object\n",
            " 1   Durum   11426 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 267.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iKKReIECiMyw",
        "outputId": "3d687472-94b4-429f-9bda-ba7d0835817d"
      },
      "source": [
        "# Check the first line in df.Görüş\n",
        "df.Görüş[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"ses kalitesi ve ergonomisi rezalet, sony olduğu için aldım ama 4'de 1 fiyatına çin replika ürün alsaydım çok çok daha iyiydi, kesinlikle tavsiye etmiyorum.\""
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9icG6wCiOhvW",
        "outputId": "f7db9266-b3ed-4996-b2f8-940282c8bfe1"
      },
      "source": [
        "# Remove punctuation for our model to learn better\n",
        "df['Görüş'] = df['Görüş'].str.replace(r'[^\\w\\s]+', '')\n",
        "df.Görüş[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ses kalitesi ve ergonomisi rezalet sony olduğu için aldım ama 4de 1 fiyatına çin replika ürün alsaydım çok çok daha iyiydi kesinlikle tavsiye etmiyorum'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2S1vGEachn_7",
        "outputId": "65decec5-125e-4ddb-f4b1-409b1bdccb74"
      },
      "source": [
        "# Lower the inputs for our model to learn better\n",
        "df[\"Görüş\"] = df[\"Görüş\"].str.lower()\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Görüş</th>\n",
              "      <th>Durum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ses kalitesi ve ergonomisi rezalet sony olduğu...</td>\n",
              "      <td>Olumsuz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hizli teslimat tesekkürler</td>\n",
              "      <td>Tarafsız</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ses olayı süpergece çalıştır sıkıntı yokkablo ...</td>\n",
              "      <td>Olumlu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>geldi bigün kullandık hemen bozoldu hiçtavsiye...</td>\n",
              "      <td>Olumsuz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>kulaklığın sesi kaliteli falan değil aleti öve...</td>\n",
              "      <td>Olumsuz</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Görüş     Durum\n",
              "0  ses kalitesi ve ergonomisi rezalet sony olduğu...   Olumsuz\n",
              "1                         hizli teslimat tesekkürler  Tarafsız\n",
              "2  ses olayı süpergece çalıştır sıkıntı yokkablo ...    Olumlu\n",
              "3  geldi bigün kullandık hemen bozoldu hiçtavsiye...   Olumsuz\n",
              "4  kulaklığın sesi kaliteli falan değil aleti öve...   Olumsuz"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFl75kfdHK_L"
      },
      "source": [
        "# Import the nltk library and download stopwords\n",
        "#import nltk\n",
        "\n",
        "#nltk.download(\"stopwords\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9FMp5AfHK2a"
      },
      "source": [
        "# Get the stopwords\n",
        "#from nltk.corpus import stopwords\n",
        "#\n",
        "#stop_words = stopwords.words(\"turkish\")\n",
        "#stop_words[:10]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnmHDrDDHK0E"
      },
      "source": [
        "# Remove stopwords from each line and check the lines\n",
        "#stop_words = set(stop_words)\n",
        "#df['Görüş'] = df['Görüş'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
        "#\n",
        "#df.Görüş[0]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiZSi75iJ0tb"
      },
      "source": [
        "# Import the library and get the stemmer for Turkish Language\n",
        "#from TurkishStemmer import TurkishStemmer\n",
        "#\n",
        "#stemmer = TurkishStemmer()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHfTMHtRhn_-"
      },
      "source": [
        "# To use stemmer on each word, turn each line into a list\n",
        "#df['Görüş'] = df['Görüş'].str.split()\n",
        "#df.head()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJikCDNehn_-"
      },
      "source": [
        "# Apply stemmer\n",
        "#df['Görüş'] = df['Görüş'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
        "#\n",
        "#df.head()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdGGI9shhn_-"
      },
      "source": [
        "#df.Görüş[0]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh4uP4FiMZlq"
      },
      "source": [
        "# Turn each line back to a string (from list)\n",
        "#df['Görüş'] = df['Görüş'].apply(lambda x: ' '.join(word for word in x))\n",
        "#\n",
        "#df.head()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YOhGxXOOhn__",
        "outputId": "d9c3966a-4c3e-4119-d45f-6b17a5b85c21"
      },
      "source": [
        "# Get train sentences from df.Görüş\n",
        "train_sentences = df[\"Görüş\"].tolist()\n",
        "\n",
        "train_sentences[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ses kalitesi ve ergonomisi rezalet sony olduğu için aldım ama 4de 1 fiyatına çin replika ürün alsaydım çok çok daha iyiydi kesinlikle tavsiye etmiyorum'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qyLG-0JhoAA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "25910313-b5c8-4e35-c775-ff75095125d1"
      },
      "source": [
        "# Shuffle the data so our model can learn in a proper way\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "df = shuffle(df)\n",
        "df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Görüş</th>\n",
              "      <th>Durum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>818</th>\n",
              "      <td>ben aldigima pismanim fan yeri cok isiniyor ve...</td>\n",
              "      <td>Olumsuz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3473</th>\n",
              "      <td>beğendim güzel</td>\n",
              "      <td>Olumlu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8322</th>\n",
              "      <td>kendi evime almıştım git gel annem makineyi be...</td>\n",
              "      <td>Olumlu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3962</th>\n",
              "      <td>leş arkadaşlar leş ssd aldık biraz hızlansın d...</td>\n",
              "      <td>Olumsuz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10751</th>\n",
              "      <td>fiyat kalite iyi</td>\n",
              "      <td>Tarafsız</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Görüş     Durum\n",
              "818    ben aldigima pismanim fan yeri cok isiniyor ve...   Olumsuz\n",
              "3473                                     beğendim güzel     Olumlu\n",
              "8322   kendi evime almıştım git gel annem makineyi be...    Olumlu\n",
              "3962   leş arkadaşlar leş ssd aldık biraz hızlansın d...   Olumsuz\n",
              "10751                                   fiyat kalite iyi  Tarafsız"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B00Rhz5QhoAA",
        "outputId": "f5b08898-0d31-4b91-a66b-164129846882"
      },
      "source": [
        "# Check the DataFrame for one last time\n",
        "df.info()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 11426 entries, 818 to 10899\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Görüş   11426 non-null  object\n",
            " 1   Durum   11426 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 267.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF_lcz7W6UfB"
      },
      "source": [
        "### Input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGIK7G8FhoAA",
        "outputId": "614f971a-f048-408e-acdb-40925523c6a8"
      },
      "source": [
        "# Get the average and the max length of the inputs\n",
        "import numpy as np\n",
        "\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "max_sent_len = np.max(sent_lens)\n",
        "avg_sent_len, max_sent_len"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21.72378785226676, 422)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWQtwElghoAA",
        "outputId": "843e996b-dceb-4146-c015-8fa4615bf1fd"
      },
      "source": [
        "# How long of a sentence lenght covers 95% of examples?\n",
        "output_seq_len_95 = int(np.percentile(sent_lens, 95))\n",
        "\n",
        "output_seq_len_95"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PQ19VcfjOdL",
        "outputId": "224c7690-7299-4ddb-9b42-f842dbc3fe63"
      },
      "source": [
        "# How long of a sentence lenght covers 99% of examples?\n",
        "output_seq_len_99 = int(np.percentile(sent_lens, 99))\n",
        "\n",
        "output_seq_len_99"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1ssprrMhoAB"
      },
      "source": [
        "# Since it is not a large number, 120 is chosen. The GPU that we're using can handle this\n",
        "output_seq_len = 120"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9pkPIYw7C8e",
        "outputId": "0c5c44fe-6de9-4b26-fba2-6b30d409d530"
      },
      "source": [
        "# Get transformers\n",
        "!pip install transformers"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 38.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 457 kB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 41.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 40.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IGlN6Z5hoAB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "4670ef70f26042a384ad8496cbef53e0",
            "885e476f896b4edfa451dc2a5a774079",
            "3cb3fe7c18ad4a308c25bd62123424b2",
            "a9e5a27d849f42c6807d042789617194",
            "db406cd0b5d848d3bb8f9091e3d8078e",
            "db38324f7a4c42ec9ab34609aa8f5f25",
            "09d922c80157474682bc5415c3fdca88",
            "122115154c374368b8ee237395743b6e",
            "32709176038c43f3862b84b82dac06d3",
            "55b5e90b98864b978e4029151c8a57ec",
            "58449db57fe94ef4a4e91f281d94c69f",
            "8ac12375835e46228ae4a1aac2bb1dda",
            "90894ef3895b49f985427ce9ec8005de",
            "9170bf9383694664b72b9526688acc0b",
            "558d301672604ea696171a5d913288fb",
            "06deab6259234345b7fbed1fc00831a9",
            "a0951413be3b46338baf2e71292bb5f8",
            "47a84a68b2aa465ebe3e788d058d0f0d",
            "1460cad9d0894c94a6f0ab2cad7e751c",
            "8429276cc5ba43229701f8e3fb625dab",
            "38a7eda172c944f289206ae896127e78",
            "6b8f1ecf74db4da9bbabf0cf399ac360",
            "c0525a28862b45efb4bc51d1d287049a",
            "9c0d445cce974d2984a1e31634790900",
            "81f9e048f6594f88a929b2ad7597cc1f",
            "022ae1c37889402690bfaee8d370ca19",
            "9a2d0b40858b41c4a0543288c665e74b",
            "f1a23a73371d4380844cecd99218aa66",
            "4b7446e3bbae41678e3643388e5b107d",
            "2415ebf4f6b444de980bd010842ca1e2",
            "759606cc132d4a5c95d18ec7281e81fa",
            "70dae3739dd2474eaaf2aeccf6983f2c",
            "7187d7b450c74c48ba7509c8d76ff4ba"
          ]
        },
        "outputId": "09e3d692-7845-46d5-9be3-a19e797ae2f5"
      },
      "source": [
        "# Import AutoTokenizer\n",
        "from transformers import AutoTokenizer\n",
        "# Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-128k-uncased\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4670ef70f26042a384ad8496cbef53e0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ac12375835e46228ae4a1aac2bb1dda",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/386 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0525a28862b45efb4bc51d1d287049a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.18M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2V5ILnRhoAD",
        "outputId": "f776ab40-085e-48ec-a41d-e829727c35aa"
      },
      "source": [
        "# Encode inputs\n",
        "import tensorflow as tf\n",
        "\n",
        "input_ids = []\n",
        "attention_mask = []\n",
        "\n",
        "for txt in df.Görüş.values:\n",
        "    encoded = tokenizer.encode_plus(\n",
        "        text=txt, # the sentence to be encoded \n",
        "        add_special_tokens=True, # Add [CLS] and [SEP]\n",
        "        max_length=output_seq_len, # max length of a sentence\n",
        "        truncation=True, # truncate if sentence length is bigger than max_length\n",
        "        pad_to_max_length=True, # Add [PAD]s\n",
        "        return_attention_mask=True, # Generate attention mask\n",
        "        return_tensors=\"tf\" # return TensorFlow tensors\n",
        "    )\n",
        "\n",
        "    # Append input_ids and attention_masks to their own lists\n",
        "    input_ids.append(encoded[\"input_ids\"])\n",
        "    attention_mask.append(encoded[\"attention_mask\"])\n",
        "\n",
        "# Concatenate\n",
        "input_ids = tf.concat(input_ids, 0)\n",
        "attention_mask = tf.concat(attention_mask, 0)\n",
        "\n",
        "print(\"Original: \", df.Görüş.values[0])\n",
        "print(\"Token IDs: \", input_ids[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  ben aldigima pismanim fan yeri cok isiniyor ve cok ses cikartiyor\n",
            "alali 4 ay oluyor 10 kere kullanmamisimdiryinede ekran kapaniyor ve simsiyah oluyor\n",
            "Token IDs:  tf.Tensor(\n",
            "[     2   2105  95487   1007 108756   1950   7085   4673   6110  97496\n",
            "   2012   1946   6110   3072 100210   2019   3110   1987     24   2054\n",
            "   3419   2562   6143  47020  23208   2025  34088   2302   4587   6331\n",
            "   2019   1946  57157   3419      3      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0], shape=(120,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Glifs9muhoAD",
        "outputId": "c25c2848-8b09-49c4-c7d1-c0023bf7799f"
      },
      "source": [
        "# Convert tokens to ids to check if the encoding operation is done correctly\n",
        "tokenizer.convert_ids_to_tokens(input_ids[0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'ben',\n",
              " 'aldigim',\n",
              " '##a',\n",
              " 'pisman',\n",
              " '##im',\n",
              " 'fan',\n",
              " 'yeri',\n",
              " 'cok',\n",
              " 'isini',\n",
              " '##yor',\n",
              " 've',\n",
              " 'cok',\n",
              " 'ses',\n",
              " 'cikart',\n",
              " '##iyor',\n",
              " 'ala',\n",
              " '##li',\n",
              " '4',\n",
              " 'ay',\n",
              " 'oluyor',\n",
              " '10',\n",
              " 'kere',\n",
              " 'kullanmam',\n",
              " '##isim',\n",
              " '##dir',\n",
              " '##yin',\n",
              " '##ede',\n",
              " 'ekran',\n",
              " 'kapan',\n",
              " '##iyor',\n",
              " 've',\n",
              " 'simsiyah',\n",
              " 'oluyor',\n",
              " '[SEP]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiKh0E1vhoAD",
        "outputId": "5bc0c1bd-1b6a-4076-b162-42dd4d3c6ef0"
      },
      "source": [
        "# Check input_ids and shape of input_ids\n",
        "input_ids, input_ids.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(11426, 120), dtype=int32, numpy=\n",
              " array([[    2,  2105, 95487, ...,     0,     0,     0],\n",
              "        [    2, 86096, 14368, ...,     0,     0,     0],\n",
              "        [    2,  2676, 21705, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [    2,  6920, 30422, ...,     0,     0,     0],\n",
              "        [    2,  5303, 13286, ...,     0,     0,     0],\n",
              "        [    2, 36664,  2327, ...,     0,     0,     0]], dtype=int32)>,\n",
              " TensorShape([11426, 120]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH94giL4hoAE",
        "outputId": "5fa55ac8-f448-43a3-a8fc-88573ee4a437"
      },
      "source": [
        "# Check attention_mask and shape of attention_mask\n",
        "attention_mask, attention_mask.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(11426, 120), dtype=int32, numpy=\n",
              " array([[1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>, TensorShape([11426, 120]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SadHbXR2iXRv",
        "outputId": "79072e1a-9b9c-414d-9594-2a6499261c00"
      },
      "source": [
        "# Seperate test df from original df\n",
        "test_df = df.iloc[:1100]\n",
        "df = df.iloc[1100:]\n",
        "len(df), len(test_df)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10326, 1100)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X6-aj9wigJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37ed02bb-5e2c-49fe-b179-a45895c99ce5"
      },
      "source": [
        "# Seperate test input ids and test attention mask from the original ones\n",
        "test_input_ids = input_ids[:1100]\n",
        "test_attention_mask = attention_mask[:1100]\n",
        "\n",
        "input_ids = input_ids[1100:]\n",
        "attention_mask = attention_mask[1100:]\n",
        "\n",
        "input_ids.shape, test_input_ids.shape, attention_mask.shape, test_attention_mask.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([10326, 120]),\n",
              " TensorShape([1100, 120]),\n",
              " TensorShape([10326, 120]),\n",
              " TensorShape([1100, 120]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHOfBbPlhoAE",
        "outputId": "ba262416-68a1-4080-d1c6-6af6f7d1aa1c"
      },
      "source": [
        "# One hot encode our labels to use in our models\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "labels_one_hot = one_hot_encoder.fit_transform(df[\"Durum\"].to_numpy().reshape(-1,1))\n",
        "labels_one_hot.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10326, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T5AS1U7lC8O",
        "outputId": "a88c53dc-a940-48ab-c26e-5b7c8cdd0df6"
      },
      "source": [
        "# One hot encode test labels\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "test_labels_one_hot = one_hot_encoder.fit_transform(test_df[\"Durum\"].to_numpy().reshape(-1,1))\n",
        "test_labels_one_hot.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1100, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-iVJ_eMitH7",
        "outputId": "14163c3c-2f44-45f7-b3aa-7f108613d36f"
      },
      "source": [
        "# Label encode test labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "test_labels_encoded = label_encoder.fit_transform(test_df[\"Durum\"].to_numpy())\n",
        "\n",
        "test_labels_encoded"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIKTKY3qVO0s",
        "outputId": "ed19ab4d-2a88-4845-9e76-2086fe498ca3"
      },
      "source": [
        "# Create a TensorFlow Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_mask, labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_input_ids, test_attention_mask, test_labels_one_hot))\n",
        "dataset, test_dataset"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<TensorSliceDataset shapes: ((120,), (120,), (3,)), types: (tf.int32, tf.int32, tf.float64)>,\n",
              " <TensorSliceDataset shapes: ((120,), (120,), (3,)), types: (tf.int32, tf.int32, tf.float64)>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBAAlyR2VP_6"
      },
      "source": [
        "# Create a function to map our dataset\n",
        "def map_func(input_ids, masks, labels):\n",
        "    # We convert our three-item tuple into a two-item tuple where the input item is a dictionary\n",
        "    return {\"input_ids\": input_ids,\n",
        "            \"attention_mask\": masks}, labels"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y7qmFLgVP9n",
        "outputId": "e78fc9a2-7aab-437d-e581-e0534e4284da"
      },
      "source": [
        "# Map the dataset using the function we created and check the dataset\n",
        "dataset = dataset.map(map_func)\n",
        "test_dataset = test_dataset.map(map_func)\n",
        "dataset, test_dataset"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<MapDataset shapes: ({input_ids: (120,), attention_mask: (120,)}, (3,)), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.float64)>,\n",
              " <MapDataset shapes: ({input_ids: (120,), attention_mask: (120,)}, (3,)), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.float64)>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sap4Qj6z8nYq"
      },
      "source": [
        "# Get the length of our dataset\n",
        "len_dataset_unbatched = len(dataset)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90lz2XbdVP4Z",
        "outputId": "214f34a9-47d8-48b0-ecf4-a8d5db0250c8"
      },
      "source": [
        "# Batch our dataset and drop remainders\n",
        "batch_size=32\n",
        "dataset = dataset.batch(batch_size) #.shuffle(10000) , drop_remainder=True\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "\n",
        "dataset.take, test_dataset"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<bound method DatasetV2.take of <BatchDataset shapes: ({input_ids: (None, 120), attention_mask: (None, 120)}, (None, 3)), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.float64)>>,\n",
              " <BatchDataset shapes: ({input_ids: (None, 120), attention_mask: (None, 120)}, (None, 3)), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.float64)>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV-l87svVSfP",
        "outputId": "c1997598-6bd1-4f1e-8bb8-d1be20d37b48"
      },
      "source": [
        "# Split our dataset into train, validation and test datasets\n",
        "split = 0.85\n",
        "size = int((input_ids.shape[0] / batch_size) * split)\n",
        "\n",
        "train_ds = dataset.take(size) # 85% of the dataset\n",
        "val_ds = dataset.skip(size) # 15% of the dataset\n",
        "\n",
        "len(dataset), len(train_ds), len(val_ds)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(323, 274, 49)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWKJvxCY2aq6"
      },
      "source": [
        "## Build and train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "6bb4bc3d84cf4c828abf0bb6feae4ac3",
            "0223f337e3a543beaf73f97ee101386d",
            "ae97031bf90c43b48f3ebc9f21b25e43",
            "c71ec55a65d94b028411a2ef25dc3a08",
            "d80ce956a9f14d448424451502512488",
            "57bbec1435474e84b85a2c64a5f48c73",
            "e2ee2f2ce0424ea1a85c88d2359d9696",
            "68ca6970b3294a5a9debd8ec67d48c1b",
            "ff0a743d2abc418b9239c094659ff53f",
            "1d0f1ee10e02405e967af4865cddb559",
            "fd529eeeceb44fc08cf9dc25bb35c22d"
          ]
        },
        "id": "Ov5QgOsEVSc3",
        "outputId": "67688fc3-0b7a-4361-c1d2-de89154a44bc"
      },
      "source": [
        "# Import the model\n",
        "from transformers import TFAutoModel\n",
        "\n",
        "bert128k = TFAutoModel.from_pretrained(\"dbmdz/bert-base-turkish-128k-uncased\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bb4bc3d84cf4c828abf0bb6feae4ac3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.06G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84ENq3wQVSaV"
      },
      "source": [
        "# Create the model\n",
        "import tensorflow as tf\n",
        "\n",
        "# two input layers, we ensure layer name variables match to dictionary keys in TF dataset\n",
        "input_ids = tf.keras.layers.Input(shape=(120,), name='input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(120,), name='attention_mask', dtype='int32')\n",
        "\n",
        "# we access the transformer model within our bert object using the bert attribute (eg bert.bert instead of bert)\n",
        "embeddings = bert128k.bert(input_ids, attention_mask=mask)[1]  # access final activations (already max-pooled) [1]\n",
        "# convert bert embeddings into 3 output classes\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(embeddings)\n",
        "outputs = tf.keras.layers.Dense(3, activation='softmax', name='outputs')(x)\n",
        "\n",
        "# model\n",
        "model_1_128k_uncased = tf.keras.Model(inputs=[input_ids, mask], outputs=outputs)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef65gdxpVYd9",
        "outputId": "1d883f3d-eff9-4c56-e943-8710a7eb5ff3"
      },
      "source": [
        "#Get the summary of model_1_128k_uncased\n",
        "model_1_128k_uncased.summary()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 120)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 120)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  184345344   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 120,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1024)         787456      ['bert[0][1]']                   \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 3)            3075        ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 185,135,875\n",
            "Trainable params: 185,135,875\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Br5uE2VP66"
      },
      "source": [
        "# Get learning rate using PolynomialDecay\n",
        "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
        "\n",
        "x = len_dataset_unbatched*0.85 # length of train_ds (unbatched)\n",
        "\n",
        "num_epochs = 3\n",
        "num_train_steps = x * num_epochs\n",
        "lr_scheduler = PolynomialDecay(\n",
        "    initial_learning_rate=5e-5,\n",
        "    end_learning_rate=0.,\n",
        "    decay_steps=num_train_steps\n",
        ")"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evtW9s40VYbs"
      },
      "source": [
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
        "\n",
        "model_1_128k_uncased.compile(optimizer=optimizer, \n",
        "              loss=loss, \n",
        "              metrics=[acc])"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPHt0g7NVYWh",
        "outputId": "a3a37cb0-cf6f-4267-8ee6-f5b3b5668af5"
      },
      "source": [
        "# Fit the model\n",
        "history = model_1_128k_uncased.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=4,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "274/274 [==============================] - 629s 2s/step - loss: 0.7106 - accuracy: 0.6939 - val_loss: 0.6189 - val_accuracy: 0.7465\n",
            "Epoch 2/4\n",
            "274/274 [==============================] - 555s 2s/step - loss: 0.5305 - accuracy: 0.7862 - val_loss: 0.6290 - val_accuracy: 0.7503\n",
            "Epoch 3/4\n",
            "274/274 [==============================] - 556s 2s/step - loss: 0.4103 - accuracy: 0.8451 - val_loss: 0.7348 - val_accuracy: 0.7388\n",
            "Epoch 4/4\n",
            "274/274 [==============================] - 556s 2s/step - loss: 0.3117 - accuracy: 0.8846 - val_loss: 0.7774 - val_accuracy: 0.7279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBvY5NXlABjZ",
        "outputId": "e5f3d3e0-ce24-4884-eed7-f5ea1ee10774"
      },
      "source": [
        "# Evaluate the model on test_ds\n",
        "model_1_128k_uncased.evaluate(test_dataset)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 22s 619ms/step - loss: 0.8040 - accuracy: 0.7291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8040470480918884, 0.7290909290313721]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAsI12RjLx0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eea017a-20d2-4620-e040-b3dbdedcc214"
      },
      "source": [
        "# Download helper functions\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-07 01:03:00--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-07 01:03:00 (52.2 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1wc9G_pL2Jh"
      },
      "source": [
        "from helper_functions import calculate_results"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tnAgQNJK4p3",
        "outputId": "e55a21a9-7ddc-4399-ec5f-7e93f0eab5c7"
      },
      "source": [
        "# Make predictions\n",
        "model_1_128k_uncased_pred_probs = model_1_128k_uncased.predict(test_dataset)\n",
        "model_1_128k_uncased_pred_probs[0], model_1_128k_uncased_pred_probs.shape"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([6.2831619e-04, 9.7018200e-01, 2.9189603e-02], dtype=float32),\n",
              " (1100, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zov0MPMrLLMJ",
        "outputId": "b6e72c30-b1ba-454f-86ba-cc37b13523e0"
      },
      "source": [
        "# Convert pred_probs to classes\n",
        "model_1_128k_uncased_preds = tf.argmax(model_1_128k_uncased_pred_probs, axis=1)\n",
        "model_1_128k_uncased_preds"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1100,), dtype=int64, numpy=array([1, 0, 0, ..., 0, 1, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-AAlwpwul_A",
        "outputId": "8251849a-2574-498d-b7d4-63209a7f53d8"
      },
      "source": [
        "# Calculate model_1 results\n",
        "model_1_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                    y_pred=model_1_128k_uncased_preds)\n",
        "model_1_results"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.9090909090909,\n",
              " 'f1': 0.7316083809301425,\n",
              " 'precision': 0.7357624165776253,\n",
              " 'recall': 0.7290909090909091}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0ylC9ntcXkH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad31910-b2c8-4097-c71d-95c9f59e887a"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# two input layers, we ensure layer name variables match to dictionary keys in TF dataset\n",
        "input_ids = tf.keras.layers.Input(shape=(120,), name='input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(120,), name='attention_mask', dtype='int32')\n",
        "\n",
        "# we access the transformer model within our bert object using the bert attribute (eg bert.bert instead of bert)\n",
        "embeddings = bert128k.bert(input_ids, attention_mask=mask)[0]  # access final activations with [0]\n",
        "\n",
        "x = tf.keras.layers.LSTM(8, dropout=.4, recurrent_dropout=.4, return_sequences=False) (embeddings) \n",
        "# normalize\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "# output\n",
        "outputs = tf.keras.layers.Dense(3, activation='softmax', name='outputs')(x)\n",
        "\n",
        "model_2_128k_uncased_LSTM = tf.keras.Model(inputs=[input_ids, mask], outputs=outputs)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCpmjS5DcXhr",
        "outputId": "9abbc5fe-ec85-449a-b262-ff758dd45004"
      },
      "source": [
        "model_2_128k_uncased_LSTM.layers[2].trainable = False\n",
        "\n",
        "# print out model summary\n",
        "model_2_128k_uncased_LSTM.summary()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 120)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 120)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  184345344   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 120,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " lstm_7 (LSTM)                  (None, 8)            24864       ['bert[8][0]']                   \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 8)           32          ['lstm_7[0][0]']                 \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 3)            27          ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 184,370,267\n",
            "Trainable params: 24,907\n",
            "Non-trainable params: 184,345,360\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sICCVKWhcXe8"
      },
      "source": [
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5) #lr_scheduler\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
        "\n",
        "model_2_128k_uncased_LSTM.compile(optimizer=optimizer, \n",
        "              loss=loss, \n",
        "              metrics=[acc])"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy7NduZucXcO",
        "outputId": "ee0a6000-82a6-422a-cc4b-0297d2cb1273"
      },
      "source": [
        "# Fit the model\n",
        "history_model_2 = model_2_128k_uncased_LSTM.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=3,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "274/274 [==============================] - 418s 1s/step - loss: 0.6764 - accuracy: 0.7320 - val_loss: 0.6962 - val_accuracy: 0.7323\n",
            "Epoch 2/3\n",
            "274/274 [==============================] - 391s 1s/step - loss: 0.3631 - accuracy: 0.8743 - val_loss: 0.7447 - val_accuracy: 0.7490\n",
            "Epoch 3/3\n",
            "274/274 [==============================] - 388s 1s/step - loss: 0.3253 - accuracy: 0.8929 - val_loss: 0.7577 - val_accuracy: 0.7490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0JDHsLlkq48",
        "outputId": "6ef00e7a-f776-44cc-d133-48d731cf8ceb"
      },
      "source": [
        "# Make predictions\n",
        "model_2_128k_uncased_LSTM_pred_probs = model_2_128k_uncased_LSTM.predict(test_dataset)\n",
        "model_2_128k_uncased_LSTM_pred_probs[0], model_2_128k_uncased_LSTM_pred_probs.shape"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.9814563 , 0.00938745, 0.00915632], dtype=float32), (1100, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKdiNgilom4m",
        "outputId": "dd579153-7923-4443-c4a8-84ddabb6d857"
      },
      "source": [
        "# Convert pred_probs to classes\n",
        "model_2_128k_uncased_LSTM_preds = tf.argmax(model_2_128k_uncased_LSTM_pred_probs, axis=1)\n",
        "model_2_128k_uncased_LSTM_preds"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1100,), dtype=int64, numpy=array([0, 2, 0, ..., 0, 0, 0])>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk4bGJ7_om2l",
        "outputId": "24a57964-fcb8-491b-d01a-8cbd9b27bbb8"
      },
      "source": [
        "# Calculate model_2 results\n",
        "model_2_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                    y_pred=model_2_128k_uncased_LSTM_preds)\n",
        "model_2_results"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.72727272727273,\n",
              " 'f1': 0.7575059480348981,\n",
              " 'precision': 0.7581581375171819,\n",
              " 'recall': 0.7572727272727273}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOKuxPh7omz9"
      },
      "source": [
        "# two input layers, we ensure layer name variables match to dictionary keys in TF dataset\n",
        "input_ids = tf.keras.layers.Input(shape=(120,), name='input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(120,), name='attention_mask', dtype='int32')\n",
        "\n",
        "# we access the transformer model within our bert object using the bert attribute (eg bert.bert instead of bert)\n",
        "embeddings = bert128k.bert(input_ids, attention_mask=mask)[0]  # access final activations with [0]\n",
        "\n",
        "x = tf.keras.layers.GRU(16, return_sequences=False)(embeddings) \n",
        "# normalize\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "# output\n",
        "outputs = tf.keras.layers.Dense(3, activation='softmax', name='outputs')(x)\n",
        "\n",
        "model_3_128k_uncased_GRU = tf.keras.Model(inputs=[input_ids, mask], outputs=outputs)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDyRN2Ut5_hi",
        "outputId": "4a7ebe2e-a4f4-4e6b-89bd-0e523a61415b"
      },
      "source": [
        "model_3_128k_uncased_GRU.layers[2].trainable = False\n",
        "\n",
        "# print out model summary\n",
        "model_3_128k_uncased_GRU.summary()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 120)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 120)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  184345344   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 120,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " gru (GRU)                      (None, 16)           37728       ['bert[10][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16)          64          ['gru[0][0]']                    \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 3)            51          ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 184,383,187\n",
            "Trainable params: 37,811\n",
            "Non-trainable params: 184,345,376\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N99ZxqJ06FsW"
      },
      "source": [
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5) #lr_scheduler\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
        "\n",
        "model_3_128k_uncased_GRU.compile(optimizer=optimizer, \n",
        "              loss=loss, \n",
        "              metrics=[acc])"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5oKmrfc6LgB",
        "outputId": "d25b345d-633b-4729-e615-ecada005de50"
      },
      "source": [
        "# Fit the model\n",
        "history_model_3 = model_3_128k_uncased_GRU.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=3,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "274/274 [==============================] - 204s 675ms/step - loss: 0.6504 - accuracy: 0.7424 - val_loss: 0.7395 - val_accuracy: 0.7266\n",
            "Epoch 2/3\n",
            "274/274 [==============================] - 181s 660ms/step - loss: 0.3267 - accuracy: 0.8877 - val_loss: 0.7467 - val_accuracy: 0.7413\n",
            "Epoch 3/3\n",
            "274/274 [==============================] - 181s 660ms/step - loss: 0.2867 - accuracy: 0.9032 - val_loss: 0.7477 - val_accuracy: 0.7458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7n5h4Mr10bZW",
        "outputId": "b359c9f8-1fc5-4eb6-b8e5-fa5bcdccb8c7"
      },
      "source": [
        "# Make predictions\n",
        "model_3_128k_uncased_GRU_pred_probs = model_3_128k_uncased_GRU.predict(test_dataset)\n",
        "model_3_128k_uncased_GRU_pred_probs[0], model_3_128k_uncased_GRU_pred_probs.shape"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.9847973 , 0.00456741, 0.01063525], dtype=float32), (1100, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCYYOG2G0bWv",
        "outputId": "510e5f96-3bb1-4b43-8c6a-230f939e9169"
      },
      "source": [
        "# Convert pred_probs to classes\n",
        "model_3_128k_uncased_GRU_preds = tf.argmax(model_3_128k_uncased_GRU_pred_probs, axis=1)\n",
        "model_3_128k_uncased_GRU_preds"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1100,), dtype=int64, numpy=array([0, 2, 0, ..., 0, 0, 0])>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckJTc_ih0yeF",
        "outputId": "8297bf34-e7a3-491b-be0c-791717bed9b4"
      },
      "source": [
        "# Calculate model_3 results\n",
        "model_3_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                    y_pred=model_3_128k_uncased_GRU_preds)\n",
        "model_3_results"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.0,\n",
              " 'f1': 0.7597449525691167,\n",
              " 'precision': 0.7599282353908192,\n",
              " 'recall': 0.76}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp4QNtuP9_CY"
      },
      "source": [
        "# two input layers, we ensure layer name variables match to dictionary keys in TF dataset\n",
        "input_ids = tf.keras.layers.Input(shape=(120,), name='input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(120,), name='attention_mask', dtype='int32')\n",
        "\n",
        "# we access the transformer model within our bert object using the bert attribute (eg bert.bert instead of bert)\n",
        "embeddings = bert128k.bert(input_ids, attention_mask=mask)[1]  # access final activations with [0]\n",
        "\n",
        "x = tf.keras.layers.Dense(16, activation=\"relu\")(embeddings)\n",
        "# output\n",
        "outputs = tf.keras.layers.Dense(3, activation='softmax', name='outputs')(x)\n",
        "\n",
        "model_4_dense = tf.keras.Model(inputs=[input_ids, mask], outputs=outputs)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q10Fgw629--S",
        "outputId": "67ae72f9-6ca2-4c44-d1a4-5155f58a1975"
      },
      "source": [
        "model_4_dense.layers[2].trainable = False\n",
        "\n",
        "# print out model summary\n",
        "model_4_dense.summary()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 120)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 120)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  184345344   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 120,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 16)           12304       ['bert[13][1]']                  \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 3)            51          ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 184,357,699\n",
            "Trainable params: 12,355\n",
            "Non-trainable params: 184,345,344\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqqo-9wy9-7z"
      },
      "source": [
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(lr_scheduler)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
        "\n",
        "model_4_dense.compile(optimizer=optimizer, \n",
        "              loss=loss, \n",
        "              metrics=[acc])"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WihHWD5n-ikK",
        "outputId": "6b8b4305-7d17-4de4-9dc5-78fb1c8ad1fc"
      },
      "source": [
        "# Fit the model\n",
        "history_model_4 = model_4_dense.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=3,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "274/274 [==============================] - 198s 661ms/step - loss: 0.3849 - accuracy: 0.8691 - val_loss: 0.7456 - val_accuracy: 0.7471\n",
            "Epoch 2/3\n",
            "274/274 [==============================] - 177s 647ms/step - loss: 0.2482 - accuracy: 0.9183 - val_loss: 0.7767 - val_accuracy: 0.7497\n",
            "Epoch 3/3\n",
            "274/274 [==============================] - 177s 648ms/step - loss: 0.2364 - accuracy: 0.9190 - val_loss: 0.7926 - val_accuracy: 0.7497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgB9xwKM-inG",
        "outputId": "96e1d593-cf7c-4dcb-b5bd-7e9a427bffaf"
      },
      "source": [
        "# Make predictions\n",
        "model_4_dense_pred_probs = model_4_dense.predict(test_dataset)\n",
        "model_4_dense_pred_probs[0], model_4_dense_pred_probs.shape"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.9831699 , 0.00322217, 0.01360795], dtype=float32), (1100, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZjDc1EZ-iqb",
        "outputId": "abb52b09-5fee-49b9-d699-b72aa52e49c7"
      },
      "source": [
        "# Convert pred_probs to classes\n",
        "model_4_dense_preds = tf.argmax(model_4_dense_pred_probs, axis=1)\n",
        "model_4_dense_preds"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1100,), dtype=int64, numpy=array([0, 2, 0, ..., 0, 0, 0])>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr0Z1opL-itf",
        "outputId": "329679db-a598-44b0-d614-99fafa420707"
      },
      "source": [
        "# Calculate model_3 results\n",
        "model_4_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                    y_pred=model_4_dense_preds)\n",
        "model_4_results"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.54545454545455,\n",
              " 'f1': 0.758077003516226,\n",
              " 'precision': 0.7617458890607534,\n",
              " 'recall': 0.7554545454545455}"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    }
  ]
}