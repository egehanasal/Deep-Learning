{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "magaza_yorumlari_duygu_analizi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWAM-m35Xoer"
      },
      "source": [
        "Data: https://www.kaggle.com/mustfkeskin/turkish-movie-sentiment-analysis-dataset/code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1mt-K5Ahn_y",
        "outputId": "ed9c3db5-c49a-4662-cbb0-a46148fb699b"
      },
      "source": [
        "# Check the GPU colab gave to us.\n",
        "!nvidia-smi -L"
      ],
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-cf47de9d-cec0-d1b1-d788-3b3a4288e3a7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1VwWbL43Pwh"
      },
      "source": [
        "### Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XV_OgZRK7tT0",
        "outputId": "3eba196f-4741-4a56-882f-08b7c92d0415"
      },
      "source": [
        "# Get data\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"magaza_yorumlari_duygu_analizi.csv\", encoding=\"utf-16\")\n",
        "df.head()"
      ],
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Görüş</th>\n",
              "      <th>Durum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ses kalitesi ve ergonomisi rezalet, sony olduğ...</td>\n",
              "      <td>Olumsuz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hizli teslimat tesekkürler</td>\n",
              "      <td>Tarafsız</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ses olayı süper....gece çalıştır sıkıntı yok.....</td>\n",
              "      <td>Olumlu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>geldi bigün kullandık hemen bozoldu hiçtavsiye...</td>\n",
              "      <td>Olumsuz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Kulaklığın sesi kaliteli falan değil. Aleti öv...</td>\n",
              "      <td>Olumsuz</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Görüş     Durum\n",
              "0  ses kalitesi ve ergonomisi rezalet, sony olduğ...   Olumsuz\n",
              "1                         hizli teslimat tesekkürler  Tarafsız\n",
              "2  ses olayı süper....gece çalıştır sıkıntı yok.....    Olumlu\n",
              "3  geldi bigün kullandık hemen bozoldu hiçtavsiye...   Olumsuz\n",
              "4  Kulaklığın sesi kaliteli falan değil. Aleti öv...   Olumsuz"
            ]
          },
          "metadata": {},
          "execution_count": 362
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqG7iax5hn_4",
        "outputId": "d9b23067-272b-48f1-a627-18eb65e8d997"
      },
      "source": [
        "# Check the DataFrame to see the number of lines and non-null objects\n",
        "df.info()"
      ],
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11429 entries, 0 to 11428\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Görüş   11426 non-null  object\n",
            " 1   Durum   11429 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 178.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2fHlfir3Pwl",
        "outputId": "1aa52b14-ca97-4100-f08e-f184779bfa35"
      },
      "source": [
        "# Check value counts to see whether the data is balanced or not\n",
        "df.Durum.value_counts()"
      ],
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Olumlu      4253\n",
              "Olumsuz     4238\n",
              "Tarafsız    2938\n",
              "Name: Durum, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 364
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzcdGXAsiIQX",
        "outputId": "f21a19aa-2c15-4e20-b1f6-56df54f4e8e3"
      },
      "source": [
        "# Since some nulls might be seen as a float, drop na to not face any problems.\n",
        "df.dropna(inplace=True)\n",
        "df.info()"
      ],
      "execution_count": 365,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 11426 entries, 0 to 11428\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Görüş   11426 non-null  object\n",
            " 1   Durum   11426 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 267.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iKKReIECiMyw",
        "outputId": "27fb0a51-9326-4d18-d12c-b400b46dd032"
      },
      "source": [
        "# Check the first line in df.Görüş\n",
        "df.Görüş[0]"
      ],
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"ses kalitesi ve ergonomisi rezalet, sony olduğu için aldım ama 4'de 1 fiyatına çin replika ürün alsaydım çok çok daha iyiydi, kesinlikle tavsiye etmiyorum.\""
            ]
          },
          "metadata": {},
          "execution_count": 366
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9icG6wCiOhvW",
        "outputId": "ca85cbb0-14e1-4033-81f7-529ec9e75bfa"
      },
      "source": [
        "# Remove punctuation for our model to learn better\n",
        "df['Görüş'] = df['Görüş'].str.replace(r'[^\\w\\s]+', '')\n",
        "df.Görüş[0]"
      ],
      "execution_count": 367,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ses kalitesi ve ergonomisi rezalet sony olduğu için aldım ama 4de 1 fiyatına çin replika ürün alsaydım çok çok daha iyiydi kesinlikle tavsiye etmiyorum'"
            ]
          },
          "metadata": {},
          "execution_count": 367
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2S1vGEachn_7",
        "outputId": "156b8ca0-0c56-40e5-d8af-7ba07af48a10"
      },
      "source": [
        "# Lower the inputs for our model to learn better\n",
        "df[\"Görüş\"] = df[\"Görüş\"].str.lower()\n",
        "df.head()"
      ],
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Görüş</th>\n",
              "      <th>Durum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ses kalitesi ve ergonomisi rezalet sony olduğu...</td>\n",
              "      <td>Olumsuz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hizli teslimat tesekkürler</td>\n",
              "      <td>Tarafsız</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ses olayı süpergece çalıştır sıkıntı yokkablo ...</td>\n",
              "      <td>Olumlu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>geldi bigün kullandık hemen bozoldu hiçtavsiye...</td>\n",
              "      <td>Olumsuz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>kulaklığın sesi kaliteli falan değil aleti öve...</td>\n",
              "      <td>Olumsuz</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Görüş     Durum\n",
              "0  ses kalitesi ve ergonomisi rezalet sony olduğu...   Olumsuz\n",
              "1                         hizli teslimat tesekkürler  Tarafsız\n",
              "2  ses olayı süpergece çalıştır sıkıntı yokkablo ...    Olumlu\n",
              "3  geldi bigün kullandık hemen bozoldu hiçtavsiye...   Olumsuz\n",
              "4  kulaklığın sesi kaliteli falan değil aleti öve...   Olumsuz"
            ]
          },
          "metadata": {},
          "execution_count": 368
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71lVDtp10QG6"
      },
      "source": [
        "--------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFl75kfdHK_L"
      },
      "source": [
        "# Import the nltk library and download stopwords\n",
        "#import nltk\n",
        "\n",
        "#nltk.download(\"stopwords\")"
      ],
      "execution_count": 369,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9FMp5AfHK2a"
      },
      "source": [
        "# Get the stopwords\n",
        "#from nltk.corpus import stopwords\n",
        "#\n",
        "#stop_words = stopwords.words(\"turkish\")\n",
        "#stop_words[:10]"
      ],
      "execution_count": 370,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnmHDrDDHK0E"
      },
      "source": [
        "# Remove stopwords from each line and check the lines\n",
        "#stop_words = set(stop_words)\n",
        "#df['Görüş'] = df['Görüş'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
        "#\n",
        "#df.Görüş[0]"
      ],
      "execution_count": 371,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lEHwPW_tl3Y"
      },
      "source": [
        "#!pip install TurkishStemmer"
      ],
      "execution_count": 372,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiZSi75iJ0tb"
      },
      "source": [
        "# Import the library and get the stemmer for Turkish Language\n",
        "#from TurkishStemmer import TurkishStemmer\n",
        "\n",
        "#stemmer = TurkishStemmer()"
      ],
      "execution_count": 373,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHfTMHtRhn_-"
      },
      "source": [
        "# To use stemmer on each word, turn each line into a list\n",
        "#df['Görüş'] = df['Görüş'].str.split()\n",
        "#df.head()"
      ],
      "execution_count": 374,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJikCDNehn_-"
      },
      "source": [
        "# Apply stemmer\n",
        "#df['Görüş'] = df['Görüş'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
        "\n",
        "#df.head()"
      ],
      "execution_count": 375,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdGGI9shhn_-"
      },
      "source": [
        "#df.Görüş[0]"
      ],
      "execution_count": 376,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh4uP4FiMZlq"
      },
      "source": [
        "# Turn each line back to a string (from list)\n",
        "#df['Görüş'] = df['Görüş'].apply(lambda x: ' '.join(word for word in x))\n",
        "\n",
        "#df.head()"
      ],
      "execution_count": 377,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMm3dBNt0Nym"
      },
      "source": [
        "-------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YOhGxXOOhn__",
        "outputId": "d5e1891f-35d3-49a3-98bc-10635438696e"
      },
      "source": [
        "# Get train sentences from df.Görüş\n",
        "train_sentences = df[\"Görüş\"].tolist()\n",
        "\n",
        "train_sentences[0]"
      ],
      "execution_count": 378,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ses kalitesi ve ergonomisi rezalet sony olduğu için aldım ama 4de 1 fiyatına çin replika ürün alsaydım çok çok daha iyiydi kesinlikle tavsiye etmiyorum'"
            ]
          },
          "metadata": {},
          "execution_count": 378
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qyLG-0JhoAA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3a683db3-8615-4111-82c2-44d33b42b41a"
      },
      "source": [
        "# Shuffle the data so our model can learn in a proper way\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "df = shuffle(df)\n",
        "df.head()"
      ],
      "execution_count": 379,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Görüş</th>\n",
              "      <th>Durum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>çok değil çekim gücü az olduğu için 3 puan</td>\n",
              "      <td>Tarafsız</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1522</th>\n",
              "      <td>avantajlar  fiyatbr i̇nternette yaptığım araşt...</td>\n",
              "      <td>Olumlu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734</th>\n",
              "      <td>ürün çok güzel paketlenmiş mükemmel kalitede</td>\n",
              "      <td>Olumlu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2504</th>\n",
              "      <td>hayalisukuta uğradım iki aydır araştırıyorum b...</td>\n",
              "      <td>Olumsuz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4523</th>\n",
              "      <td>ürün çin malı menüsü karışık kullanımı çocukla...</td>\n",
              "      <td>Tarafsız</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Görüş     Durum\n",
              "10           çok değil çekim gücü az olduğu için 3 puan  Tarafsız\n",
              "1522  avantajlar  fiyatbr i̇nternette yaptığım araşt...    Olumlu\n",
              "734        ürün çok güzel paketlenmiş mükemmel kalitede    Olumlu\n",
              "2504  hayalisukuta uğradım iki aydır araştırıyorum b...   Olumsuz\n",
              "4523  ürün çin malı menüsü karışık kullanımı çocukla...  Tarafsız"
            ]
          },
          "metadata": {},
          "execution_count": 379
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B00Rhz5QhoAA",
        "outputId": "2f3e647b-16a2-4f53-a78b-97677b03197b"
      },
      "source": [
        "# Check the DataFrame for one last time\n",
        "df.info()"
      ],
      "execution_count": 380,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 11426 entries, 10 to 9877\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Görüş   11426 non-null  object\n",
            " 1   Durum   11426 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 267.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF_lcz7W6UfB"
      },
      "source": [
        "### Input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGIK7G8FhoAA",
        "outputId": "ca92c57d-73d0-4cda-dc3a-985072276a74"
      },
      "source": [
        "# Get the average and the max length of the inputs\n",
        "import numpy as np\n",
        "\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "max_sent_len = np.max(sent_lens)\n",
        "avg_sent_len, max_sent_len"
      ],
      "execution_count": 381,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21.72378785226676, 422)"
            ]
          },
          "metadata": {},
          "execution_count": 381
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWQtwElghoAA",
        "outputId": "005ee700-d00c-471c-8f6b-26f166dddd14"
      },
      "source": [
        "# How long of a sentence lenght covers 95% of examples?\n",
        "output_seq_len_95 = int(np.percentile(sent_lens, 95))\n",
        "\n",
        "output_seq_len_95"
      ],
      "execution_count": 382,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 382
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PQ19VcfjOdL",
        "outputId": "e8d241a7-f775-4c18-b6d5-3acbf37f09fa"
      },
      "source": [
        "# How long of a sentence lenght covers 99% of examples?\n",
        "output_seq_len_99 = int(np.percentile(sent_lens, 99))\n",
        "\n",
        "output_seq_len_99"
      ],
      "execution_count": 383,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 383
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1ssprrMhoAB"
      },
      "source": [
        "# Since it is not a large number, 120 is chosen. The GPU that we're using can handle this\n",
        "output_seq_len = 120"
      ],
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9pkPIYw7C8e",
        "outputId": "73e0dc77-488f-4db7-865d-d559af2f2145"
      },
      "source": [
        "# Get transformers\n",
        "!pip install transformers"
      ],
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IGlN6Z5hoAB"
      },
      "source": [
        "# Import AutoTokenizer\n",
        "from transformers import AutoTokenizer\n",
        "# Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-128k-uncased\")"
      ],
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2V5ILnRhoAD",
        "outputId": "33f2836c-7225-40fb-af22-722853b00a04"
      },
      "source": [
        "# Encode inputs\n",
        "import tensorflow as tf\n",
        "\n",
        "input_ids = []\n",
        "attention_mask = []\n",
        "\n",
        "for txt in df.Görüş.values:\n",
        "    encoded = tokenizer.encode_plus(\n",
        "        text=txt, # the sentence to be encoded \n",
        "        add_special_tokens=True, # Add [CLS] and [SEP]\n",
        "        max_length=output_seq_len, # max length of a sentence\n",
        "        truncation=True, # truncate if sentence length is bigger than max_length\n",
        "        pad_to_max_length=True, # Add [PAD]s\n",
        "        return_attention_mask=True, # Generate attention mask\n",
        "        return_tensors=\"tf\" # return TensorFlow tensors\n",
        "    )\n",
        "\n",
        "    # Append input_ids and attention_masks to their own lists\n",
        "    input_ids.append(encoded[\"input_ids\"])\n",
        "    attention_mask.append(encoded[\"attention_mask\"])\n",
        "\n",
        "# Concatenate\n",
        "input_ids = tf.concat(input_ids, 0)\n",
        "attention_mask = tf.concat(attention_mask, 0)\n",
        "\n",
        "print(\"Original: \", df.Görüş.values[0])\n",
        "print(\"Token IDs: \", input_ids[0])"
      ],
      "execution_count": 387,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  çok değil çekim gücü az olduğu için 3 puan\n",
            "Token IDs:  tf.Tensor(\n",
            "[     2   6110  10715 106798  48790   1012   2463  15500   8059     23\n",
            "   4058      3      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0], shape=(120,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Glifs9muhoAD",
        "outputId": "de00de21-3695-4b21-f263-8b3bb5e5bde1"
      },
      "source": [
        "# Convert tokens to ids to check if the encoding operation is done correctly\n",
        "tokenizer.convert_ids_to_tokens(input_ids[0])"
      ],
      "execution_count": 388,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'cok',\n",
              " 'degil',\n",
              " 'cekim',\n",
              " 'guc',\n",
              " '##u',\n",
              " 'az',\n",
              " 'oldugu',\n",
              " 'icin',\n",
              " '3',\n",
              " 'puan',\n",
              " '[SEP]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {},
          "execution_count": 388
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiKh0E1vhoAD",
        "outputId": "157c8453-aca8-4c7b-dc93-ffec5b8e681d"
      },
      "source": [
        "# Check input_ids and shape of input_ids\n",
        "input_ids, input_ids.shape"
      ],
      "execution_count": 389,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(11426, 120), dtype=int32, numpy=\n",
              " array([[     2,   6110,  10715, ...,      0,      0,      0],\n",
              "        [     2,  26965,   2821, ...,      0,      0,      0],\n",
              "        [     2,  36664,   6110, ...,      0,      0,      0],\n",
              "        ...,\n",
              "        [     2,  16294,   2101, ...,      0,      0,      0],\n",
              "        [     2,   4991,  70375, ...,      0,      0,      0],\n",
              "        [     2, 106798,  48790, ...,      0,      0,      0]], dtype=int32)>,\n",
              " TensorShape([11426, 120]))"
            ]
          },
          "metadata": {},
          "execution_count": 389
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH94giL4hoAE",
        "outputId": "4fef2664-25a1-4e86-c972-fb20bafdd874"
      },
      "source": [
        "# Check attention_mask and shape of attention_mask\n",
        "attention_mask, attention_mask.shape"
      ],
      "execution_count": 390,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(11426, 120), dtype=int32, numpy=\n",
              " array([[1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>, TensorShape([11426, 120]))"
            ]
          },
          "metadata": {},
          "execution_count": 390
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SadHbXR2iXRv",
        "outputId": "2b736cee-2f60-4ae2-8f12-a38bd04e70e9"
      },
      "source": [
        "# Seperate test df from original df\n",
        "test_df = df.iloc[:1100]\n",
        "df = df.iloc[1100:]\n",
        "len(df), len(test_df)"
      ],
      "execution_count": 391,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10326, 1100)"
            ]
          },
          "metadata": {},
          "execution_count": 391
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X6-aj9wigJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cb720df-516f-4723-d68c-886592c5d61f"
      },
      "source": [
        "# Seperate test input ids and test attention mask from the original ones\n",
        "test_input_ids = input_ids[:1100]\n",
        "test_attention_mask = attention_mask[:1100]\n",
        "\n",
        "input_ids = input_ids[1100:]\n",
        "attention_mask = attention_mask[1100:]\n",
        "\n",
        "input_ids.shape, test_input_ids.shape, attention_mask.shape, test_attention_mask.shape"
      ],
      "execution_count": 392,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([10326, 120]),\n",
              " TensorShape([1100, 120]),\n",
              " TensorShape([10326, 120]),\n",
              " TensorShape([1100, 120]))"
            ]
          },
          "metadata": {},
          "execution_count": 392
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHOfBbPlhoAE",
        "outputId": "66231591-986b-4716-8b5d-8c03533b5d5d"
      },
      "source": [
        "# One hot encode our labels to use in our models\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "labels_one_hot = one_hot_encoder.fit_transform(df[\"Durum\"].to_numpy().reshape(-1,1))\n",
        "labels_one_hot.shape"
      ],
      "execution_count": 393,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10326, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 393
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T5AS1U7lC8O",
        "outputId": "0db12fbc-66d0-472a-d4bf-9be57ca0bde7"
      },
      "source": [
        "# One hot encode test labels\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "test_labels_one_hot = one_hot_encoder.fit_transform(test_df[\"Durum\"].to_numpy().reshape(-1,1))\n",
        "test_labels_one_hot.shape"
      ],
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1100, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 394
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-iVJ_eMitH7",
        "outputId": "80551c1e-7ce4-4c0a-d8d6-1346d65ce83f"
      },
      "source": [
        "# Label encode test labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "test_labels_encoded = label_encoder.fit_transform(test_df[\"Durum\"].to_numpy())\n",
        "\n",
        "test_labels_encoded"
      ],
      "execution_count": 395,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 0, ..., 2, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 395
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIKTKY3qVO0s",
        "outputId": "fb5562c3-28c0-425d-951d-681469eaa438"
      },
      "source": [
        "# Create a TensorFlow Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_mask, labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_input_ids, test_attention_mask, test_labels_one_hot))\n",
        "dataset, test_dataset"
      ],
      "execution_count": 396,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<TensorSliceDataset shapes: ((120,), (120,), (3,)), types: (tf.int32, tf.int32, tf.float64)>,\n",
              " <TensorSliceDataset shapes: ((120,), (120,), (3,)), types: (tf.int32, tf.int32, tf.float64)>)"
            ]
          },
          "metadata": {},
          "execution_count": 396
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBAAlyR2VP_6"
      },
      "source": [
        "# Create a function to map our dataset\n",
        "def map_func(input_ids, masks, labels):\n",
        "    # We convert our three-item tuple into a two-item tuple where the input item is a dictionary\n",
        "    return {\"input_ids\": input_ids,\n",
        "            \"attention_mask\": masks}, labels"
      ],
      "execution_count": 397,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y7qmFLgVP9n",
        "outputId": "e6ad1b1d-846f-49db-ef79-8d577feb7cfb"
      },
      "source": [
        "# Map the dataset using the function we created and check the dataset\n",
        "dataset = dataset.map(map_func)\n",
        "test_dataset = test_dataset.map(map_func)\n",
        "dataset, test_dataset"
      ],
      "execution_count": 398,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<MapDataset shapes: ({input_ids: (120,), attention_mask: (120,)}, (3,)), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.float64)>,\n",
              " <MapDataset shapes: ({input_ids: (120,), attention_mask: (120,)}, (3,)), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.float64)>)"
            ]
          },
          "metadata": {},
          "execution_count": 398
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sap4Qj6z8nYq"
      },
      "source": [
        "# Get the length of our dataset\n",
        "len_dataset_unbatched = len(dataset)"
      ],
      "execution_count": 399,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90lz2XbdVP4Z",
        "outputId": "23f2c04b-7b83-49c2-ebe8-e7453c9ab25e"
      },
      "source": [
        "# Batch our datasets\n",
        "batch_size=32\n",
        "dataset = dataset.batch(batch_size) #.shuffle(10000) , drop_remainder=True\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "\n",
        "dataset.take, test_dataset"
      ],
      "execution_count": 400,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<bound method DatasetV2.take of <BatchDataset shapes: ({input_ids: (None, 120), attention_mask: (None, 120)}, (None, 3)), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.float64)>>,\n",
              " <BatchDataset shapes: ({input_ids: (None, 120), attention_mask: (None, 120)}, (None, 3)), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.float64)>)"
            ]
          },
          "metadata": {},
          "execution_count": 400
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV-l87svVSfP",
        "outputId": "3e7e5ee3-70b1-4563-8f8d-eb8169ddc673"
      },
      "source": [
        "# Split our dataset into train, validation and test datasets\n",
        "split = 0.85\n",
        "size = int((input_ids.shape[0] / batch_size) * split)\n",
        "\n",
        "train_ds = dataset.take(size) # 85% of the dataset\n",
        "val_ds = dataset.skip(size) # 15% of the dataset\n",
        "\n",
        "len(dataset), len(train_ds), len(val_ds)"
      ],
      "execution_count": 401,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(323, 274, 49)"
            ]
          },
          "metadata": {},
          "execution_count": 401
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWKJvxCY2aq6"
      },
      "source": [
        "## Build and train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov5QgOsEVSc3",
        "outputId": "851dc620-7de9-416c-ee46-0b2bce164968"
      },
      "source": [
        "# Import the model\n",
        "from transformers import TFAutoModel\n",
        "\n",
        "bert128k = TFAutoModel.from_pretrained(\"dbmdz/bert-base-turkish-128k-uncased\")"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84ENq3wQVSaV"
      },
      "source": [
        "# Create the model\n",
        "import tensorflow as tf\n",
        "\n",
        "# two input layers, we ensure layer name variables match to dictionary keys in TF dataset\n",
        "input_ids = tf.keras.layers.Input(shape=(120,), name='input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(120,), name='attention_mask', dtype='int32')\n",
        "\n",
        "# we access the transformer model within our bert object using the bert attribute (eg bert.bert instead of bert)\n",
        "embeddings = bert128k.bert(input_ids, attention_mask=mask)[1]  # access final activations (already max-pooled) [1]\n",
        "# convert bert embeddings into 3 output classes\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(embeddings)\n",
        "outputs = tf.keras.layers.Dense(3, activation='softmax', name='outputs')(x)\n",
        "\n",
        "# model\n",
        "model_1_128k_uncased = tf.keras.Model(inputs=[input_ids, mask], outputs=outputs)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef65gdxpVYd9",
        "outputId": "2dbd6957-350f-471a-bee0-2c39af05595c"
      },
      "source": [
        "#Get the summary of model_1_128k_uncased\n",
        "model_1_128k_uncased.summary()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 120)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 120)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  184345344   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 120,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1024)         787456      ['bert[0][1]']                   \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 3)            3075        ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 185,135,875\n",
            "Trainable params: 185,135,875\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Br5uE2VP66"
      },
      "source": [
        "# Get learning rate using PolynomialDecay\n",
        "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
        "\n",
        "x = len_dataset_unbatched*0.85 # length of train_ds (unbatched)\n",
        "\n",
        "num_epochs = 3\n",
        "num_train_steps = x * num_epochs\n",
        "lr_scheduler = PolynomialDecay(\n",
        "    initial_learning_rate=5e-5,\n",
        "    end_learning_rate=0.,\n",
        "    decay_steps=num_train_steps\n",
        ")"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evtW9s40VYbs"
      },
      "source": [
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
        "\n",
        "model_1_128k_uncased.compile(optimizer=optimizer, \n",
        "              loss=loss, \n",
        "              metrics=[acc])"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPHt0g7NVYWh",
        "outputId": "db1a626b-401a-43b8-a7d7-2920144cbb53"
      },
      "source": [
        "# Fit the model\n",
        "history = model_1_128k_uncased.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=4,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "274/274 [==============================] - 431s 1s/step - loss: 0.7413 - accuracy: 0.6658 - val_loss: 0.7084 - val_accuracy: 0.7073\n",
            "Epoch 2/4\n",
            "274/274 [==============================] - 407s 1s/step - loss: 0.5633 - accuracy: 0.7709 - val_loss: 0.6632 - val_accuracy: 0.7401\n",
            "Epoch 3/4\n",
            "274/274 [==============================] - 407s 1s/step - loss: 0.4469 - accuracy: 0.8254 - val_loss: 0.6962 - val_accuracy: 0.7420\n",
            "Epoch 4/4\n",
            "274/274 [==============================] - 407s 1s/step - loss: 0.3309 - accuracy: 0.8809 - val_loss: 0.7932 - val_accuracy: 0.7471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBvY5NXlABjZ",
        "outputId": "5ac1bd8f-4cd1-4dd8-e765-7d099dcd739a"
      },
      "source": [
        "# Evaluate the model on test_ds\n",
        "model_1_128k_uncased.evaluate(test_dataset)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 17s 473ms/step - loss: 0.7069 - accuracy: 0.7673\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7068949937820435, 0.7672727108001709]"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAsI12RjLx0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c90a280-fe0e-46e4-93af-cab946d7c12e"
      },
      "source": [
        "# Download helper functions\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-07 22:03:43--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-07 22:03:43 (75.1 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1wc9G_pL2Jh"
      },
      "source": [
        "from helper_functions import calculate_results"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tnAgQNJK4p3",
        "outputId": "eb0b296a-45cd-4591-d6d9-6d8d527409ef"
      },
      "source": [
        "# Make predictions\n",
        "model_1_128k_uncased_pred_probs = model_1_128k_uncased.predict(test_dataset)\n",
        "model_1_128k_uncased_pred_probs[0], model_1_128k_uncased_pred_probs.shape"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.8083878 , 0.0064343 , 0.18517783], dtype=float32), (1100, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zov0MPMrLLMJ",
        "outputId": "94b17f28-3136-49a7-a3cb-b3674351e00a"
      },
      "source": [
        "# Convert pred_probs to classes\n",
        "model_1_128k_uncased_preds = tf.argmax(model_1_128k_uncased_pred_probs, axis=1)\n",
        "model_1_128k_uncased_preds"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1100,), dtype=int64, numpy=array([0, 1, 0, ..., 0, 1, 0])>"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-AAlwpwul_A",
        "outputId": "48fb03e3-50cf-4a04-83aa-30f7f90ba3be"
      },
      "source": [
        "# Calculate model_1 results\n",
        "model_1_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                    y_pred=model_1_128k_uncased_preds)\n",
        "model_1_results"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.72727272727272,\n",
              " 'f1': 0.7695097795934159,\n",
              " 'precision': 0.7722493926925608,\n",
              " 'recall': 0.7672727272727272}"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0ylC9ntcXkH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de3c028-d75f-4349-f108-e54abf1a1d12"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# two input layers, we ensure layer name variables match to dictionary keys in TF dataset\n",
        "input_ids = tf.keras.layers.Input(shape=(120,), name='input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(120,), name='attention_mask', dtype='int32')\n",
        "\n",
        "# we access the transformer model within our bert object using the bert attribute (eg bert.bert instead of bert)\n",
        "embeddings = bert128k.bert(input_ids, attention_mask=mask)[0]  # access final activations with [0]\n",
        "\n",
        "x = tf.keras.layers.LSTM(8, dropout=.4, recurrent_dropout=.4, return_sequences=False) (embeddings) \n",
        "# normalize\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "# output\n",
        "outputs = tf.keras.layers.Dense(3, activation='softmax', name='outputs')(x)\n",
        "\n",
        "model_2_128k_uncased_LSTM = tf.keras.Model(inputs=[input_ids, mask], outputs=outputs)"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCpmjS5DcXhr",
        "outputId": "80cb1c4d-8bf9-40e6-be01-87aa14bb88a1"
      },
      "source": [
        "model_2_128k_uncased_LSTM.layers[2].trainable = False\n",
        "\n",
        "# print out model summary\n",
        "model_2_128k_uncased_LSTM.summary()"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 120)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 120)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  184345344   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 120,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, 8)            24864       ['bert[5][0]']                   \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 8)           32          ['lstm_2[0][0]']                 \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 3)            27          ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 184,370,267\n",
            "Trainable params: 24,907\n",
            "Non-trainable params: 184,345,360\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sICCVKWhcXe8"
      },
      "source": [
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5) #lr_scheduler\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
        "\n",
        "model_2_128k_uncased_LSTM.compile(optimizer=optimizer, \n",
        "              loss=loss, \n",
        "              metrics=[acc])"
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy7NduZucXcO",
        "outputId": "9c28cf11-99ad-42bf-f35a-27f22d7176b0"
      },
      "source": [
        "# Fit the model\n",
        "history_model_2 = model_2_128k_uncased_LSTM.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=4,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "274/274 [==============================] - 354s 1s/step - loss: 0.6841 - accuracy: 0.7148 - val_loss: 0.4174 - val_accuracy: 0.8588\n",
            "Epoch 2/4\n",
            "274/274 [==============================] - 331s 1s/step - loss: 0.4537 - accuracy: 0.8418 - val_loss: 0.3702 - val_accuracy: 0.8800\n",
            "Epoch 3/4\n",
            "274/274 [==============================] - 332s 1s/step - loss: 0.4196 - accuracy: 0.8549 - val_loss: 0.3554 - val_accuracy: 0.8858\n",
            "Epoch 4/4\n",
            "274/274 [==============================] - 332s 1s/step - loss: 0.4054 - accuracy: 0.8607 - val_loss: 0.3489 - val_accuracy: 0.8890\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kToL7sjqDJwd",
        "outputId": "73652f19-ac1e-4e36-f1c9-29b11bb7acb6"
      },
      "source": [
        "# Evaluate the model on test_ds\n",
        "model_2_128k_uncased_LSTM.evaluate(test_dataset)"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 19s 529ms/step - loss: 0.3291 - accuracy: 0.8873\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.32908207178115845, 0.8872727155685425]"
            ]
          },
          "metadata": {},
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0JDHsLlkq48",
        "outputId": "5bdc8701-53e1-4420-c0a7-a5afabe247e6"
      },
      "source": [
        "# Make predictions\n",
        "model_2_128k_uncased_LSTM_pred_probs = model_2_128k_uncased_LSTM.predict(test_dataset)\n",
        "model_2_128k_uncased_LSTM_pred_probs[0], model_2_128k_uncased_LSTM_pred_probs.shape"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.00780847, 0.9600811 , 0.03211032], dtype=float32), (1100, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKdiNgilom4m",
        "outputId": "0965b405-0ed5-49e6-af6a-660b7b5cf3bf"
      },
      "source": [
        "# Convert pred_probs to classes\n",
        "model_2_128k_uncased_LSTM_preds = tf.argmax(model_2_128k_uncased_LSTM_pred_probs, axis=1)\n",
        "model_2_128k_uncased_LSTM_preds"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1100,), dtype=int64, numpy=array([1, 0, 1, ..., 2, 2, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk4bGJ7_om2l",
        "outputId": "50a51e25-fedf-4e79-8561-b601271cfd40"
      },
      "source": [
        "# Calculate model_2 results\n",
        "model_2_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                    y_pred=model_2_128k_uncased_LSTM_preds)\n",
        "model_2_results"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 88.72727272727273,\n",
              " 'f1': 0.8848936799629704,\n",
              " 'precision': 0.8851480160049142,\n",
              " 'recall': 0.8872727272727273}"
            ]
          },
          "metadata": {},
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOKuxPh7omz9"
      },
      "source": [
        "# two input layers, we ensure layer name variables match to dictionary keys in TF dataset\n",
        "input_ids = tf.keras.layers.Input(shape=(120,), name='input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(120,), name='attention_mask', dtype='int32')\n",
        "\n",
        "# we access the transformer model within our bert object using the bert attribute (eg bert.bert instead of bert)\n",
        "embeddings = bert128k.bert(input_ids, attention_mask=mask)[0]  # access final activations with [0]\n",
        "\n",
        "x = tf.keras.layers.GRU(16, return_sequences=False)(embeddings) \n",
        "# normalize\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "# output\n",
        "outputs = tf.keras.layers.Dense(3, activation='softmax', name='outputs')(x)\n",
        "\n",
        "model_3_128k_uncased_GRU = tf.keras.Model(inputs=[input_ids, mask], outputs=outputs)"
      ],
      "execution_count": 353,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDyRN2Ut5_hi",
        "outputId": "d32169fe-e2a5-424d-97ce-4d98a2fa87b1"
      },
      "source": [
        "model_3_128k_uncased_GRU.layers[2].trainable = False\n",
        "\n",
        "# print out model summary\n",
        "model_3_128k_uncased_GRU.summary()"
      ],
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 120)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 120)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  184345344   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 120,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " gru_2 (GRU)                    (None, 16)           37728       ['bert[7][0]']                   \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16)          64          ['gru_2[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 3)            51          ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 184,383,187\n",
            "Trainable params: 37,811\n",
            "Non-trainable params: 184,345,376\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N99ZxqJ06FsW"
      },
      "source": [
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5) #lr_scheduler\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
        "\n",
        "model_3_128k_uncased_GRU.compile(optimizer=optimizer, \n",
        "              loss=loss, \n",
        "              metrics=[acc])"
      ],
      "execution_count": 355,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5oKmrfc6LgB",
        "outputId": "6fb6e50e-fc00-48ab-a79d-9ef6d03f8354"
      },
      "source": [
        "# Fit the model\n",
        "history_model_3 = model_3_128k_uncased_GRU.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=4,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 356,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "274/274 [==============================] - 190s 626ms/step - loss: 0.6361 - accuracy: 0.7525 - val_loss: 0.3886 - val_accuracy: 0.8716\n",
            "Epoch 2/4\n",
            "274/274 [==============================] - 168s 612ms/step - loss: 0.4264 - accuracy: 0.8493 - val_loss: 0.3570 - val_accuracy: 0.8813\n",
            "Epoch 3/4\n",
            "274/274 [==============================] - 168s 612ms/step - loss: 0.3964 - accuracy: 0.8629 - val_loss: 0.3443 - val_accuracy: 0.8870\n",
            "Epoch 4/4\n",
            "274/274 [==============================] - 168s 612ms/step - loss: 0.3871 - accuracy: 0.8678 - val_loss: 0.3373 - val_accuracy: 0.8902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2ue1EZ9DQei",
        "outputId": "627e1768-8b4a-478d-b365-c69d29027b5c"
      },
      "source": [
        "# Evaluate the model on test_ds\n",
        "model_3_128k_uncased_GRU.evaluate(test_dataset)"
      ],
      "execution_count": 357,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 17s 478ms/step - loss: 0.3365 - accuracy: 0.8873\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3365486264228821, 0.8872727155685425]"
            ]
          },
          "metadata": {},
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7n5h4Mr10bZW",
        "outputId": "ed601ee6-d532-4d13-ab49-3f16a39a0609"
      },
      "source": [
        "# Make predictions\n",
        "model_3_128k_uncased_GRU_pred_probs = model_3_128k_uncased_GRU.predict(test_dataset)\n",
        "model_3_128k_uncased_GRU_pred_probs[0], model_3_128k_uncased_GRU_pred_probs.shape"
      ],
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.01193844, 0.9718598 , 0.01620176], dtype=float32), (1100, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 358
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCYYOG2G0bWv",
        "outputId": "09fa2b9e-b7a7-4960-e2d6-66b557290f02"
      },
      "source": [
        "# Convert pred_probs to classes\n",
        "model_3_128k_uncased_GRU_preds = tf.argmax(model_3_128k_uncased_GRU_pred_probs, axis=1)\n",
        "model_3_128k_uncased_GRU_preds"
      ],
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1100,), dtype=int64, numpy=array([1, 1, 0, ..., 2, 1, 0])>"
            ]
          },
          "metadata": {},
          "execution_count": 359
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckJTc_ih0yeF",
        "outputId": "b1a4310d-c242-492a-9d01-7338daad2149"
      },
      "source": [
        "# Calculate model_3 results\n",
        "model_3_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                    y_pred=model_3_128k_uncased_GRU_preds)\n",
        "model_3_results"
      ],
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 88.72727272727273,\n",
              " 'f1': 0.8860886106830129,\n",
              " 'precision': 0.8856997214280882,\n",
              " 'recall': 0.8872727272727273}"
            ]
          },
          "metadata": {},
          "execution_count": 360
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp4QNtuP9_CY"
      },
      "source": [
        "# two input layers, we ensure layer name variables match to dictionary keys in TF dataset\n",
        "input_ids = tf.keras.layers.Input(shape=(120,), name='input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(120,), name='attention_mask', dtype='int32')\n",
        "\n",
        "# we access the transformer model within our bert object using the bert attribute (eg bert.bert instead of bert)\n",
        "embeddings = bert128k.bert(input_ids, attention_mask=mask)[1]  # access final activations with [0]\n",
        "\n",
        "x = tf.keras.layers.Dense(16, activation=\"relu\")(embeddings)\n",
        "# output\n",
        "outputs = tf.keras.layers.Dense(3, activation='softmax', name='outputs')(x)\n",
        "\n",
        "model_4_dense = tf.keras.Model(inputs=[input_ids, mask], outputs=outputs)"
      ],
      "execution_count": 402,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q10Fgw629--S",
        "outputId": "0147cbee-224a-4a37-a85b-6313af92fd2a"
      },
      "source": [
        "model_4_dense.layers[2].trainable = False\n",
        "\n",
        "# print out model summary\n",
        "model_4_dense.summary()"
      ],
      "execution_count": 403,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 120)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 120)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  184345344   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 120,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 16)           12304       ['bert[8][1]']                   \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 3)            51          ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 184,357,699\n",
            "Trainable params: 12,355\n",
            "Non-trainable params: 184,345,344\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqqo-9wy9-7z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47db1452-a460-4985-bd73-094e3ce087f1"
      },
      "source": [
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(lr=3e-5)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
        "\n",
        "model_4_dense.compile(optimizer=optimizer, \n",
        "              loss=loss, \n",
        "              metrics=[acc])"
      ],
      "execution_count": 405,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WihHWD5n-ikK",
        "outputId": "4d7822e1-6719-458a-ec1f-f681a79a42b5"
      },
      "source": [
        "# Fit the model\n",
        "history_model_4 = model_4_dense.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=3,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 406,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "274/274 [==============================] - 185s 614ms/step - loss: 0.8585 - accuracy: 0.6551 - val_loss: 0.4298 - val_accuracy: 0.8755\n",
            "Epoch 2/3\n",
            "274/274 [==============================] - 165s 602ms/step - loss: 0.4014 - accuracy: 0.8625 - val_loss: 0.3698 - val_accuracy: 0.8819\n",
            "Epoch 3/3\n",
            "274/274 [==============================] - 165s 601ms/step - loss: 0.3788 - accuracy: 0.8654 - val_loss: 0.3644 - val_accuracy: 0.8851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0WExa_hDXgw",
        "outputId": "6033cf74-bf1f-489c-bb88-577e2cf68b77"
      },
      "source": [
        "# Evaluate the model on test_ds\n",
        "model_4_dense.evaluate(test_dataset)"
      ],
      "execution_count": 407,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 17s 471ms/step - loss: 0.3104 - accuracy: 0.8936\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3103732466697693, 0.8936363458633423]"
            ]
          },
          "metadata": {},
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgB9xwKM-inG",
        "outputId": "6b861ee5-1180-4fc7-c91d-c162aaa8e533"
      },
      "source": [
        "# Make predictions\n",
        "model_4_dense_pred_probs = model_4_dense.predict(test_dataset)\n",
        "model_4_dense_pred_probs[0], model_4_dense_pred_probs.shape"
      ],
      "execution_count": 408,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.48290142, 0.1296168 , 0.38748175], dtype=float32), (1100, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 408
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZjDc1EZ-iqb",
        "outputId": "042e7d6b-24ef-4872-f198-59b222228486"
      },
      "source": [
        "# Convert pred_probs to classes\n",
        "model_4_dense_preds = tf.argmax(model_4_dense_pred_probs, axis=1)\n",
        "model_4_dense_preds"
      ],
      "execution_count": 409,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1100,), dtype=int64, numpy=array([0, 0, 0, ..., 2, 2, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 409
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr0Z1opL-itf",
        "outputId": "9b905952-e426-45c1-c9ed-dc7a99659b73"
      },
      "source": [
        "# Calculate model_3 results\n",
        "model_4_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                    y_pred=model_4_dense_preds)\n",
        "model_4_results"
      ],
      "execution_count": 410,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 89.36363636363637,\n",
              " 'f1': 0.8930262630968501,\n",
              " 'precision': 0.8927291539405786,\n",
              " 'recall': 0.8936363636363637}"
            ]
          },
          "metadata": {},
          "execution_count": 410
        }
      ]
    }
  ]
}