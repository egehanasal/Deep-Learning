{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce GTX 1050 Ti (UUID: GPU-ada268bc-35a4-5a51-f812-70e7584578bb)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>3 milyon ile ön seçim vaadi mhp nin 10 olağan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>mesut_yılmaz yüce_divan da ceza alabilirdi pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>disko lar kaldırılıyor başbakan_yardımcısı ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>sarıgül anayasa_mahkemesi ne gidiyor mustafa_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>siyaset</td>\n",
       "      <td>erdoğan idamın bir haklılık sebebi var demek ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                               text\n",
       "0  siyaset    3 milyon ile ön seçim vaadi mhp nin 10 olağan...\n",
       "1  siyaset    mesut_yılmaz yüce_divan da ceza alabilirdi pr...\n",
       "2  siyaset    disko lar kaldırılıyor başbakan_yardımcısı ar...\n",
       "3  siyaset    sarıgül anayasa_mahkemesi ne gidiyor mustafa_...\n",
       "4  siyaset    erdoğan idamın bir haklılık sebebi var demek ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/siyaset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "siyaset       700\n",
       "dunya         700\n",
       "ekonomi       700\n",
       "kultur        700\n",
       "saglik        700\n",
       "spor          700\n",
       "teknoloji     700\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 3 milyon ile ön seçim vaadi mhp nin 10 olağan büyük kurultayı nda konuşan genel başkan adayı koray_aydın seçimlerden önce partinin üye sayısının 3 milyona ulaştırılması hedefini koyarak ön seçim uygulaması vaadinde bulundu mhp nin 10 olağan büyük kurultayı nda konuşan genel başkan adayı koray_aydın seçimlerden önce partinin üye sayısının 3 milyona ulaştırılması hedefini koyarak ön seçim uygulaması vaadinde bulundu genel_başkan adayı koray_aydın kürsüye beklenirken yapılan tezahüratlar ve ıslıklamalar üzerine divan başkanı tuğrul_türkeş mhp nin genel başkanlığı da genel başkan adaylığı da saygıdeğer işlerdir bu salondaki herkes ciddiye almak zorundadır dedi ve taşkınlıklara izin verilmeyeceğini salonda sükunet sağlanmadan konuşmaların başlamayacağını vurguladı türkeş devlet_bahçeli nin kurultay açılışında konuştuğu için adaylık nedeniyle ikinci bir konuşma yapmayacağını açıkladı konuşmasında kurultayın mhp nin tek başına iktidarına vesile olmasını dileyen aydın ak_parti nin mhp yi eleştirirken kaleleri bir bir fethederek yollarına devam ettiklerini söylediğini hatırlatarak iktidarın basın ve sivil toplumu susturduğunu ifade etti ak_parti nin bürokraside taş üstüne taş bırakmadığını ileri süren aydın ülkücüleri düşman kabule ederek onları kıyma makinelerinden geçirecek bir zihniyetle sürgün ederek oraya buraya saldırarak bürokrasideki ülkücü kadrolara savaş açtılar dedi yaşanan bütün skandalların ardından devleti çete mantığıyla yöneten siyasi iktidarın olduğunu savunan aydın iktidarın belediyelere sahte raporlarla ve dinlemelerle saldırdığını savunan aydın arkasından habur dan içeri soktukları vatan hainlerine karşılama törenleri yetmez gibi oslo da teröristlerle kurdukları pazarlık masalarında suçüstü yakalanınca da ben görmedim diyerek bunu ispat edecek biri varsa şerefle ispat etsin diyerek ses kayıtları çıkınca da kıvırarak sahiplenemeyerek yaptığı işin üzerine şal örtmeye çalışarak siyasi riyakarlıkta sınır tanımayan siyasi iktidarla karşı karşıyayız diye konuştu mintika temizliği yapiyorlar ak_parti nin ne yaptığını iyi bildiğini türkiye de ihtilal teşebbüsü var diyerek ordunun subaylarını yargılama adı altında cezaevine koyduğunu savunan aydın önce milletin bu darbeciler ortadan kalksın diyerek desteklediği sonra plan gereği sürek avına çevirerek türk ordusunun neredeyse yarısını içeri atan bu zihniyet mıntıka temizliği yapıyor kuracakları yeni türkiye modeline engel olmasın diye bunları kaldırıyorlar bu işi haince yapanlar ne zaman ki şehit cenazeleri türkiye yi ağlatmaya başlarken acılarımızla yaşarken türkiye nin başbakanı gerekirse öcalan la yeniden görüşebilirim diyor sayın_başbakan ne görüşeceksin öcalan la ne söyleyeceksin oraya bir masa koymuşsun masanın üstünde türkiye karşında öcalan ne kadar istiyorsun şu kadar versem yeter mi diyeceksin öcalan yüzsüzlük eder de türkiye nin tamamını isterse ne yapacaksın diye konuştu o zaman ne yapacağiz yeni anayasa kapsamında türk milletinin adının anayasadan çıkarılarak bir alt kimlik haline getirileceğini türk milletine etnisite temelli yaklaşılacağını savunan aydın bu_türk milletinin varlığını ötüken de söğüt te türk olan türk milletinin varlığını ortadan kaldırma çabasıdır bu işin sonudur çünkü şu anda kendisiyle benzeşen anamuhalefetle anlaşıp anayasadan türk milletinin adını çıkarırlarsa yapılacak bir şey kalmaz meclis sayısal çoğunlukla yönetiliyor bunlar sinsi her işi alttan alttan götürüyorlar böyle bir adım atar bu büyük milletin adını çıkararak türk milletini bir alt kimlik haline dönüştürürlerse ne yapacağız bunu yaparlarsa 5 yıl 10 yıl sonra bu ülkenin adının türkiye olmasına gerek yoktur derlerse ne yapacağız bu sinsi planı iyi görelim bunu için bir şeyler yapmamız harekete geçmemiz lazım dedi şubat ta 1 milyon olarak toplanirsak … kimsenin türkiye de olanlara arkasını dönemeyeceğini ifade eden aydın özetle şunları söyledi meydanlara ineceğiz türk milletine gideceğiz milletle bütünleşeceğiz onu bekleyen bu tehlikeler hakkında uyaracağız anlatacağız onu yanımıza almaya çalışacağız o büyük gücü harekete geçirir meydanlara iner onların dikkatini çekip yanımıza alırsak şubat ayında 1 milyon olarak toplanırsak hangi vatan hainleri bunu yapmaya cesaret edebilir türk milletinin bunu anlamasını sağlamamız lazım bunun için güçlü bir mhp ye ihtiyaç var 43 yıllık fikri birikimi üzerinden türk milletini bütün problemlerine getireceği çözüm önerilerini bir iktidar projesine dönüştürerek türk milletini karşısına çıkıp iktidar istersek bu coşku ve heyecanı ona aksettirirsek bu millet bu şaşkınlıkla etrafına bakınırken ben nereye bakacağım sorusunu sorarken bu millet elimizi tutacak ve mhp ile yeniden ayağa kalkacaktır hedef 3 milyon üye bu mücadelede ilk doğru adımın ülkücü hareketin birliğini ve dirliğini sağlamak olduğunu kaydeden aydın harekete bir gün bile hizmet etmiş her ülküdaşlarıyla kucaklaşmak ve bir araya gelmek mecburiyetinde olduklarını ifade etti ülkücüleri ülküdaşlık hukuku temelinde kaynaştırmadan büyük hedeflere yürüyemeyeceklerini anlatan aydın bunu temel hareket noktası kabul ediyoruz birey temelli bir hareketin başlaması için önce partide üyelik sistemini bir kampanyaya çevireceğiz seçime kadar 3 milyon üye yaparak ailelerimizin fertlerini genişleteceğiz bunu iller arası yarışa çevireceğiz mhp nin 3 milyon üyeli geniş aile haline gelmesini sağlayacağız dedi önseçim vaadi genel_başkan seçilmesi halinde mhp ailesini genişleteceğini kaydeden aydın bunu yapınca bu 3 milyon kişi kurulan sandıklarla yapacağı bir ön seçimi size vaat ediyorum bunu taban güvenmek demektir böyle bir ön seçim yapıldı mı ankara da kimse genel merkez katlarında dolaşmayacak tabana size gidecek hasta olanın düğünü olanın yanında olacak yere düşeni ayağa kaldıracak böylece bu büyük aile fertleri bir birini anlayacak bu güzel sözün olduğu ortamın inşası demektir bu kötü söz olanın tasfiye edileceği liyakatın esas alınacağı yeni bir sistemin gelmesin demektir bu adımı atar aile fertleri arasında huzuru sağlarsak örgütlenme modelini buna paralel değiştirirsek mhp nin içinde huzur sağlanır diye konuştu bu bir kişiyi korumak için kelle avcısı rolü üstlenip ülküdaşlarını yok farz ederek küskünler ordusu yarattığın bir sitemin anlaşılması demektir diyen aydın mhp her yerde sloganıyla parti içinde hareketlilik sağlayacaklarını halka dokunacaklarını ifade etti ve tabanla bütünleşmiş mhp ye ihtiyaç var bunun içi bir iktidar projesi koyarak aday olduk biz iktidar olmak istiyoruz dedi aydın türk milletinin yalnızlığı yaşadığı bir durumda etrafına bakındığı kendini kaldıracak birini bekleyen türkiye nin mhp nin kendisine ulaşmasıyla yarın elbet bizimdir diye haykıracağını ifade etti haber anka foto emre senoglu murat oztek'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get train sentences from df.comment\n",
    "train_sentences = df[\"text\"].tolist()\n",
    "\n",
    "train_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268.6981632653061, 2711)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the average and the max length of the inputs\n",
    "import numpy as np\n",
    "\n",
    "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
    "avg_sent_len = np.mean(sent_lens)\n",
    "max_sent_len = np.max(sent_lens)\n",
    "avg_sent_len, max_sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "673"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "output_seq_len = int(np.percentile(sent_lens, 95))\n",
    "\n",
    "output_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-128k-uncased', do_lower_case=True)\n",
    "sentences = df.text.values\n",
    "max_len = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egehan\\anaconda3\\envs\\DL\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:   3 milyon ile ön seçim vaadi mhp nin 10 olağan büyük kurultayı nda konuşan genel başkan adayı koray_aydın seçimlerden önce partinin üye sayısının 3 milyona ulaştırılması hedefini koyarak ön seçim uygulaması vaadinde bulundu mhp nin 10 olağan büyük kurultayı nda konuşan genel başkan adayı koray_aydın seçimlerden önce partinin üye sayısının 3 milyona ulaştırılması hedefini koyarak ön seçim uygulaması vaadinde bulundu genel_başkan adayı koray_aydın kürsüye beklenirken yapılan tezahüratlar ve ıslıklamalar üzerine divan başkanı tuğrul_türkeş mhp nin genel başkanlığı da genel başkan adaylığı da saygıdeğer işlerdir bu salondaki herkes ciddiye almak zorundadır dedi ve taşkınlıklara izin verilmeyeceğini salonda sükunet sağlanmadan konuşmaların başlamayacağını vurguladı türkeş devlet_bahçeli nin kurultay açılışında konuştuğu için adaylık nedeniyle ikinci bir konuşma yapmayacağını açıkladı konuşmasında kurultayın mhp nin tek başına iktidarına vesile olmasını dileyen aydın ak_parti nin mhp yi eleştirirken kaleleri bir bir fethederek yollarına devam ettiklerini söylediğini hatırlatarak iktidarın basın ve sivil toplumu susturduğunu ifade etti ak_parti nin bürokraside taş üstüne taş bırakmadığını ileri süren aydın ülkücüleri düşman kabule ederek onları kıyma makinelerinden geçirecek bir zihniyetle sürgün ederek oraya buraya saldırarak bürokrasideki ülkücü kadrolara savaş açtılar dedi yaşanan bütün skandalların ardından devleti çete mantığıyla yöneten siyasi iktidarın olduğunu savunan aydın iktidarın belediyelere sahte raporlarla ve dinlemelerle saldırdığını savunan aydın arkasından habur dan içeri soktukları vatan hainlerine karşılama törenleri yetmez gibi oslo da teröristlerle kurdukları pazarlık masalarında suçüstü yakalanınca da ben görmedim diyerek bunu ispat edecek biri varsa şerefle ispat etsin diyerek ses kayıtları çıkınca da kıvırarak sahiplenemeyerek yaptığı işin üzerine şal örtmeye çalışarak siyasi riyakarlıkta sınır tanımayan siyasi iktidarla karşı karşıyayız diye konuştu mintika temizliği yapiyorlar ak_parti nin ne yaptığını iyi bildiğini türkiye de ihtilal teşebbüsü var diyerek ordunun subaylarını yargılama adı altında cezaevine koyduğunu savunan aydın önce milletin bu darbeciler ortadan kalksın diyerek desteklediği sonra plan gereği sürek avına çevirerek türk ordusunun neredeyse yarısını içeri atan bu zihniyet mıntıka temizliği yapıyor kuracakları yeni türkiye modeline engel olmasın diye bunları kaldırıyorlar bu işi haince yapanlar ne zaman ki şehit cenazeleri türkiye yi ağlatmaya başlarken acılarımızla yaşarken türkiye nin başbakanı gerekirse öcalan la yeniden görüşebilirim diyor sayın_başbakan ne görüşeceksin öcalan la ne söyleyeceksin oraya bir masa koymuşsun masanın üstünde türkiye karşında öcalan ne kadar istiyorsun şu kadar versem yeter mi diyeceksin öcalan yüzsüzlük eder de türkiye nin tamamını isterse ne yapacaksın diye konuştu o zaman ne yapacağiz yeni anayasa kapsamında türk milletinin adının anayasadan çıkarılarak bir alt kimlik haline getirileceğini türk milletine etnisite temelli yaklaşılacağını savunan aydın bu_türk milletinin varlığını ötüken de söğüt te türk olan türk milletinin varlığını ortadan kaldırma çabasıdır bu işin sonudur çünkü şu anda kendisiyle benzeşen anamuhalefetle anlaşıp anayasadan türk milletinin adını çıkarırlarsa yapılacak bir şey kalmaz meclis sayısal çoğunlukla yönetiliyor bunlar sinsi her işi alttan alttan götürüyorlar böyle bir adım atar bu büyük milletin adını çıkararak türk milletini bir alt kimlik haline dönüştürürlerse ne yapacağız bunu yaparlarsa 5 yıl 10 yıl sonra bu ülkenin adının türkiye olmasına gerek yoktur derlerse ne yapacağız bu sinsi planı iyi görelim bunu için bir şeyler yapmamız harekete geçmemiz lazım dedi şubat ta 1 milyon olarak toplanirsak … kimsenin türkiye de olanlara arkasını dönemeyeceğini ifade eden aydın özetle şunları söyledi meydanlara ineceğiz türk milletine gideceğiz milletle bütünleşeceğiz onu bekleyen bu tehlikeler hakkında uyaracağız anlatacağız onu yanımıza almaya çalışacağız o büyük gücü harekete geçirir meydanlara iner onların dikkatini çekip yanımıza alırsak şubat ayında 1 milyon olarak toplanırsak hangi vatan hainleri bunu yapmaya cesaret edebilir türk milletinin bunu anlamasını sağlamamız lazım bunun için güçlü bir mhp ye ihtiyaç var 43 yıllık fikri birikimi üzerinden türk milletini bütün problemlerine getireceği çözüm önerilerini bir iktidar projesine dönüştürerek türk milletini karşısına çıkıp iktidar istersek bu coşku ve heyecanı ona aksettirirsek bu millet bu şaşkınlıkla etrafına bakınırken ben nereye bakacağım sorusunu sorarken bu millet elimizi tutacak ve mhp ile yeniden ayağa kalkacaktır hedef 3 milyon üye bu mücadelede ilk doğru adımın ülkücü hareketin birliğini ve dirliğini sağlamak olduğunu kaydeden aydın harekete bir gün bile hizmet etmiş her ülküdaşlarıyla kucaklaşmak ve bir araya gelmek mecburiyetinde olduklarını ifade etti ülkücüleri ülküdaşlık hukuku temelinde kaynaştırmadan büyük hedeflere yürüyemeyeceklerini anlatan aydın bunu temel hareket noktası kabul ediyoruz birey temelli bir hareketin başlaması için önce partide üyelik sistemini bir kampanyaya çevireceğiz seçime kadar 3 milyon üye yaparak ailelerimizin fertlerini genişleteceğiz bunu iller arası yarışa çevireceğiz mhp nin 3 milyon üyeli geniş aile haline gelmesini sağlayacağız dedi önseçim vaadi genel_başkan seçilmesi halinde mhp ailesini genişleteceğini kaydeden aydın bunu yapınca bu 3 milyon kişi kurulan sandıklarla yapacağı bir ön seçimi size vaat ediyorum bunu taban güvenmek demektir böyle bir ön seçim yapıldı mı ankara da kimse genel merkez katlarında dolaşmayacak tabana size gidecek hasta olanın düğünü olanın yanında olacak yere düşeni ayağa kaldıracak böylece bu büyük aile fertleri bir birini anlayacak bu güzel sözün olduğu ortamın inşası demektir bu kötü söz olanın tasfiye edileceği liyakatın esas alınacağı yeni bir sistemin gelmesin demektir bu adımı atar aile fertleri arasında huzuru sağlarsak örgütlenme modelini buna paralel değiştirirsek mhp nin içinde huzur sağlanır diye konuştu bu bir kişiyi korumak için kelle avcısı rolü üstlenip ülküdaşlarını yok farz ederek küskünler ordusu yarattığın bir sitemin anlaşılması demektir diyen aydın mhp her yerde sloganıyla parti içinde hareketlilik sağlayacaklarını halka dokunacaklarını ifade etti ve tabanla bütünleşmiş mhp ye ihtiyaç var bunun içi bir iktidar projesi koyarak aday olduk biz iktidar olmak istiyoruz dedi aydın türk milletinin yalnızlığı yaşadığı bir durumda etrafına bakındığı kendini kaldıracak birini bekleyen türkiye nin mhp nin kendisine ulaşmasıyla yarın elbet bizimdir diye haykıracağını ifade etti haber anka foto emre senoglu murat oztek\n",
      "Token IDs:  tf.Tensor(\n",
      "[     2     23   2961   2037   2121  75030  47568   6321   2276   2562\n",
      " 110065  20086  30418   3334   5484   1928   2468  34449   6892  20249\n",
      "     41   3948  75030   2884  18094  10349  84087   8369     23  18462\n",
      " 114961   3940 120685  28262  14540   2121  75030   6394  87715   4502\n",
      "   6321   2276   2562 110065  20086  30418   3334   5484   1928   2468\n",
      "  34449   6892  20249     41   3948  75030   2884  18094  10349  84087\n",
      "   8369     23  18462 114961   3940 120685  28262  14540   2121  75030\n",
      "   6394  87715   4502   2468     41  34449   6892  20249     41   3948\n",
      "   6905   3356  37662   2649  17852  90680   1934   1946  48998  10086\n",
      "  45898  11835  34449   1022  36527   9021     41   6142   1951   6321\n",
      "   2276   2468  34449  49313   1972   2468  34449   3554  49313   1972\n",
      "   5316   1942   4829  72798   2025   1964  51135   3171  15818   3632\n",
      "  10121   2841   1946  80525   1930  21291   3794  35219  98117   4389\n",
      "  17367  27101  13224   1025   9598  25110  75577   1980  90717   2213\n",
      " 123433   8781   6142   1951   2780     41  68429   2276  15900  26419\n",
      "   5692 105223   2287   8059  24030   3426   3547   1947  75577   5180\n",
      " 123433  20314   2986  75577   5692  80152   6321   2276   2171  13940\n",
      "  64856  11824   5634  23461   3948   2158     41   3474   2276   6321\n",
      "   3553  77122   5370  68190   1947   1947  37649   2408  27374   2524\n",
      "  10924  80447   7426  19655  17131   3961   1946   5089  11406  23901\n",
      "   2000  11497   3017   2517   2158     41   3474   2276   2312  78323\n",
      "   1942   2703  74369   2703  28513  22328   4570  25994   1009   3948\n",
      "  31025   4500   2023  21565   2089  62375   3972   4187  27088 110861\n",
      "  38529   2154   1947  87387   3241   2653   3972   6770   4509  61248\n",
      "   2312  78323   2326  31025   4500  44583  37590  56166  36859      3], shape=(250,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input_ids = []\n",
    "attention_mask = []\n",
    "\n",
    "for txt in df.text.values:\n",
    "    encoded = tokenizer.encode_plus(\n",
    "        text=txt, # the sentence to be encoded \n",
    "        add_special_tokens=True, # Add [CLS] and [SEP]\n",
    "        max_length=250, # max length of a sentence\n",
    "        truncation=True, # truncate if sentence length is bigger than max_length\n",
    "        pad_to_max_length=True, # Add [PAD]s\n",
    "        return_attention_mask=True, # Generate attention mask\n",
    "        return_tensors=\"tf\" # return TenforFlow tensors\n",
    "    )\n",
    "\n",
    "    # Append input_ids and attention_masks to their own lists\n",
    "    input_ids.append(encoded[\"input_ids\"])\n",
    "    attention_mask.append(encoded[\"attention_mask\"])\n",
    "\n",
    "# Concatenate\n",
    "input_ids = tf.concat(input_ids, 0)\n",
    "attention_mask = tf.concat(attention_mask, 0)\n",
    "\n",
    "print(\"Original: \", df.text.values[0])\n",
    "print(\"Token IDs: \", input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '3',\n",
       " 'milyon',\n",
       " 'ile',\n",
       " 'on',\n",
       " 'secim',\n",
       " 'vaadi',\n",
       " 'mhp',\n",
       " 'nin',\n",
       " '10',\n",
       " 'olagan',\n",
       " 'buyuk',\n",
       " 'kurultayı',\n",
       " 'nda',\n",
       " 'konus',\n",
       " '##an',\n",
       " 'genel',\n",
       " 'baskan',\n",
       " 'adayı',\n",
       " 'koray',\n",
       " '_',\n",
       " 'aydın',\n",
       " 'secim',\n",
       " '##lerden',\n",
       " 'once',\n",
       " 'partinin',\n",
       " 'uye',\n",
       " 'sayısının',\n",
       " '3',\n",
       " 'milyona',\n",
       " 'ulast',\n",
       " '##ırı',\n",
       " '##lması',\n",
       " 'hedefini',\n",
       " 'koyarak',\n",
       " 'on',\n",
       " 'secim',\n",
       " 'uygulaması',\n",
       " 'vaadinde',\n",
       " 'bulundu',\n",
       " 'mhp',\n",
       " 'nin',\n",
       " '10',\n",
       " 'olagan',\n",
       " 'buyuk',\n",
       " 'kurultayı',\n",
       " 'nda',\n",
       " 'konus',\n",
       " '##an',\n",
       " 'genel',\n",
       " 'baskan',\n",
       " 'adayı',\n",
       " 'koray',\n",
       " '_',\n",
       " 'aydın',\n",
       " 'secim',\n",
       " '##lerden',\n",
       " 'once',\n",
       " 'partinin',\n",
       " 'uye',\n",
       " 'sayısının',\n",
       " '3',\n",
       " 'milyona',\n",
       " 'ulast',\n",
       " '##ırı',\n",
       " '##lması',\n",
       " 'hedefini',\n",
       " 'koyarak',\n",
       " 'on',\n",
       " 'secim',\n",
       " 'uygulaması',\n",
       " 'vaadinde',\n",
       " 'bulundu',\n",
       " 'genel',\n",
       " '_',\n",
       " 'baskan',\n",
       " 'adayı',\n",
       " 'koray',\n",
       " '_',\n",
       " 'aydın',\n",
       " 'kursu',\n",
       " '##ye',\n",
       " 'beklenirken',\n",
       " 'yapılan',\n",
       " 'tezah',\n",
       " '##urat',\n",
       " '##lar',\n",
       " 've',\n",
       " 'ıslık',\n",
       " '##lamalar',\n",
       " 'uzerine',\n",
       " 'divan',\n",
       " 'baskan',\n",
       " '##ı',\n",
       " 'tug',\n",
       " '##rul',\n",
       " '_',\n",
       " 'turk',\n",
       " '##es',\n",
       " 'mhp',\n",
       " 'nin',\n",
       " 'genel',\n",
       " 'baskan',\n",
       " '##lıgı',\n",
       " 'da',\n",
       " 'genel',\n",
       " 'baskan',\n",
       " 'aday',\n",
       " '##lıgı',\n",
       " 'da',\n",
       " 'saygı',\n",
       " '##de',\n",
       " '##ger',\n",
       " 'isler',\n",
       " '##dir',\n",
       " 'bu',\n",
       " 'salondaki',\n",
       " 'herkes',\n",
       " 'ciddiye',\n",
       " 'almak',\n",
       " 'zorundadır',\n",
       " 'dedi',\n",
       " 've',\n",
       " 'task',\n",
       " '##ın',\n",
       " '##lıklara',\n",
       " 'izin',\n",
       " 'verilmeye',\n",
       " '##cegi',\n",
       " '##ni',\n",
       " 'salonda',\n",
       " 'suk',\n",
       " '##une',\n",
       " '##t',\n",
       " 'sag',\n",
       " '##lanmadan',\n",
       " 'konusma',\n",
       " '##ların',\n",
       " 'baslam',\n",
       " '##aya',\n",
       " '##cagını',\n",
       " 'vurguladı',\n",
       " 'turk',\n",
       " '##es',\n",
       " 'devlet',\n",
       " '_',\n",
       " 'bahceli',\n",
       " 'nin',\n",
       " 'kurultay',\n",
       " 'acılı',\n",
       " '##sında',\n",
       " 'konustu',\n",
       " '##gu',\n",
       " 'icin',\n",
       " 'adaylık',\n",
       " 'nedeniyle',\n",
       " 'ikinci',\n",
       " 'bir',\n",
       " 'konusma',\n",
       " 'yapmaya',\n",
       " '##cagını',\n",
       " 'acık',\n",
       " '##ladı',\n",
       " 'konusma',\n",
       " '##sında',\n",
       " 'kurultayın',\n",
       " 'mhp',\n",
       " 'nin',\n",
       " 'tek',\n",
       " 'basına',\n",
       " 'iktidarına',\n",
       " 'vesile',\n",
       " 'olmasını',\n",
       " 'dileyen',\n",
       " 'aydın',\n",
       " 'ak',\n",
       " '_',\n",
       " 'parti',\n",
       " 'nin',\n",
       " 'mhp',\n",
       " 'yi',\n",
       " 'elestir',\n",
       " '##irken',\n",
       " 'kaleleri',\n",
       " 'bir',\n",
       " 'bir',\n",
       " 'fethed',\n",
       " '##erek',\n",
       " 'yollarına',\n",
       " 'devam',\n",
       " 'ettiklerini',\n",
       " 'soyledi',\n",
       " '##gini',\n",
       " 'hatırlatarak',\n",
       " 'iktidarın',\n",
       " 'basın',\n",
       " 've',\n",
       " 'sivil',\n",
       " 'toplumu',\n",
       " 'sustur',\n",
       " '##du',\n",
       " '##gunu',\n",
       " 'ifade',\n",
       " 'etti',\n",
       " 'ak',\n",
       " '_',\n",
       " 'parti',\n",
       " 'nin',\n",
       " 'bur',\n",
       " '##okrasi',\n",
       " '##de',\n",
       " 'tas',\n",
       " 'ustune',\n",
       " 'tas',\n",
       " 'bırakmadı',\n",
       " '##gını',\n",
       " 'ileri',\n",
       " 'sure',\n",
       " '##n',\n",
       " 'aydın',\n",
       " 'ulk',\n",
       " '##ucu',\n",
       " '##leri',\n",
       " 'dus',\n",
       " '##man',\n",
       " 'kabule',\n",
       " 'ederek',\n",
       " 'onları',\n",
       " 'kıyma',\n",
       " 'makinelerinden',\n",
       " 'gecir',\n",
       " '##ecek',\n",
       " 'bir',\n",
       " 'zihniyetle',\n",
       " 'sur',\n",
       " '##gun',\n",
       " 'ederek',\n",
       " 'oraya',\n",
       " 'buraya',\n",
       " 'saldırarak',\n",
       " 'bur',\n",
       " '##okrasi',\n",
       " '##deki',\n",
       " 'ulk',\n",
       " '##ucu',\n",
       " 'kadrolara',\n",
       " 'savas',\n",
       " 'act',\n",
       " '##ıla',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert tokens to ids to check\n",
    "x = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 23,\n",
       " 2961,\n",
       " 2037,\n",
       " 2121,\n",
       " 75030,\n",
       " 47568,\n",
       " 6321,\n",
       " 2276,\n",
       " 2562,\n",
       " 110065,\n",
       " 20086,\n",
       " 30418,\n",
       " 3334,\n",
       " 5484,\n",
       " 1928,\n",
       " 2468,\n",
       " 34449,\n",
       " 6892,\n",
       " 20249,\n",
       " 41,\n",
       " 3948,\n",
       " 75030,\n",
       " 2884,\n",
       " 18094,\n",
       " 10349,\n",
       " 84087,\n",
       " 8369,\n",
       " 23,\n",
       " 18462,\n",
       " 114961,\n",
       " 3940,\n",
       " 120685,\n",
       " 28262,\n",
       " 14540,\n",
       " 2121,\n",
       " 75030,\n",
       " 6394,\n",
       " 87715,\n",
       " 4502,\n",
       " 6321,\n",
       " 2276,\n",
       " 2562,\n",
       " 110065,\n",
       " 20086,\n",
       " 30418,\n",
       " 3334,\n",
       " 5484,\n",
       " 1928,\n",
       " 2468,\n",
       " 34449,\n",
       " 6892,\n",
       " 20249,\n",
       " 41,\n",
       " 3948,\n",
       " 75030,\n",
       " 2884,\n",
       " 18094,\n",
       " 10349,\n",
       " 84087,\n",
       " 8369,\n",
       " 23,\n",
       " 18462,\n",
       " 114961,\n",
       " 3940,\n",
       " 120685,\n",
       " 28262,\n",
       " 14540,\n",
       " 2121,\n",
       " 75030,\n",
       " 6394,\n",
       " 87715,\n",
       " 4502,\n",
       " 2468,\n",
       " 41,\n",
       " 34449,\n",
       " 6892,\n",
       " 20249,\n",
       " 41,\n",
       " 3948,\n",
       " 6905,\n",
       " 3356,\n",
       " 37662,\n",
       " 2649,\n",
       " 17852,\n",
       " 90680,\n",
       " 1934,\n",
       " 1946,\n",
       " 48998,\n",
       " 10086,\n",
       " 45898,\n",
       " 11835,\n",
       " 34449,\n",
       " 1022,\n",
       " 36527,\n",
       " 9021,\n",
       " 41,\n",
       " 6142,\n",
       " 1951,\n",
       " 6321,\n",
       " 2276,\n",
       " 2468,\n",
       " 34449,\n",
       " 49313,\n",
       " 1972,\n",
       " 2468,\n",
       " 34449,\n",
       " 3554,\n",
       " 49313,\n",
       " 1972,\n",
       " 5316,\n",
       " 1942,\n",
       " 4829,\n",
       " 72798,\n",
       " 2025,\n",
       " 1964,\n",
       " 51135,\n",
       " 3171,\n",
       " 15818,\n",
       " 3632,\n",
       " 10121,\n",
       " 2841,\n",
       " 1946,\n",
       " 80525,\n",
       " 1930,\n",
       " 21291,\n",
       " 3794,\n",
       " 35219,\n",
       " 98117,\n",
       " 4389,\n",
       " 17367,\n",
       " 27101,\n",
       " 13224,\n",
       " 1025,\n",
       " 9598,\n",
       " 25110,\n",
       " 75577,\n",
       " 1980,\n",
       " 90717,\n",
       " 2213,\n",
       " 123433,\n",
       " 8781,\n",
       " 6142,\n",
       " 1951,\n",
       " 2780,\n",
       " 41,\n",
       " 68429,\n",
       " 2276,\n",
       " 15900,\n",
       " 26419,\n",
       " 5692,\n",
       " 105223,\n",
       " 2287,\n",
       " 8059,\n",
       " 24030,\n",
       " 3426,\n",
       " 3547,\n",
       " 1947,\n",
       " 75577,\n",
       " 5180,\n",
       " 123433,\n",
       " 20314,\n",
       " 2986,\n",
       " 75577,\n",
       " 5692,\n",
       " 80152,\n",
       " 6321,\n",
       " 2276,\n",
       " 2171,\n",
       " 13940,\n",
       " 64856,\n",
       " 11824,\n",
       " 5634,\n",
       " 23461,\n",
       " 3948,\n",
       " 2158,\n",
       " 41,\n",
       " 3474,\n",
       " 2276,\n",
       " 6321,\n",
       " 3553,\n",
       " 77122,\n",
       " 5370,\n",
       " 68190,\n",
       " 1947,\n",
       " 1947,\n",
       " 37649,\n",
       " 2408,\n",
       " 27374,\n",
       " 2524,\n",
       " 10924,\n",
       " 80447,\n",
       " 7426,\n",
       " 19655,\n",
       " 17131,\n",
       " 3961,\n",
       " 1946,\n",
       " 5089,\n",
       " 11406,\n",
       " 23901,\n",
       " 2000,\n",
       " 11497,\n",
       " 3017,\n",
       " 2517,\n",
       " 2158,\n",
       " 41,\n",
       " 3474,\n",
       " 2276,\n",
       " 2312,\n",
       " 78323,\n",
       " 1942,\n",
       " 2703,\n",
       " 74369,\n",
       " 2703,\n",
       " 28513,\n",
       " 22328,\n",
       " 4570,\n",
       " 25994,\n",
       " 1009,\n",
       " 3948,\n",
       " 31025,\n",
       " 4500,\n",
       " 2023,\n",
       " 21565,\n",
       " 2089,\n",
       " 62375,\n",
       " 3972,\n",
       " 4187,\n",
       " 27088,\n",
       " 110861,\n",
       " 38529,\n",
       " 2154,\n",
       " 1947,\n",
       " 87387,\n",
       " 3241,\n",
       " 2653,\n",
       " 3972,\n",
       " 6770,\n",
       " 4509,\n",
       " 61248,\n",
       " 2312,\n",
       " 78323,\n",
       " 2326,\n",
       " 31025,\n",
       " 4500,\n",
       " 44583,\n",
       " 37590,\n",
       " 56166,\n",
       " 36859,\n",
       " 3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4900, 250), dtype=int32, numpy=\n",
       " array([[     2,     23,   2961, ...,  56166,  36859,      3],\n",
       "        [     2,  11633,     41, ...,  22328,  80447,      3],\n",
       "        [     2,  50235,   4861, ...,     24,   4642,      3],\n",
       "        ...,\n",
       "        [     2,   6865,   2370, ...,   2351,   1964,      3],\n",
       "        [     2, 123116,  30632, ...,  44145,  46950,      3],\n",
       "        [     2,   5533,   1964, ...,      0,      0,      0]])>,\n",
       " TensorShape([4900, 250]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check input_ids and shape of input_ids\n",
    "input_ids, input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4900, 250), dtype=int32, numpy=\n",
       " array([[1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 0, 0, 0]])>,\n",
       " TensorShape([4900, 250]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check attention_mask and shape of attention_mask\n",
    "attention_mask, attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "labels_one_hot = one_hot_encoder.fit_transform(df[\"category\"].to_numpy().reshape(-1,1))\n",
    "labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((250,), (250,), (7,)), types: (tf.int32, tf.int32, tf.float64)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_mask, labels_one_hot))\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(input_ids, masks, labels):\n",
    "    # we convert our three-item tuple into a two-item tuple where the input item is a dictionary\n",
    "    return {\"input_ids\": input_ids,\n",
    "            \"attention_mask\": masks}, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({input_ids: (250,), attention_mask: (250,)}, (7,)), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.float64)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(map_func)\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "\n",
    "x = len(dataset)*0.85\n",
    "\n",
    "num_epochs = 3\n",
    "num_train_steps = x * num_epochs\n",
    "lr_scheduler = PolynomialDecay(\n",
    "    initial_learning_rate=5e-5,\n",
    "    end_learning_rate=0.,\n",
    "    decay_steps=num_train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({input_ids: (16, 250), attention_mask: (16, 250)}, (16, 7)), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.float64)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=16\n",
    "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(250,), dtype=int32, numpy=\n",
       " array([     2,     23,   2961,   2037,   2121,  75030,  47568,   6321,\n",
       "          2276,   2562, 110065,  20086,  30418,   3334,   5484,   1928,\n",
       "          2468,  34449,   6892,  20249,     41,   3948,  75030,   2884,\n",
       "         18094,  10349,  84087,   8369,     23,  18462, 114961,   3940,\n",
       "        120685,  28262,  14540,   2121,  75030,   6394,  87715,   4502,\n",
       "          6321,   2276,   2562, 110065,  20086,  30418,   3334,   5484,\n",
       "          1928,   2468,  34449,   6892,  20249,     41,   3948,  75030,\n",
       "          2884,  18094,  10349,  84087,   8369,     23,  18462, 114961,\n",
       "          3940, 120685,  28262,  14540,   2121,  75030,   6394,  87715,\n",
       "          4502,   2468,     41,  34449,   6892,  20249,     41,   3948,\n",
       "          6905,   3356,  37662,   2649,  17852,  90680,   1934,   1946,\n",
       "         48998,  10086,  45898,  11835,  34449,   1022,  36527,   9021,\n",
       "            41,   6142,   1951,   6321,   2276,   2468,  34449,  49313,\n",
       "          1972,   2468,  34449,   3554,  49313,   1972,   5316,   1942,\n",
       "          4829,  72798,   2025,   1964,  51135,   3171,  15818,   3632,\n",
       "         10121,   2841,   1946,  80525,   1930,  21291,   3794,  35219,\n",
       "         98117,   4389,  17367,  27101,  13224,   1025,   9598,  25110,\n",
       "         75577,   1980,  90717,   2213, 123433,   8781,   6142,   1951,\n",
       "          2780,     41,  68429,   2276,  15900,  26419,   5692, 105223,\n",
       "          2287,   8059,  24030,   3426,   3547,   1947,  75577,   5180,\n",
       "        123433,  20314,   2986,  75577,   5692,  80152,   6321,   2276,\n",
       "          2171,  13940,  64856,  11824,   5634,  23461,   3948,   2158,\n",
       "            41,   3474,   2276,   6321,   3553,  77122,   5370,  68190,\n",
       "          1947,   1947,  37649,   2408,  27374,   2524,  10924,  80447,\n",
       "          7426,  19655,  17131,   3961,   1946,   5089,  11406,  23901,\n",
       "          2000,  11497,   3017,   2517,   2158,     41,   3474,   2276,\n",
       "          2312,  78323,   1942,   2703,  74369,   2703,  28513,  22328,\n",
       "          4570,  25994,   1009,   3948,  31025,   4500,   2023,  21565,\n",
       "          2089,  62375,   3972,   4187,  27088, 110861,  38529,   2154,\n",
       "          1947,  87387,   3241,   2653,   3972,   6770,   4509,  61248,\n",
       "          2312,  78323,   2326,  31025,   4500,  44583,  37590,  56166,\n",
       "         36859,      3])>,\n",
       " TensorShape([250]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0], input_ids[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = 0.85\n",
    "size = int((input_ids.shape[0] / batch_size) * split)\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306, 260, 46)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = dataset.take(size)\n",
    "val_ds = dataset.skip(size)\n",
    "\n",
    "len(dataset), len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModel\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "bert128k = TFAutoModel.from_pretrained(\"dbmdz/bert-base-turkish-128k-uncased\")\n",
    "#bert = TFAutoModel.from_pretrained(\"dbmdz/bert-base-turkish-uncased\")\n",
    "#distilbert = TFAutoModel.from_pretrained(\"dbmdz/distilbert-base-turkish-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\egehan\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# two input layers, we ensure layer name variables match to dictionary keys in TF dataset\n",
    "input_ids = tf.keras.layers.Input(shape=(250,), name='input_ids', dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(250,), name='attention_mask', dtype='int32')\n",
    "\n",
    "# we access the transformer model within our bert object using the bert attribute (eg bert.bert instead of bert)\n",
    "embeddings = bert128k.bert(input_ids, attention_mask=mask)[1]  # access final activations (alread max-pooled) [1]\n",
    "# convert bert embeddings into 6 output classes\n",
    "x = tf.keras.layers.Dropout(0.1)(embeddings)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(7, activation='softmax', name='outputs')(x)\n",
    "\n",
    "# model\n",
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 250)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (TFBertMainLayer)          TFBaseModelOutputWit 184345344   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 768)          0           bert[0][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         787456      dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 7)            7175        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 185,139,975\n",
      "Trainable params: 794,631\n",
      "Non-trainable params: 184,345,344\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.layers[2].trainable=False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler) # lr=2e-5, decay=1e-6\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss=loss, \n",
    "              metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<TakeDataset shapes: ({input_ids: (16, 250), attention_mask: (16, 250)}, (16, 7)), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.float64)>,\n",
       " <SkipDataset shapes: ({input_ids: (16, 250), attention_mask: (16, 250)}, (16, 7)), types: ({input_ids: tf.int32, attention_mask: tf.int32}, tf.float64)>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "260/260 [==============================] - 697s 3s/step - loss: 1.5390 - accuracy: 0.4772 - val_loss: 1.1484 - val_accuracy: 0.6929\n",
      "Epoch 2/4\n",
      "260/260 [==============================] - 690s 3s/step - loss: 1.0721 - accuracy: 0.6798 - val_loss: 0.8713 - val_accuracy: 0.7622\n",
      "Epoch 3/4\n",
      "260/260 [==============================] - 688s 3s/step - loss: 0.8934 - accuracy: 0.7204 - val_loss: 0.7220 - val_accuracy: 0.7962\n",
      "Epoch 4/4\n",
      "260/260 [==============================] - 689s 3s/step - loss: 0.7936 - accuracy: 0.7522 - val_loss: 0.6642 - val_accuracy: 0.7948\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=4,\n",
    "    verbose=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c63b9c31b1e96fc19d2a13fbdf4ff075e8ca3441f99cb01fe5283baad6e722e3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('DL': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
